{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9727a21383dc4097a45bd1faa5de4813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db78f9df295d4a12879ca35fd4152318",
              "IPY_MODEL_93fe741a05544776a274a7e19d8d480c",
              "IPY_MODEL_3b94acd8d9d642a9bdaf98cfd5da6635",
              "IPY_MODEL_b1477056b47c495e8914e0b9d965e836"
            ],
            "layout": "IPY_MODEL_fe92789cc57c421998f19e53b4dcc32f"
          }
        },
        "dc679de6da604022b281a6db617856c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e4ff6e58fef4010be71f95ff8d4f5c1",
            "placeholder": "​",
            "style": "IPY_MODEL_03af4c5d5c3043d58b2acda51496ee33",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "8924d53ecb7747fca0751a73aebc48f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1adb0fd701584681aa7aa395434141e5",
            "placeholder": "​",
            "style": "IPY_MODEL_ff9fb615eb8542d4993f0c0ecf405dbb",
            "value": ""
          }
        },
        "255bd55cd800495cbf533bfc93f7fb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_bd017f370d634fdc86b5ea0c86289237",
            "style": "IPY_MODEL_7d43a61035b041e5b1f2b4f0a3a28dd2",
            "value": true
          }
        },
        "46fb51aa623c469abaadd13c6668fb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_275f205008c14c5e9fb24a85a5997d75",
            "style": "IPY_MODEL_c10a3b5cdc3e4c63a462f7d2b44578a9",
            "tooltip": ""
          }
        },
        "a299a62e4fc14afb8f8a8fbddfe7230f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872c6c5e3adb4310ae3f37d07e6bf6f5",
            "placeholder": "​",
            "style": "IPY_MODEL_73650804a1884db0aa1b5109340bb5ac",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "fe92789cc57c421998f19e53b4dcc32f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0e4ff6e58fef4010be71f95ff8d4f5c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03af4c5d5c3043d58b2acda51496ee33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1adb0fd701584681aa7aa395434141e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff9fb615eb8542d4993f0c0ecf405dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd017f370d634fdc86b5ea0c86289237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d43a61035b041e5b1f2b4f0a3a28dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "275f205008c14c5e9fb24a85a5997d75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c10a3b5cdc3e4c63a462f7d2b44578a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "872c6c5e3adb4310ae3f37d07e6bf6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73650804a1884db0aa1b5109340bb5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b32f66273054e7196ee69f5af4f32ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea54a2e7cbc4534a2ce19c7428119d2",
            "placeholder": "​",
            "style": "IPY_MODEL_be992587447b42a8bf183e9bdeb3b82a",
            "value": "Connecting..."
          }
        },
        "dea54a2e7cbc4534a2ce19c7428119d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be992587447b42a8bf183e9bdeb3b82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db78f9df295d4a12879ca35fd4152318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2d7666aea2468383b460ece894edb5",
            "placeholder": "​",
            "style": "IPY_MODEL_6a0832467c464105b7439993218b2bce",
            "value": "Token is valid (permission: write)."
          }
        },
        "93fe741a05544776a274a7e19d8d480c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75a8916f74894a1784fbe2d3e668d157",
            "placeholder": "​",
            "style": "IPY_MODEL_695d5b8df9054ce18401bf100fe12f45",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "3b94acd8d9d642a9bdaf98cfd5da6635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283e8139f9db43fb934cb691ef419653",
            "placeholder": "​",
            "style": "IPY_MODEL_d01f950743ab4555998858827c5d9bd8",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "b1477056b47c495e8914e0b9d965e836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd9c74a3b5ae44a4b947413a23a0caf2",
            "placeholder": "​",
            "style": "IPY_MODEL_862f74e2ed764cab8eb24ce0b1d0ae12",
            "value": "Login successful"
          }
        },
        "bf2d7666aea2468383b460ece894edb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a0832467c464105b7439993218b2bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75a8916f74894a1784fbe2d3e668d157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "695d5b8df9054ce18401bf100fe12f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "283e8139f9db43fb934cb691ef419653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d01f950743ab4555998858827c5d9bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd9c74a3b5ae44a4b947413a23a0caf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "862f74e2ed764cab8eb24ce0b1d0ae12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1efb2374a1644e52a81a636a13d58249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0d12a53ae8741529c8bf2b5091ff77e",
              "IPY_MODEL_668fc4ca3f3649fba0aa8a8b247190f9",
              "IPY_MODEL_9752189bc9b24d03944bef5a5e54be4c"
            ],
            "layout": "IPY_MODEL_39813189570f4788999192850a4e49d9"
          }
        },
        "e0d12a53ae8741529c8bf2b5091ff77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6daf309730fa4663b580b82b809b0a8a",
            "placeholder": "​",
            "style": "IPY_MODEL_946599f8b6b549ce97259b76c214e2d4",
            "value": "(…)a-2-13b-chat-hf/resolve/main/config.json: 100%"
          }
        },
        "668fc4ca3f3649fba0aa8a8b247190f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c92c69be70147a68d69b09298beb0e5",
            "max": 587,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7753614eac8449c28790b03307e041fb",
            "value": 587
          }
        },
        "9752189bc9b24d03944bef5a5e54be4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_920092d6cc814f7bac5871f15399354f",
            "placeholder": "​",
            "style": "IPY_MODEL_2fa280ad9b1d412d8069991ea1a71dd1",
            "value": " 587/587 [00:00&lt;00:00, 49.1kB/s]"
          }
        },
        "39813189570f4788999192850a4e49d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6daf309730fa4663b580b82b809b0a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946599f8b6b549ce97259b76c214e2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c92c69be70147a68d69b09298beb0e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7753614eac8449c28790b03307e041fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "920092d6cc814f7bac5871f15399354f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fa280ad9b1d412d8069991ea1a71dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c262b8db4074d16abc7b6bf8ea498f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62613533653246e58b2098ebce07dde9",
              "IPY_MODEL_2d2f447babe349e6b0855ebd88891f35",
              "IPY_MODEL_077844fb62a94cb0a3110dab3c3dece0"
            ],
            "layout": "IPY_MODEL_de01eaac2f7e4d1f9602dfe91d909a16"
          }
        },
        "62613533653246e58b2098ebce07dde9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ea299e685d40e7b0b6489238971672",
            "placeholder": "​",
            "style": "IPY_MODEL_da701fa4748444d481dffa06a9f27615",
            "value": "(…)esolve/main/model.safetensors.index.json: 100%"
          }
        },
        "2d2f447babe349e6b0855ebd88891f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f94d3a90644b9ca78017adf744676f",
            "max": 33444,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea8cdf1ee35641f2acccca64ab3cbbd7",
            "value": 33444
          }
        },
        "077844fb62a94cb0a3110dab3c3dece0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6885ce7fb88844eea68afcea5eba5815",
            "placeholder": "​",
            "style": "IPY_MODEL_3976ed21cc40432f84feaed5b73f0853",
            "value": " 33.4k/33.4k [00:00&lt;00:00, 2.90MB/s]"
          }
        },
        "de01eaac2f7e4d1f9602dfe91d909a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ea299e685d40e7b0b6489238971672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da701fa4748444d481dffa06a9f27615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93f94d3a90644b9ca78017adf744676f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea8cdf1ee35641f2acccca64ab3cbbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6885ce7fb88844eea68afcea5eba5815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3976ed21cc40432f84feaed5b73f0853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5bbd14bce5748189abbbb7590286084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_552ab0fd9a2548eaa83b734afa624700",
              "IPY_MODEL_35f8a9ddeb87498ca8d2255b762b43df",
              "IPY_MODEL_ddc5cf8a1d3b428ab46427324bacb1e2"
            ],
            "layout": "IPY_MODEL_b2d3a46945814958a0d1f7cc5eab69f0"
          }
        },
        "552ab0fd9a2548eaa83b734afa624700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b876d53cfc49bc84196c197ceaa678",
            "placeholder": "​",
            "style": "IPY_MODEL_206e23463df34730ab727c17d6947957",
            "value": "Downloading shards: 100%"
          }
        },
        "35f8a9ddeb87498ca8d2255b762b43df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac28784d1585470fa1a2694e4241331f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3b2428376d5422298e3347882b4e4cf",
            "value": 3
          }
        },
        "ddc5cf8a1d3b428ab46427324bacb1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39990ef1d383482d929837fa1342cf68",
            "placeholder": "​",
            "style": "IPY_MODEL_e29497df3e634110b7de7be93737e02c",
            "value": " 3/3 [01:19&lt;00:00, 25.31s/it]"
          }
        },
        "b2d3a46945814958a0d1f7cc5eab69f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b876d53cfc49bc84196c197ceaa678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "206e23463df34730ab727c17d6947957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac28784d1585470fa1a2694e4241331f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b2428376d5422298e3347882b4e4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39990ef1d383482d929837fa1342cf68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e29497df3e634110b7de7be93737e02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f48d9623fa894b97b5bfb18191bc1654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67f293a4c0bb4c71939f7914a503f6b0",
              "IPY_MODEL_92dfe87e5dc4430da51d75237b04c0c1",
              "IPY_MODEL_dfc951fbaa5d4ab38d048debd8438dac"
            ],
            "layout": "IPY_MODEL_d87dd27f884d44d299516825abc045ee"
          }
        },
        "67f293a4c0bb4c71939f7914a503f6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff8f259492df4a92b221cb3d2c18112b",
            "placeholder": "​",
            "style": "IPY_MODEL_f6b76b715d134f118dd5d3fa04d955fa",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "92dfe87e5dc4430da51d75237b04c0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e8ffcc4ec024a5a975978aee2583ec5",
            "max": 9948693272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20f5eab6b39e4d939fb2387dee26e3eb",
            "value": 9948693272
          }
        },
        "dfc951fbaa5d4ab38d048debd8438dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228ea255624740ffb1dafcb3edd85cb5",
            "placeholder": "​",
            "style": "IPY_MODEL_bc15521b83864637bf2cfbff055de64b",
            "value": " 9.95G/9.95G [00:29&lt;00:00, 411MB/s]"
          }
        },
        "d87dd27f884d44d299516825abc045ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff8f259492df4a92b221cb3d2c18112b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b76b715d134f118dd5d3fa04d955fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e8ffcc4ec024a5a975978aee2583ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20f5eab6b39e4d939fb2387dee26e3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "228ea255624740ffb1dafcb3edd85cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc15521b83864637bf2cfbff055de64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab56e160fa2f4449ada8f12a244b8dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b552dfdfe2a4d72afcc80e472980897",
              "IPY_MODEL_f7c8a6b04fb748cf9c54a14af528eaf9",
              "IPY_MODEL_a6e5ee9e3a3a46479d4b6fa61225a26f"
            ],
            "layout": "IPY_MODEL_e9a4a8dccf3a41058ba67a093277d9d0"
          }
        },
        "4b552dfdfe2a4d72afcc80e472980897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4920b6584893485bb084cb7cbc48339a",
            "placeholder": "​",
            "style": "IPY_MODEL_ba55aa3001a441199c7b7b89decf6f73",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "f7c8a6b04fb748cf9c54a14af528eaf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c80b2427c22e41f8b3fcc1ecc128c009",
            "max": 9904129368,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0ebda48fa1b4670baf38a160bb2605b",
            "value": 9904129368
          }
        },
        "a6e5ee9e3a3a46479d4b6fa61225a26f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1cecf38c3bc4cb0926fa66d82363328",
            "placeholder": "​",
            "style": "IPY_MODEL_5b582053acbb4cd0857455a272b1b6c9",
            "value": " 9.90G/9.90G [00:29&lt;00:00, 419MB/s]"
          }
        },
        "e9a4a8dccf3a41058ba67a093277d9d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4920b6584893485bb084cb7cbc48339a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba55aa3001a441199c7b7b89decf6f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c80b2427c22e41f8b3fcc1ecc128c009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ebda48fa1b4670baf38a160bb2605b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1cecf38c3bc4cb0926fa66d82363328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b582053acbb4cd0857455a272b1b6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1466d45547f64f0db50685fd5375fbe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d93c96940af7482baece6ce369138b40",
              "IPY_MODEL_0a9e946e9a4f4bbea1293d80a9df6ddf",
              "IPY_MODEL_52a78d04f9214f5cb309cd0609f46e64"
            ],
            "layout": "IPY_MODEL_e79536b981be40d0995f6f064fa28a43"
          }
        },
        "d93c96940af7482baece6ce369138b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21a3ce442905456bbff81a0539367c31",
            "placeholder": "​",
            "style": "IPY_MODEL_f311d97105cb46b2899d0ed69954a015",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "0a9e946e9a4f4bbea1293d80a9df6ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92fbde51dbd64f52aa48cb58bac6a85e",
            "max": 6178962272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed0aab945c674eef9db84dbeb681139f",
            "value": 6178962272
          }
        },
        "52a78d04f9214f5cb309cd0609f46e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0ea578250a74c6d84fdec66e4c97ef4",
            "placeholder": "​",
            "style": "IPY_MODEL_e6fc4c4fd5f3418f8c7ee4b7d471cac3",
            "value": " 6.18G/6.18G [00:20&lt;00:00, 347MB/s]"
          }
        },
        "e79536b981be40d0995f6f064fa28a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21a3ce442905456bbff81a0539367c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f311d97105cb46b2899d0ed69954a015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92fbde51dbd64f52aa48cb58bac6a85e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed0aab945c674eef9db84dbeb681139f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0ea578250a74c6d84fdec66e4c97ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6fc4c4fd5f3418f8c7ee4b7d471cac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c3072086afa42f2a7d819f95ae5a970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e103408322324d749325d7146d941ad5",
              "IPY_MODEL_8ccec662868c4895abcdc0f51d8669ea",
              "IPY_MODEL_f8fb1bbda77e4f0b8079e517f450c53f"
            ],
            "layout": "IPY_MODEL_9038750942a14c418f84ce889fc06227"
          }
        },
        "e103408322324d749325d7146d941ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efeb488cf2244131a2cf2727b8adb575",
            "placeholder": "​",
            "style": "IPY_MODEL_fca1f59286754b8f8cc2850a7c1709be",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8ccec662868c4895abcdc0f51d8669ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e483714a12794cb6b86da27493f4acdc",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c71bc16b6cf4790aa7a4f75d1ed07b9",
            "value": 3
          }
        },
        "f8fb1bbda77e4f0b8079e517f450c53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b60f469dc364c998c6896120948eb00",
            "placeholder": "​",
            "style": "IPY_MODEL_16c6385016e345d9879a7a4dcd1b3344",
            "value": " 3/3 [01:51&lt;00:00, 35.04s/it]"
          }
        },
        "9038750942a14c418f84ce889fc06227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efeb488cf2244131a2cf2727b8adb575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca1f59286754b8f8cc2850a7c1709be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e483714a12794cb6b86da27493f4acdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c71bc16b6cf4790aa7a4f75d1ed07b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b60f469dc364c998c6896120948eb00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16c6385016e345d9879a7a4dcd1b3344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1ae393b1a83404894287e8f8d3e6da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8909831f56843f6a2bd2fab7540e5e8",
              "IPY_MODEL_55f2d974fd3f411897a4c98a2f461e90",
              "IPY_MODEL_d04d44aba64f42c1a1d32e238253b099"
            ],
            "layout": "IPY_MODEL_d558550f31984373929ee69b1d049ef3"
          }
        },
        "c8909831f56843f6a2bd2fab7540e5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c306eb541d024e6bb5584457030a5b1f",
            "placeholder": "​",
            "style": "IPY_MODEL_dfa44ca6659447848d74bdcf2aba91c5",
            "value": "(…)t-hf/resolve/main/generation_config.json: 100%"
          }
        },
        "55f2d974fd3f411897a4c98a2f461e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972ab6bfa69f4f4e9b3cd6ee75cf33a4",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_872fe4cfdfb349178c77fa7653235e2a",
            "value": 188
          }
        },
        "d04d44aba64f42c1a1d32e238253b099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b71d2f4a385741b0b04e71ecd743560e",
            "placeholder": "​",
            "style": "IPY_MODEL_002fc7e34d6542fca4c1c7244f392392",
            "value": " 188/188 [00:00&lt;00:00, 16.5kB/s]"
          }
        },
        "d558550f31984373929ee69b1d049ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c306eb541d024e6bb5584457030a5b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa44ca6659447848d74bdcf2aba91c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "972ab6bfa69f4f4e9b3cd6ee75cf33a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "872fe4cfdfb349178c77fa7653235e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b71d2f4a385741b0b04e71ecd743560e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002fc7e34d6542fca4c1c7244f392392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8561f0b7d510479fa0e24c4dc0f2c501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac454e01a978411f9bf8d2450076d1dc",
              "IPY_MODEL_49018fb7c125419e8dfa4dd2a044ad23",
              "IPY_MODEL_907b52d19b5e463391194c1e916a1980"
            ],
            "layout": "IPY_MODEL_02fa431029614c96b6340780333d0fab"
          }
        },
        "ac454e01a978411f9bf8d2450076d1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5958e14e464742c88a9a472d1e6a520c",
            "placeholder": "​",
            "style": "IPY_MODEL_b897cd965ee54c45aaf45e703c969b9a",
            "value": "(…)at-hf/resolve/main/tokenizer_config.json: 100%"
          }
        },
        "49018fb7c125419e8dfa4dd2a044ad23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_684b49fbeaa34fe19c8968fa788bc372",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4d2569b660441128ad76f61004cf154",
            "value": 1618
          }
        },
        "907b52d19b5e463391194c1e916a1980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed0a98f834e41e6a3326c0dc84bfba8",
            "placeholder": "​",
            "style": "IPY_MODEL_903506efc5d54acf9a6ad2de25fd8693",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 131kB/s]"
          }
        },
        "02fa431029614c96b6340780333d0fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5958e14e464742c88a9a472d1e6a520c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b897cd965ee54c45aaf45e703c969b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "684b49fbeaa34fe19c8968fa788bc372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d2569b660441128ad76f61004cf154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ed0a98f834e41e6a3326c0dc84bfba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "903506efc5d54acf9a6ad2de25fd8693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5afe71e74c1a404bb4caed2713802863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe0939e7ba2842fa9801e3b72729d7e6",
              "IPY_MODEL_bce8d1e8e47e45c48f0984b8f55a255c",
              "IPY_MODEL_f7bdf42b7a70418ba8adf8e26b87487c"
            ],
            "layout": "IPY_MODEL_c40b7841f0a349738143e1e6a46fc26e"
          }
        },
        "fe0939e7ba2842fa9801e3b72729d7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9912e713d5945b693d77949bf72053a",
            "placeholder": "​",
            "style": "IPY_MODEL_7c5e3810c57546eca33e263389a66333",
            "value": "tokenizer.model: 100%"
          }
        },
        "bce8d1e8e47e45c48f0984b8f55a255c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ddeed00a774e259d59ffff57638378",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7766c4247fc54aad97c8027a59fa70d2",
            "value": 499723
          }
        },
        "f7bdf42b7a70418ba8adf8e26b87487c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9925962aba204892a01999081f8c0489",
            "placeholder": "​",
            "style": "IPY_MODEL_58013e37ff59432192ed91f4c1ee494d",
            "value": " 500k/500k [00:00&lt;00:00, 10.9MB/s]"
          }
        },
        "c40b7841f0a349738143e1e6a46fc26e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9912e713d5945b693d77949bf72053a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c5e3810c57546eca33e263389a66333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00ddeed00a774e259d59ffff57638378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7766c4247fc54aad97c8027a59fa70d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9925962aba204892a01999081f8c0489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58013e37ff59432192ed91f4c1ee494d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a32c8ed7d03e4b6d833254ea4dc25841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5132176feaff40ffaf83b2b5528f3606",
              "IPY_MODEL_ca744cb5cfe14ae7b26b1026735ea908",
              "IPY_MODEL_1138daef29964892a7c5e2f5894f66cf"
            ],
            "layout": "IPY_MODEL_7bff7c6c762f40de928f1d32f492d3fd"
          }
        },
        "5132176feaff40ffaf83b2b5528f3606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c79b7a7b0f2440448d50b7016b67640e",
            "placeholder": "​",
            "style": "IPY_MODEL_2c1ce27fa6c14eebb364204def1a8134",
            "value": "(…)-13b-chat-hf/resolve/main/tokenizer.json: 100%"
          }
        },
        "ca744cb5cfe14ae7b26b1026735ea908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51e0aee033b343309be4b447def12b1f",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50485d7d98434acbb7ece883958a20b7",
            "value": 1842767
          }
        },
        "1138daef29964892a7c5e2f5894f66cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34e64be41c124c4ba200ecd2ab8a360b",
            "placeholder": "​",
            "style": "IPY_MODEL_44f7d3a6182b4484bcfe61e21c8da94c",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 4.90MB/s]"
          }
        },
        "7bff7c6c762f40de928f1d32f492d3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c79b7a7b0f2440448d50b7016b67640e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c1ce27fa6c14eebb364204def1a8134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51e0aee033b343309be4b447def12b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50485d7d98434acbb7ece883958a20b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34e64be41c124c4ba200ecd2ab8a360b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f7d3a6182b4484bcfe61e21c8da94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "156ad84235b64399a4d978c8450a3d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07d47d2514af4f82a7290d5a689aa9f8",
              "IPY_MODEL_60da19e614b647d6b31511a484333a80",
              "IPY_MODEL_ce239a66fd624f349a259d8769e06fb2"
            ],
            "layout": "IPY_MODEL_ba926ec5181142ed98492da94d0f2db1"
          }
        },
        "07d47d2514af4f82a7290d5a689aa9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cafb0b0a9d834b6fa03da55a1d5a3b91",
            "placeholder": "​",
            "style": "IPY_MODEL_13dc5eb9583c4c67afa23004f5a2e6df",
            "value": "(…)-hf/resolve/main/special_tokens_map.json: 100%"
          }
        },
        "60da19e614b647d6b31511a484333a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1601b7b079d64d23a9e22ef186628c1a",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3192096d9b064c889a03cfb725b9578f",
            "value": 414
          }
        },
        "ce239a66fd624f349a259d8769e06fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1084c72683b14087a81e0def011c2ff5",
            "placeholder": "​",
            "style": "IPY_MODEL_b59fa3efd3a44f819ab16ccfa0db9e2c",
            "value": " 414/414 [00:00&lt;00:00, 34.8kB/s]"
          }
        },
        "ba926ec5181142ed98492da94d0f2db1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cafb0b0a9d834b6fa03da55a1d5a3b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13dc5eb9583c4c67afa23004f5a2e6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1601b7b079d64d23a9e22ef186628c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3192096d9b064c889a03cfb725b9578f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1084c72683b14087a81e0def011c2ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59fa3efd3a44f819ab16ccfa0db9e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dapopov-st/ExperimentsWithLanguageModels/blob/main/RAG_over_ArXiv_PDFs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Make a directory of ArXiv papers on Google Drive\n",
        "- See if can store the vector store in Drive or just in ram\n",
        "- Bridge this paper with the book\n",
        "- If can't access A100 consistenly and run out of GPU memory, make a Mistral 7B/Zephyr 7B version (Zephyr can do ReAct!)\n",
        "- Rag with metadata (ex, subdirectory name etc.)\n",
        "- Use Self-Rag 7b? selfrag/selfrag_llama2_7b or 13b.  Think this will help overcome some of the challenges with retrieving from pdfs (getting titles from References section, for example, rather than useful content)"
      ],
      "metadata": {
        "id": "acp5I6NYnqUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Original NB worked in under 10GB on V100"
      ],
      "metadata": {
        "id": "wNFFyZtKbPTl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GEn4fyEq80Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-task Work\n",
        "\n",
        "All we really need to do to get started is to get our prerequisites!\n",
        "\n",
        "We'll be leveraging `langchain` and `llama 2` today.\n",
        "\n",
        "Check out the docs:\n",
        "- [LangChain](https://docs.langchain.com/docs/)\n",
        "- [LLaMA 2](https://huggingface.co/blog/llama2)"
      ],
      "metadata": {
        "id": "zcL8585DsZML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"langchain\" \"transformers==4.31.0\" \"datasets==2.13.0\" \"peft==0.4.0\" \"accelerate==0.21.0\" \"bitsandbytes==0.40.2\" \"trl==0.4.7\" \"safetensors>=0.3.1\"\n",
        "!pip install -U -q cohere llama-index\n",
        "!pip install PyPDF2\n",
        "!pip install pypdf\n",
        "!pip install -q qdrant-client\n",
        "!pip install -q -U faiss-cpu tiktoken sentence-transformers\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/PdfRag/rag_output_dir'\n",
        "logging_dir = '/content/drive/MyDrive/PdfRag/rag_logging_dir'\n",
        "index_dir = '/content/drive/MyDrive/PdfRag/rag_index_dir'\n",
        "\n",
        "#!ls /content/drive/MyDrive/PdfRag/clusterofstars\n",
        "%cd /content/drive/MyDrive/PdfRag\n",
        "#My\\ Drive/PdfRag && ls clusterofstars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_4yw-Kt9OLh",
        "outputId": "811b85f5-5863-47f1-ea51-553c339e6a92"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.17.0)\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/PdfRag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5OniYBVAUkZ",
        "outputId": "974eaab1-a25c-4d5b-c567-0a0f184e9437"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "barbie.csv  cache  clusterofstars  oppenheimer.csv  rag_index_dir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "PDFS_PATH = Path('/content/drive/MyDrive/PdfRag/clusterofstars')\n",
        "PDFS = list(PDFS_PATH.glob('*.pdf'))\n",
        "PDFS[0], len(PDFS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASsG0WrAKpjx",
        "outputId": "2432f9d5-a09f-4ab3-a41d-46acdff9fea2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('/content/drive/MyDrive/PdfRag/clusterofstars/InContextRALM.pdf'),\n",
              " 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For now, flatten out the file structure for simplicity.  In the future, see if can have Rag use this metadata.\n",
        "#!mv /content/drive/MyDrive/PdfRag/clusterofstars/ChainOfThought/* /content/drive/MyDrive/PdfRag/clusterofstars"
      ],
      "metadata": {
        "id": "cZh-G1B4BR3N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fastai function to clean GPU memory\n",
        "\n",
        "import sys,gc,traceback\n",
        "import torch\n",
        "def clean_ipython_hist():\n",
        "    # Code in this function mainly copied from IPython source\n",
        "    if not 'get_ipython' in globals(): return\n",
        "    ip = get_ipython()\n",
        "    user_ns = ip.user_ns\n",
        "    ip.displayhook.flush()\n",
        "    pc = ip.displayhook.prompt_count + 1\n",
        "    for n in range(1, pc): user_ns.pop('_i'+repr(n),None)\n",
        "    user_ns.update(dict(_i='',_ii='',_iii=''))\n",
        "    hm = ip.history_manager\n",
        "    hm.input_hist_parsed[:] = [''] * pc\n",
        "    hm.input_hist_raw[:] = [''] * pc\n",
        "    hm._i = hm._ii = hm._iii = hm._i00 =  ''\n",
        "\n",
        "\n",
        "\n",
        "def clean_tb():\n",
        "    # h/t Piotr Czapla\n",
        "    if hasattr(sys, 'last_traceback'):\n",
        "        traceback.clear_frames(sys.last_traceback)\n",
        "        delattr(sys, 'last_traceback')\n",
        "    if hasattr(sys, 'last_type'): delattr(sys, 'last_type')\n",
        "    if hasattr(sys, 'last_value'): delattr(sys, 'last_value')\n",
        "\n",
        "def clean_mem():\n",
        "    clean_tb()\n",
        "    clean_ipython_hist()\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n"
      ],
      "metadata": {
        "id": "njvn6qYP_wA5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a PDF Data Loader"
      ],
      "metadata": {
        "id": "XKDGPyyD8Ks3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --q pdfminer.six"
      ],
      "metadata": {
        "id": "NUGqdUYZ-Lyi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PDFMinerLoader"
      ],
      "metadata": {
        "id": "5SJ-jPac86JW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PDFMinerLoader(os.path.expanduser(PDFS[0]))"
      ],
      "metadata": {
        "id": "HAGFzA-F86UN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_content = loader.load()\n",
        "pdf_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw6qfeuf86iV",
        "outputId": "24d73f74-35b3-44a6-e55e-eec095fe2729"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='In-ContextRetrieval-AugmentedLanguageModelsOriRam∗YoavLevine∗ItayDalmedigosDorMuhlgayAmnonShashuaKevinLeyton-BrownYoavShohamAI21Labs{orir,yoavl,itayd,dorm,amnons,kevinlb,yoavs}@ai21.comAbstractRetrieval-AugmentedLanguageModeling(RALM)methods,whichconditionalan-guagemodel(LM)onrelevantdocumentsfromagroundingcorpusduringgeneration,wereshowntosigni\\ue000cantlyimprovelan-guagemodelingperformance.Inaddition,theycanmitigatetheproblemoffactuallyinaccuratetextgenerationandprovidenatu-ralsourceattributionmechanism.ExistingRALMapproachesfocusonmodifyingtheLMarchitectureinordertofacilitatethein-corporationofexternalinformation,signi\\ue000-cantlycomplicatingdeployment.Thispaperconsidersasimplealternative,whichwedubIn-ContextRALM:leavingtheLMarchitec-tureunchangedandprependinggroundingdocumentstotheinput,withoutanyfurthertrainingoftheLM.WeshowthatIn-ContextRALMthatbuildsonoff-the-shelfgeneralpurposeretrieversprovidessurprisinglylargeLMgainsacrossmodelsizesanddiversecor-pora.Wealsodemonstratethatthedocumentretrievalandrankingmechanismcanbespe-cializedtotheRALMsettingtofurtherboostperformance.WeconcludethatIn-ContextRALMhasconsiderablepotentialtoincreasetheprevalenceofLMgrounding,particularlyinsettingswhereapretrainedLMmustbeusedwithoutmodi\\ue000cationorevenviaAPIaccess.11IntroductionRecentadvancesinlanguagemodeling(LM)havedramaticallyincreasedtheusefulnessofmachine-generatedtextacrossawiderangeofuse-casesanddomains(Brownetal.,2020).However,themainstreamparadigmofgeneratingtextwithLMsbearsinherentlimitationsinaccesstoexternalknowledge.First,LMsarenotcoupledwithany∗Equalcontribution.1Ourcodeisavailableathttps://github.com/AI21Labs/in-context-ralmFigure1:Ourframework,dubbedIn-ContextRALM,provideslargelanguagemodelinggainsonthetestsetofWikiText-103,withoutmodifyingtheLM.AdaptingtheuseofaBM25retriever(Robert-sonandZaragoza,2009)totheLMtask(§5)yieldssigni\\ue000cantgains,andchoosingthegroundingdoc-umentsviaournewclassofPredictiveRerankers(§6)providesafurtherboost.SeeTable1forthefullresultson\\ue000vediversecorpora.sourceattribution,andmustbetrainedinordertoincorporateup-to-dateinformationthatwasnotseenduringtraining.Moreimportantly,theytendtoproducefactualinaccuraciesanderrors(Linetal.,2022;Maynezetal.,2020;Huangetal.,2020).ThisproblemispresentinanyLMgen-erationscenario,andisexacerbatedwhengener-ationismadeinuncommondomainsorprivatedata.ApromisingapproachforaddressingtheaboveisRetrieval-AugmentedLanguageModeling(RALM),groundingtheLMduringgenerationbyconditioningonrelevantdocumentsretrievedfromanexternalknowledgesource.RALMsystemsin-cludetwohighlevelcomponents:(i)documentse-lection,selectingthesetofdocumentsuponwhichtocondition;and(ii)documentreading,determin-inghowtoincorporatetheselecteddocumentsintotheLMgenerationprocess.LeadingRALMsystemsintroducedrecentlyarXiv:2302.00083v3  [cs.CL]  1 Aug 2023\\x0cFigure2:AnexampleofIn-ContextRALM:wesimplyprependtheretrieveddocumentbeforetheinputpre\\ue000x.tendtobefocusedonalteringthelanguagemodelarchitecture(Khandelwaletal.,2020;Borgeaudetal.,2022;Zhongetal.,2022;Levineetal.,2022c;Lietal.,2022).Notably,Borgeaudetal.(2022)in-troducedRETRO,featuringdocumentreadingvianontrivialmodi\\ue000cationsthatrequirefurthertrain-ingtotheLMarchitecture,whileusinganoff-the-shelffrozenBERTretrieverfordocumentselec-tion.Althoughthepaper’sexperimental\\ue000ndingsshowedimpressiveperformancegains,theneedforchangesinarchitectureanddedicatedretraininghashinderedthewideadoptionofsuchmodels.Inthispaper,weshowthataverysimpledoc-umentreadingmechanismcanhavealargeim-pact,andthatsubstantialgainscanalsobemadebyadaptingthedocumentselectionmechanismtothetaskoflanguagemodeling.Thus,weshowthatmanyofthebene\\ue000tsofRALMcanbeachievedwhileworkingwithoff-the-shelfLMs,evenviaAPIaccess.Speci\\ue000cally,weconsiderasimplebutpowerfulRALMframework,dubbedIn-ContextRALM(presentedinSection3),whichemploysazero-effortdocumentreadingmechanism:wesim-plyprependtheselecteddocumentstotheLM’sinputtext(Figure2).Section4describesourexperimentalsetup.Toshowthewideapplicabilityofourframework,weperformedLMexperimentsonasuiteof\\ue000vedi-versecorpora:WikiText-103(Merityetal.,2016),RealNews(Zellersetal.,2019),andthreedatasetsfromThePile(Gaoetal.,2021):ArXiv,StackExchangeandFreeLaw.Weuseopen-sourceLMsrangingfrom110Mto66Bparameters(fromtheGPT-2,GPT-Neo,OPTandLLaMAmodelfami-lies).InSection5weevaluatetheapplicationofoff-the-shelfretrieverstoourframework.Inthisminimal-effortsetting,wefoundthatIn-ContextRALMledtoLMperformancegainsequivalenttoincreasingtheLM’snumberofparametersby2–3×acrossallofthetextcorporaweexamined.InSection6weinvestigatemethodsforadaptingdoc-umentrankingtotheLMtask,arelativelyunder-exploredRALMdegreeoffreedom.Ouradapta-tionmethodsrangefromusingasmallLMtoper-formzero-shotrankingoftheretrieveddocuments,uptotrainingadedicatedbidirectionalrerankerbyemployingself-supervisionfromtheLMsignal.ThesemethodsleadtofurthergainsintheLMtaskcorrespondingtoanadditionalsizeincreaseof2×intheLMarchitecture.Asaconcreteexampleofthegains,a345MparameterGPT-2enhancedbyIn-ContextRALMoutperformsa762Mparame-terGPT-2whenemployinganoff-the-shelfBM25retriever(RobertsonandZaragoza,2009),andout-performsa1.5BparameterGPT-2whenemployingourtrainedLM-orientedreranker(seeFigure1).Forlargemodelsizes,ourmethodisevenmoreeffective:In-ContextRALMwithanoff-the-shelfretrieverimprovedtheperformanceofa6.7Bpa-rameterOPTmodeltomatchthatofa66Bparam-eterparameterOPTmodel(seeFigure4).InSection7wedemonstratetheapplicabilityofIn-ContextRALMtodownstreamopen-domainquestionsanswering(ODQA)tasks.Inaconcurrentwork,Shietal.(2023)alsosug-gesttoaugmentoff-the-shelfLMswithretrievedtextsbyprependingthemtotheinput.Theirre-sultsarebasedontrainingadedicatedretrieverforlanguagemodeling.Incontrast,wefocusonthegainsachievableinusingoff-the-shelfretrieversforthistask.Weshowstronggainsofthissimplersettingbyinvestigating:(1)whichoff-the-shelfretrieverisbestsuitedforlanguagemodeling,(2)thefrequencyofretrievaloperations,and(3)theoptimalquerylength.Inaddition,weboosttheoff-the-shelfretrievalperformancebyintroducingtworerankingmethodsthatdemonstratefurthergainsinperplexity.WebelievethatIn-ContextRALMcanplaytwoimportantrolesinmakingRALMsystemsmorepowerfulandmoreprevalent.First,givenitssimplereadingmechanism,In-ContextRALMcanserveasacleanprobefordevelopingdocumentretrieval\\x0cmethodsthatarespecializedfortheLMtask.TheseinturncanbeusedtoimprovebothIn-ContextRALMandothermoreelaborateRALMmethodsthatcurrentlyleveragegeneralpurposeretrievers.Second,duetoitscompatibilitywithoff-the-shelfLMs,In-ContextRALMcanhelpdrivewiderde-ploymentofRALMsystems.2RelatedWorkRALMapproachescanberoughlydividedintotwofamiliesofmodels:(i)nearest-neighborlanguagemodels(alsocalledkNN-LM),and(ii)retrieveandreadmodels.Ourworkbelongstothesecondfamily,butisdistinctinthatitinvolvesnofurthertrainingoftheLM.NearestNeighborLanguageModelsThekNN-LMapproachwas\\ue000rstintroducedinKhandel-waletal.(2020).Theauthorssuggestasimpleinference-timemodelthatinterpolatesbetweentwonext-tokendistributions:oneinducedbytheLMitself,andoneinducedbythekneighborsfromtheretrievalcorpusthatareclosesttothequerytokenintheLMembeddingspace.Zhongetal.(2022)sug-gestaframeworkfortrainingthesemodels.Whiletheyshowedsigni\\ue000cantgainsfromkNN-LM,theapproachrequiresstoringtherepresentationsforeachtokeninthecorpus,anexpensiverequirementevenforasmallcorpuslikeWikipedia.Althoughnumerousapproacheshavebeensuggestedforal-leviatingthisissue(Heetal.,2021;Alonetal.,2022),scalinganyofthemtolargecorporaremainsanopenchallenge.RetrieveandReadModelsThisfamilyofRALMscreatesacleardivisionbetweendocumentselectionanddocumentreadingcomponents.AllpriorworkinvolvestrainingtheLM.Webeginbydescribingworksthatusethisapproachfortack-lingdownstreamtasks,andthenmentionworksori-entedtowardsRALM.Lewisetal.(2020)andIzac-ardandGrave(2021)\\ue000netunedencoder–decoderarchitecturesfordownstreamknowledge-intensivetasks.Izacardetal.(2022b)exploreddifferentwaysofpretrainingsuchmodels,whileLevineetal.(2022c)pretrainedanautoregressiveLMonclustersofnearestneighborsinsentenceembed-dingspace.Levineetal.(2022a)showedcompeti-tiveopendomainquestion-answeringperformancebyprompt-tuningafrozenLMasareader.Guuetal.(2020)pretrainedREALM,aretrievalaug-mentedbidirectional,maskedLM,later\\ue000ne-tunedforopen-domainquestionanswering.Theworkclosesttothispaper—withafocusonthelanguagemodelingtask—isRETRO(Borgeaudetal.,2022),whichmodi\\ue000esanautoregressiveLMtoattendtorelevantdocumentsviachunkedcross-attention,thusintroducingnewparameterstothemodel.OurIn-ContextRALMdiffersfrompriorworkinthisfamilyofmodelsintwokeyaspects:•Weuseoff-the-shelfLMsfordocumentread-ingwithoutanyfurthertrainingoftheLM.•WefocusonhowtochoosedocumentsforimprovedLMperformance.3OurFramework3.1In-ContextRALMLanguagemodelsde\\ue000neprobabilitydistributionsoversequencesoftokens.Givensuchasequencex1,...,xn,thestandardwaytomodelitsprobabil-ityisvianext-tokenprediction:p(x1,...,xn)=\\ue007ni=1p(xi|x<i),wherex<i:=x1,...,xi−1isthesequenceoftokensprecedingxi,alsoreferredtoasitspre\\ue000x.Thisautoregressivemodelisusu-allyimplementedviaalearnedtransformernet-work(Vaswanietal.,2017)parameterizedbythesetofparametersθ:p(x1,...,xn)=n\\ue009i=1pθ(xi|x<i),(1)wheretheconditionalprobabilitiesaremodeledbyemployingacausalself-attentionmask(Rad-fordetal.,2018).Notably,leadingLMssuchasGPT-2(Radfordetal.,2019),GPT-3(Brownetal.,2020),OPT(Zhangetal.,2022)orJurassic-1(Lieberetal.,2021)followthissimpleparame-terization.Retrievalaugmentedlanguagemodels(RALMs)addanoperationthatretrievesoneormoredocu-mentsfromanexternalcorpusC,andconditiontheaboveLMpredictionsonthesedocuments.Speci\\ue000-cally,forpredictingxi,theretrievaloperationfromCdependsonitspre\\ue000x:RC(x<i),sothemostgeneralRALMdecompositionis:p(x1,...,xn)=\\ue007ni=1p(xi|x<i,RC(x<i)).InordertoconditiontheLMgenerationontheretrieveddocument,pre-viousRALMapproachesusedspecializedarchitec-turesoralgorithms(see§2).Inspiredbythesuc-cessofIn-ContextLearning(Brownetal.,2020;Dongetal.,2023),In-ContextRALMreferstothefollowingspeci\\ue000c,simplemethodofconcatenating\\x0ctheretrieveddocuments2withintheTransformer’sinputpriortothepre\\ue000x(seeFigure2),whichdoesnotinvolvealteringtheLMweightsθ:p(x1,...,xn)=n\\ue009i=1pθ(xi|[RC(x<i);x<i]),(2)where[a;b]denotestheconcatenationofstringsaandb.SincecommonTransformer-basedLMimple-mentationssupportlimitedlengthinputsequences,whentheconcatenationofthedocumentandtheinputsequenceexceedthislimitweremoveto-kensfromthebeginningofxuntiltheoverallinputlengthequalsthatallowedbythemodel.Becauseourretrieveddocumentsarepassagesoflimitedlength,wealwayshaveenoughcontextleftfromx(see§4.3).3.2RALMDesignChoicesWedetailbelowtwopracticaldesignchoicesoftenmadeinRALMsystems.In§5,weinvestigatetheeffectoftheseinthesettingofIn-ContextRALM.RetrievalStrideWhileintheaboveformulationaretrievaloperationcanoccurateachgenerationstep,wemightwanttoperformretrievalonlyonceeverys>1tokensduetothecostofcallingtheretriever,andtheneedtoreplacethedocumentsintheLMpre\\ue000xduringgeneration.Werefertosastheretrievalstride.Thisgivesrisetothefollow-ingIn-ContextRALMformulation(whichreducesbacktoEq.(2)fors=1):p(x1,...,xn)=ns−1\\ue009j=0s\\ue009i=1pθ\\ue000xs·j+i|\\ue002RC(x≤s·j);x<(s·j+i)\\ue003\\ue001,(3)wherens=n/sisthenumberofretrievalstrides.Notably,inthisframeworktheruntimecostsofeachretrievaloperationiscomposedof(a)apply-ingtheretrieveritself,and(b)recomputingtheembeddingsofthepre\\ue000x.In§5.2weshowthatus-ingsmallerretrievalstrides,i.e.,retrievingasoftenaspossible,issuperiortousinglargerones(thoughIn-ContextRALMwithlargerstridesalreadypro-videslargegainsovervanillaLM).Thus,choosingtheretrievalstrideisultimatelyatradeoffbetweenruntimeandperformance.2Wealwaysuseasingledocument,butitisconceptuallysimpletosupportmultipledocumentsaswell.RetrievalQueryLengthWhiletheretrievalqueryaboveinprincipledependsonallpre\\ue000xto-kensx≤s·j,theinformationattheveryendofthepre\\ue000xistypicallythemostrelevanttothegeneratedtokens.Iftheretrievalqueryistoolongthenthisin-formationcanbediluted.Toavoidthis,werestricttheretrievalqueryatstridejtothelastℓtokensofthepre\\ue000x,i.e.,weuseqs,ℓj:=xs·j−ℓ+1,...,xs·j.Werefertoℓastheretrievalquerylength.NotethatpriorRALMworkcouplestheretrievalstridesandtheretrievalquerylengthℓ(Borgeaudetal.,2022).In§5,weshowthatenforcings=ℓdegradesLMperformance.Integratingthesehyper-parametersintotheIn-ContextRALMformulationgivesp(x1,...,xn)=ns−1\\ue009j=0s\\ue009i=1pθ\\ue004xs·j+i|\\ue00aRC(qs,ℓj);x<(s·j+i)\\ue00b\\ue005.(4)4ExperimentalDetailsWenowdescribeourexperimentalsetup,includingallmodelsweuseandtheirimplementationdetails.4.1DatasetsWeevaluatedtheeffectivenessofIn-ContextRALMacross\\ue000vediverselanguagemodelingdatasetsandtwocommonopen-domainquestionansweringdatasets.LanguageModelingThe\\ue000rstLMdatasetisWikiText-103(Merityetal.,2016),whichhasbeenextensivelyusedtoevaluateRALMs(Khandelwaletal.,2020;Heetal.,2021;Borgeaudetal.,2022;Alonetal.,2022;Zhongetal.,2022).Second,wechosethreedatasetsspanningdiversesubjectsfromThePile(Gaoetal.,2021):ArXiv,StackExchangeandFreeLaw.Finally,wealsoinvestigatedReal-News(Zellersetal.,2019),sinceThePilelacksacorpusfocusedonlyonnews(whichisbynatureaknowledge-intensivedomain).Open-DomainQuestionAnsweringInordertoevaluateIn-ContextRALMondownstreamtasksaswell,weusetheNaturalQuestions(NQ;Kwiatkowskietal.2019)andTriviaQA(Joshietal.,2017)open-domainquestionansweringdatasets.4.2ModelsLanguageModelsWeperformedourexperi-mentsusingthefourmodelsofGPT-2(110M–1.5B;Radfordetal.2019),threemodelsofGPT-NeoandGPT-J(1.3B–6B;Blacketal.2021;Wang\\x0candKomatsuzaki2021),eightmodelsofOPT(125M–66B;Zhangetal.2022)andthreemod-elsofLLaMA(7B–33B;Touvronetal.2023).Allmodelsareopensourceandpubliclyavailable.3Weelectedtostudytheseparticularmodelsforthefollowingreasons.The\\ue000rstfour(GPT-2)mod-elsweretrainedonWebText(Radfordetal.,2019),withWikipediadocumentsexcludedfromtheirtrainingdatasets.Wewerethusabletoevaluateourmethod’s“zero-shot”performancewhenretrievingfromanovelcorpus(forWikiText-103).Therestofthemodelsbroughttwofurtherbene\\ue000ts.First,theyallowedustoinvestigatehowourmethodsscaletomodelslargerthanGPT-2.Second,thefactthatWikipediawaspartoftheirtrainingdataallowedustoinvestigatetheusefulnessofIn-ContextRALMforcorporaseenduringtraining.Thehelpfulnessofsuchretrievalhasbeendemonstratedforprevi-ousRALMmethods(Khandelwaletal.,2020)andhasalsobeenjusti\\ue000edtheoreticallybyLevineetal.(2022c).Weranallmodelswithamaximumsequencelengthof1,024,eventhoughGPT-Neo,OPTandLLaMAmodelssupportasequencelengthof2,048.4RetrieversWeexperimentedwithbothsparse(word-based)anddense(neural)retrievers.WeusedBM25(RobertsonandZaragoza,2009)asoursparsemodel.Fordensemodels,weexperimentedwith(i)afrozenBERT-base(Devlinetal.,2019)followedbymeanpooling,similartoBorgeaudetal.(2022);and(ii)theContriever(Izacardetal.,2022a)andSpider(Rametal.,2022)models,whicharedenseretrieversthatweretrainedinun-supervisedmanners.RerankingWhentrainingrerankers(Sec-tion6.2),weinitializedfromRoBERTa-base(Liuetal.,2019).4.3ImplementationDetailsWeimplementedourcodebaseusingtheTrans-formerslibrary(Wolfetal.,2020).WebasedourdenseretrievalcodeontheDPRrepository(Karpukhinetal.,2020).3Allmodelsareavailableforuseuseviahttps://huggingface.co/4Inpreliminaryexperiments,weobservedsimilarimprove-mentsfromIn-ContextRALMwhenusingasequencelengthof2,048.Weusedasequencelengthof1,024inordertofacilitateadirectcomparisonbetweenallmodels.Figure3:Theperformanceoffouroff-the-shelfretrieversusedforIn-ContextRALMonthede-velopmentsetofWikiText-103.AllRALMsarerunwiths=4(i.e.,retrievalisappliedeveryfourtokens).ForeachRALM,wereporttheresultofthebestquerylengthℓ(seeFigures6,9,10).RetrievalCorporaForWikiText-103andODQAdatasets,weusedtheWikipediacorpusfromDec.20,2018,standardizedbyKarpukhinetal.(2020)usingthepreprocessingfromChenetal.(2017).Toavoidcontamination,wefoundandremovedall120articlesofthedevelopmentandtestsetofWikiText-103fromthecorpus.Fortheremainingdatasets,weusedtheirtrainingdataastheretrievalcorpus.SimilartoKarpukhinetal.(2020),ourretrievalcorporaconsistofnon-overlappingpassagesof100words(whichtranslatetolessthan150tokensforthevastmajorityofpassages).Thus,wetruncateourretrievedpassagesat256tokenswheninputtothemodels,buttheyareusuallymuchsmaller.RetrievalForsparseretrieval,weusedthePy-serinilibrary(Linetal.,2021).Fordenseretrieval,weappliedexactsearchusingFAISS(Johnsonetal.,2021).5TheEffectivenessofIn-ContextRALMwithOff-the-ShelfRetrieversWenowempiricallyshowthatdespiteitssimpledocumentreadingmechanism,In-ContextRALMleadstosubstantialLMgainsacrossourdiverseevaluationsuite.Webegininthissectionbyinves-tigatingtheeffectivenessofoff-the-shelfretrieversforIn-ContextRALM;wegoonin§6toshowthatfurtherLMgainscanbemadebytailoringdocumentrankingfunctionstotheLMtask.Theexperimentsinthissectionprovideduswitharecommendedcon\\ue000gurationforapplyingIn-\\x0cModelRetrievalRerankingWikiText-103RealNewsArXivStackExch.FreeLawwordppltokenppltokenppltokenppltokenpplGPT-2S––37.521.312.012.813.0BM25§5–29.616.110.911.39.6BM25Zero-shot§6.128.615.510.110.68.8BM25Predictive§6.226.8––––GPT-2M––26.315.79.38.89.6BM25§5–21.512.48.68.17.4BM25Zero-shot§6.120.812.08.07.76.9BM25Predictive§6.219.7––––GPT-2L––22.013.68.48.58.7BM25§5–18.110.97.87.86.8BM25Zero-shot§6.117.610.67.37.46.4BM25Predictive§6.216.6––––GPT-2XL––20.012.47.88.08.0BM25§5–16.610.17.27.46.4BM25Zero-shot§6.116.19.86.87.16.0BM25Predictive§6.215.4––––Table1:PerplexityonthetestsetofWikiText-103,RealNewsandthreedatasetsfromthePile.ForeachLM,wereport:(a)itsperformancewithoutretrieval,(b)itsperformancewhenfedthetop-scoredpassagebyBM25(§5),and(c)itsperformancewhenappliedonthetop-scoredpassageofeachofourtwosuggestedrerankers(§6).Allmodelssharethesamevocabulary,thustoken-levelperplexity(tokenppl)numbersarecomparable.ForWikiTextwefollowpriorworkandreportword-levelperplexity(wordppl).ModelRetrievalWikiText-103wordpplLLaMA-7B-9.9BM25,§58.8LLaMA-13B-8.5BM25,§57.6LLaMA-33B-6.3BM25,§56.1Table2:TheperformanceofmodelsfromtheLLaMAfamily,measuredbyword-levelperplexityonthetestsetofWikiText-103.ContextRALM:applyingasparseBM25retrieverthatreceivesℓ=32querytokensandisappliedasfrequentlyaspossible.Practically,weretrieveeverys=4tokens(ℓandsarede\\ue000nedin§3).Table1showsfortheGPT-2modelsthatacrossalltheexaminedcorpora,employingIn-ContextRALMwithanoff-the-shelfretrieverimprovedLMperplexitytoasuf\\ue000cientextentthatitmatchedthatofa2–3×largermodel.Figure4andTables2and5showthatthistrendholdsacrossmodelsizesupto66Bparameters,forbothWikiText-103andRealNews.5.1BM25OutperformsOff-the-ShelfNeuralRetrieversinLanguageModelingWeexperimentedwithdifferentoff-the-shelfgen-eralpurposeretrievers,andfoundthatthesparse(lexical)BM25retriever(RobertsonandZaragoza,2009)outperformedthreepopulardense(neu-ral)retrievers:theself-supervisedretrieversCon-triever(Izacardetal.,2022a)andSpider(Rametal.,2022),aswellasaretrieverbasedontheaveragepoolingofBERTembeddingsthatwasusedintheRETROsystem(Borgeaudetal.,2022).Weconductedaminimalhyper-parametersearchonthequerylengthℓforeachoftheretrievers,andfoundthatℓ=32wasoptimalforBM25(Fig-ure6),andℓ=64workedbestfordenseretrievers(Figures9,10).Figure3comparestheperformancegainsofIn-ContextRALMwiththesefourgeneral-purposere-trievers.TheBM25retrieverclearlyoutperformedalldenseretrievers.ThisoutcomeisconsistentwithpriorworkshowingthatBM25outperformsneuralretrieversacrossawidearrayoftasks,whenappliedinzero-shotsettings(Thakuretal.,2021).ThisresultrendersIn-ContextRALMevenmore\\x0cFigure4:ResultsofOPTmodels(Zhangetal.,2022)onthetestsetofWikiText-103(word-levelperplexity)andthedevelopmentsetofRealNews(token-levelperplexity).In-ContextRALMmodelsuseaBM25retrieverwiths=4(i.e.,theretrieveriscalledeveryfourtokens)andℓ=32(i.e.,theretrieverqueryiscomprisedofthelast32tokensofthepre\\ue000x).In-ContextRALMwithanoff-the-shelfretrieverimprovedtheperformanceofa6.7BparameterOPTmodeltomatchthatofa66BparameterOPTmodel.appealingsinceapplyingaBM25retrieverissig-ni\\ue000cantlycheaperthantheneuralalternatives.5.2FrequentRetrievalImprovesLanguageModelingWeinvestigatedtheeffectofvaryingtheretrievalstrides(i.e.,thenumberoftokensbetweenconsec-utiveretrievaloperations).Figure5showsthatLMperformanceimprovedastheretrievaloperationbecamemorefrequent.Thissupportstheintuitionthatretrieveddocumentsbecomemorerelevanttheclosertheretrievalquerybecomestothegener-atedtokens.Ofcourse,eachretrievaloperationimposesaruntimecost.Tobalanceperformanceandruntime,weuseds=4inourexperiments.Forcomparison,RETROemployedaretrievalfre-quencyofs=64(Borgeaudetal.,2022),whichleadstolargedegradationinperplexity.Intuitively,retrievingwithhighfrequency(lowretrievalstride)allowstogroundtheLMinhigherresolution.5.3AContextualizationvs.RecencyTradeoffinQueryLengthWealsoinvestigatedtheeffectofvaryingℓ,thelengthoftheretrievalqueryforBM25.Figure6revealsaninterestingtradeoffandasweetspotaroundaquerylengthof32tokens.Similarex-perimentsfordenseretrieversaregiveninApp.A.Weconjecturethatwhentheretrieverqueryistooshort,itdoesnotincludeenoughoftheinputcon-text,decreasingtheretrieveddocument’srelevance.Conversely,excessivelygrowingtheretrieverquerydeemphasizesthetokensattheveryendofthepre-\\ue000x,dilutingthequery’srelevancetotheLMtask.6ImprovingIn-ContextRALMwithLM-OrientedRerankingSinceIn-ContextRALMusesa\\ue000xeddocumentreadingcomponentbyde\\ue000nition,itisnaturaltoaskwhetherperformancecanbeimprovedbyspe-cializingitsdocumentretrievalmechanismtotheLMtask.Indeed,thereisconsiderablescopeforimprovement:theprevioussectionconsideredcon-ditioningthemodelonlyonthe\\ue000rstdocumentre-\\x0cFigure5:Ananalysisofperplexityasafunctionofs,theretrievalstride,i.e.,thenumberoftokensbetweenconsecutiveretrievaloperations,onthedevelopmentsetofWikiText-103.Throughoutthepaper,weuses=4tobalanceperplexityandruntime.Figure6:AnanalysisofperplexityasafunctionofthenumberoftokensinthequeryℓforBM25onthedevelopmentsetofWikiText-103.Intheappendix,weshowsimilartrade-offsfordenseretrieverswithinWikiText-103.Throughoutthepaper,weuseaquerylengthofℓ=32tokens.trievedbytheBM25retriever.Thispermitsverylimitedsemanticunderstandingofthequery,sinceBM25isbasedonlyonthebagofwordssignal.Moreover,itoffersnowaytoaccorddifferentde-greesofimportancetodifferentretrievalqueryto-kens,suchasrecognizingthatlaterquerytokensaremorerelevanttothegeneratedtext.Inthissection,wefocusonchoosingwhichdoc-umenttopresenttothemodel,byrerankingthetop-kdocumentsreturnedbytheBM25retriever.5WeuseFigure7asmotivation:itshowsthelargepotentialforimprovementamongthetop-16docu-mentsreturnedbytheBM25retriever.Weactupon5Inboth§6.1and§6.2weusek=16.Figure7:Potentialforgainsfromreranking:per-plexityimprovement(onthedevelopmentsetofWikiText-103)fromanoraclethattakesthebestofthetop-16documentsretrievedbyBM25ratherthanthe\\ue000rst.thismotivationbyusingtworerankers.Speci\\ue000-cally,in§6.1weshowperformancegainsacrossourevaluationsuiteobtainedbyusinganLMtoperformzero-shotrerankingofthetop-kBM25retrieveddocuments(resultsinthirdrowforeachofthemodelsinTable1).Then,in§6.2weshowthattrainingaspecializedbidirectionalrerankerofthetop-kBM25retrieveddocumentsinaself-supervisedmannerviatheLMsignalcanprovidefurtherLMgains(resultsinforthrowforeachofthemodelsinTable1).6.1LMsasZero-ShotRerankersFirst,weusedoff-the-shelflanguagemodelsasdocumentrerankersfortheIn-ContextRALMset-ting.Formally,foraqueryqconsistingofthelastℓtokensinthepre\\ue000xoftheLMinputx,let{d1,...,dk}bethetop-kdocumentsreturnedbyBM25.Forretrievaliterationj,letthetextforgenerationbey:=xs·j+1,...,xs·j+s.Ideally,wewouldliketo\\ue000ndthedocumentdi∗thatmaximizestheprobabilityofthetextforgeneration,i.e.,i∗=argmaxi∈[k]pθ(y|[di;x≤s·j]).(5)However,attesttimewedonothaveaccesstothetokensofy.Instead,weusedthelastpre-\\ue000xtokens(whichareavailableattesttime),de-notedbyy′,forreranking.Formally,lets′beahyper-parameterthatdeterminesthenumberofthepre\\ue000xtokensbywhichtorerank.Wede\\ue000ney′:=xs·j−s′+1,...,xs·j(i.e.,thestrideoflengths′thatprecedesy)andchoosethedocumentdˆisuch\\x0cModelRerankingModelWikiText-103RealNewswordppltokenpplGPT-2345M(M)GPT-2110M(S)20.812.1GPT-2345M(M)20.812.0GPT-2762M(L)GPT-2110M(S)17.710.7GPT-2762M(L)17.610.6GPT-21.5B(XL)GPT-2110M(S)16.29.9GPT-21.5B(XL)16.19.8Table3:Perplexityforzero-shotreranking(§6.1)wherethererankingmodelsissmallerthantheLM,ortheLMitself.Rerankingisperformedonthetop16documentsretrievedbyBM25.UsingaGPT-2110M(S)insteadofalargerlanguagemodelasarerankerleadstoonlyaminordegradation.thatˆi=argmaxi∈[k]pϕ(y′|\\ue002di;x≤(s·j−s′)\\ue003).(6)ThemainmotivationisthatsinceBM25isalexicalretriever,wewanttoincorporateasemanticsignalinducedbytheLM.Also,thisrerankingsharescon-ceptualsimilaritieswiththererankingframeworkofSachanetal.(2022)foropen-domainquestionanswering,wherey′(i.e.,thelastpre\\ue000xtokens)canbethoughtofastheir“question”.Notethatourzero-shotrerankingdoesnotre-quirethattheLMusedforrerankingisthesamemodelastheLMusedforgeneration(i.e.,theLMinEq.(6),parameterizedbyϕ,doesnotneedtobetheLMinEq.(2),parameterizedbyθ).Thisob-servationunlocksthepossibilityofrerankingwithsmaller(andthusfaster)models,whichisimpor-tantfortwomainreasons:(i)Rerankingkdocu-mentsrequireskforwardpasses;and(ii)itallowsourmethodstobeusedincaseswheretheactualLM’slogprobabilitiesarenotavailable(forexam-ple,whentheLMisaccessedthroughanAPI).6ResultsAminimalhyper-parametersearchonthedevelopmentsetofWikiText-103revealedthattheoptimalquerylengthiss′=16,7soweproceedwiththisvaluegoingforward.Table1showstheresultsoflettingtheLMperformzero-shotrerank-ingonthetop-16documentsretrievedbyBM25(thirdrowforeachofthemodels).Itisevidentthatrerankingyieldedconsistentlybetterresultsthansimplytakingthe\\ue000rstresultreturnedbytheretriever.6Notewedonotrequirethatthetwomodelssharethesamevocabulary.7Weexperimentedwiths′∈{4,8,16,32}.Table3showsthatasmallLM(GPT-2117M)canbeusedtorerankthedocumentsforalllargerGPT-2models,withroughlythesameperformanceashavingeachLMperformrerankingforitself,supportingtheapplicabilityofthismethodforLMsthatareonlyaccessibleviaanAPI.6.2TrainingLM-dedicatedRerankersNext,wetrainedarerankertochooseoneofthetop-kdocumentsretrievedbyBM25.WerefertothisapproachasPredictiveReranking,sincethererankerlearnstochoosewhichdocumentwillhelpin“predicting”theupcomingtext.Forthisprocess,weassumeavailabilityoftrainingdatafromthetargetcorpus.Ourrerankerisaclassi\\ue000erthatgetsapre\\ue000xx≤s·jandadocumentdi(fori∈[k]),andproducesascalarf(x≤s·j,di)thatshouldresembletherelevanceofdiforthecontinuationofx≤s·j.Wethennormalizetheserelevancescores:prank(di|x≤s·j)=exp(f(x≤s·j,di))\\ue006ki′=1exp(f(x≤s·j,di′)),(7)andchoosethedocumentdˆisuchthatˆi=argmaxi∈[k]prank(di|x≤s·j).(8)CollectingTrainingExamplesTotrainourpre-dictivereranker,wecollectedtrainingexamplesasfollows.Letx≤s·jbeapre\\ue000xwesamplefromthetrainingdata,andy:=xs·j+1,...,xs·j+sbethetextforgenerationupcominginitsnextstride.WerunBM25onthequeryqs,ℓjderivedfromx≤s·j(see§3.2)andgetkdocuments{d1,...,dk}.Foreachdocumentdi,wethenruntheLMtocomputepθ(y|[di;x≤s·j])similartoEq.(4).\\x0cFigure8:Zero-shotperformanceofIn-ContextRALMonthedevelopmentsetofNaturalQues-tionsandTriviaQA,whenvaryingthenumberofdocuments(retrievedbyDPR)shownin-context.TrainingOurrerankerwasa\\ue000ne-tunedRoBERTa-base(Liuetal.,2019)thattrainedfor10,000stepswithapeaklearningrateof10−5andabatchsizeof32.Overall,wecreated300,000examplesfromthetrainingsetofWikiText-103asexplainedabove.Thelossfunctionweusetotrainthererankerfollowspreviouswork(Guuetal.,2020;Lewisetal.,2020):−logk\\ue008i=1prank(di|x≤s·j)·pθ(y|[di;x≤s·j]).(9)Notethatunlikethoseworks,wetrainonlythereranker(prank),keepingtheLMweightsθfrozen.ResultsTable1showstheresultofourpredictivereranker,trainedonWikiText-103.Speci\\ue000cally,wetraineditwithdataproducedbyGPT-2110M(S),andtesteditseffectivenessforallGPT-2models.Weobservedsigni\\ue000cantgainsobtainedfromPredic-tiveReranking.Forexample,theperplexityofGPT-2110M(S)improvedfrom29.6to26.8,andthatofGPT-21.5B(XL)improvedfrom16.6to15.4.Thistrendheldfortheothertwomodelsaswell.Overall,theseresultsdemonstratethattrainingarerankerwithdomain-speci\\ue000cdatawasmoreeffectivethanzero-shotreranking(Section6.1).Notethattheseresults—whileimpressive—stillleaveroomforfur-therimprovements,comparedtothetop-16BM25oracleresults(seeFigure7).Moreover,theoracleresultsthemselvescanbeimprovedbyretrievingk>16documentsviaaBM25retriever,orbytrainingstrongerretrieversdedicatedtotheRALMtask.Weleavethisdirectionforfuturework.ModelRetrievalNQTriviaQALLaMA-7B-10.347.5DPR28.056.0LLaMA-13B-12.054.8DPR31.060.1LLaMA-33B-13.758.3DPR32.362.7Table4:Zero-shotresultsofIn-ContextRALMonthetestsetofNaturalQuestionsandTriviaQAmea-suredbyexactmatch.Intheopen-booksetting,weincludethetoptwodocumentsreturnedbyDPR.7In-ContextRALMforOpen-DomainQuestionAnsweringSofar,weevaluatedourframeworkonlanguagemodelingbenchmarks.Totestitsef\\ue000cacyinaddi-tionalscenarios,andspeci\\ue000callydownstreamtasks,wenowturntoevaluateIn-ContextRALMonopen-domainquestionanswering(ODQA;Chenetal.2017).Thisexperimentisintendedtoverify,inacontrolledenvironment,thatLMscanleverageretrieveddocumentswithoutfurthertrainingandwithoutanytrainingexamples.Speci\\ue000cally,weusetheLLaMAfamily(Touvronetal.,2023)withandwithoutIn-ContextRALM(oftenreferredtoinODQAliteratureasopen-bookandclosed-booksettings,respectively).IncontrasttomostpriorworkonODQA(e.g.,IzacardandGrave2021;Fa-jciketal.2021;Izacardetal.2022b;Levineetal.2022b),our“reader”(i.e.,themodelthatgetsthequestionalongwithitscorrespondingretrieveddoc-uments,andreturnstheanswer)issimplyafrozenlargeLM:notpretrained,\\ue000ne-tunedorpromptedtoberetrieval-augmented.Fortheclosed-bookset-ting,weutilizethepromptofTouvronetal.(2023).Fortheopen-booksetting,weextendthisprompttoincluderetrieveddocuments(seeApp.C).WeuseDPR(Karpukhinetal.,2020)asourretriever.VaryingtheNumberofDocumentsToinves-tigatethetheeffectofthenumberofdocumentsshowntothemodel,weperformedaminimalanal-ysisonthedevelopmentsetofNQandTriviaQA.Figure8demonstratesthatshowingdocumentsin-contextsigni\\ue000cantlyimprovesthemodel’sperfor-mance.Inaddition,mostofthegaincanbeob-tainedbyusingonlytwodocuments(orevenasingleoneinsomecases).\\x0cResultsTable4givestheresultsofIn-ContextRALMonthetestsetofNaturalQuestionsandTriviaQA.Motivatedbyourprevious\\ue000ndings,weusedtworetrieveddocuments.Itisevidentthatshowingthemodelrelevantdocumentssig-ni\\ue000cantlyboosteditsperformance.Forexample,addingretrieveddocumentsimprovedLLaMA-13Binthezero-shotsettingbymorethan18pointsonNQ(from12.0%to31.0%)andmorethan5pointsonTriviaQA(from54.8%to60.1%).8DiscussionRetrievalfromexternalsourceshasbecomeacom-monpracticeinknowledge-intensivetasks(suchasfactualquestionanswering,factchecking,andmore;Petronietal.2021).Inparallel,recentbreak-throughsinLMgenerationcapabilitieshasledtoLMsthatcangenerateusefullongtexts.How-ever,factualinaccuraciesremainacommonwayinwhichmachine-generatedtextcanfallshort,andlackofdirectprovenancemakesithardtotrustmachinegeneratedtext.Thismakeslanguagemod-elingbothapromisingandanurgentnewapplica-tionareaforknowledgegrounding,andmotivatespromotingRALMapproaches.PriorresearchhasalreadyinvestigatedRALM,ofcourse,butitisnotyetwidelydeployed.Onelikelyreasonisthatexistingapproachesrelyupon\\ue000ne-tuningtheLM,whichistypicallydif\\ue000cultandcostly,andisevenimpossibleforLMsaccessibleonlyviaanAPI.ThispaperpresentedtheframeworkofIn-ContextRALM,enablingfrozen,off-the-shelfLMstobene\\ue000tfromretrieval.Wedemonstratedthatsubstantialperformancegainscanbeachievedbyusinggeneralpurposeretrievers,andshowedthatadditionalgainscanbeachievedbytailoringthedocumentselectiontotheLMsetting.ArecentworkbyMuhlgayetal.(2023)demonstratesthatIn-ContextRALMisindeedabletoimprovethefactualityoflargeLMs.Severaldirectionsforfurtherimprovementre-mainforfuturework.First,thispaperconsidersonlythecaseofprependingasingleexternaldocu-menttothecontext;addingmoredocumentscoulddrivefurthergains(forexample,usingtheframe-workofRatneretal.2022).Second,weretrieveddocumentsevery\\ue000xedintervalofstokens,butseepotentialforlargelatencyandcostgainsbyretriev-ingmoresparsely,suchasonlywhenaspecializedmodelpredictsthatretrievalisneeded.Wereleasethecodeusedinthiswork,forthecommunitytouseandimproveover.WehopeitwilldrivefurtherresearchofRALM,whichwillenableitswideradoption.AcknowledgementsWewouldliketothankthereviewersandtheAc-tionEditorfortheirvaluablefeedback.ReferencesUriAlon,FrankXu,JunxianHe,SudiptaSengupta,DanRoth,andGrahamNeubig.2022.Neuro-symboliclanguagemodelingwithautomaton-augmentedretrieval.InICML.SidBlack,LeoGao,PhilWang,ConnorLeahy,andStellaBiderman.2021.GPT-Neo:LargeScaleAutoregressiveLanguageModelingwithMesh-Tensor\\ue001ow.SebastianBorgeaud,ArthurMensch,JordanHoff-mann,TrevorCai,ElizaRutherford,KatieMil-lican,GeorgeBmVanDenDriessche,Jean-BaptisteLespiau,BogdanDamoc,AidanClark,DiegoDeLasCasas,AureliaGuy,JacobMenick,RomanRing,TomHennigan,SaffronHuang,LorenMaggiore,ChrisJones,AlbinCassirer,AndyBrock,MichelaPaganini,GeoffreyIrv-ing,OriolVinyals,SimonOsindero,KarenSi-monyan,JackRae,ErichElsen,andLaurentSifre.2022.Improvinglanguagemodelsbyre-trievingfromtrillionsoftokens.InICML.TomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhari-wal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielZiegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,andDarioAmodei.2020.Languagemodelsarefew-shotlearners.InAdvancesinNeuralInformationProcessingSystems.DanqiChen,AdamFisch,JasonWeston,andAn-toineBordes.2017.ReadingWikipediatoan-sweropen-domainquestions.InProceedingsofthe55thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:Long\\x0cPapers),pages1870–1879,Vancouver,Canada.AssociationforComputationalLinguistics.JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2019.BERT:Pre-trainingofdeepbidirectionaltransformersforlanguageunderstanding.InProceedingsofthe2019Con-ferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,Volume1(LongandShortPapers),pages4171–4186,Minneapo-lis,Minnesota.AssociationforComputationalLinguistics.QingxiuDong,LeiLi,DamaiDai,CeZheng,Zhiy-ongWu,BaobaoChang,XuSun,JingjingXu,LeiLi,andZhifangSui.2023.Asurveyonin-contextlearning.MartinFajcik,MartinDocekal,KarelOndrej,andPavelSmrz.2021.R2-D2:Amodularbaselineforopen-domainquestionanswering.InFind-ingsoftheAssociationforComputationalLin-guistics:EMNLP2021,pages854–870,PuntaCana,DominicanRepublic.AssociationforComputationalLinguistics.LeoGao,StellaBiderman,SidBlack,LaurenceGolding,TravisHoppe,CharlesFoster,JasonPhang,HoraceHe,AnishThite,NoaNabeshima,ShawnPresser,andConnorLeahy.2021.Thepile:An800gbdatasetofdiversetextforlan-guagemodeling.KelvinGuu,KentonLee,ZoraTung,PanupongPasupat,andMing-WeiChang.2020.REALM:Retrieval-augmentedlanguagemodelpre-training.InICML.JunxianHe,GrahamNeubig,andTaylorBerg-Kirkpatrick.2021.Ef\\ue000cientnearestneighborlanguagemodels.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages5703–5714,OnlineandPuntaCana,DominicanRepublic.Associa-tionforComputationalLinguistics.MinlieHuang,XiaoyanZhu,andJianfengGao.2020.Challengesinbuildingintelligentopen-domaindialogsystems.ACMTrans.Inf.Syst.,38(3).GautierIzacard,MathildeCaron,LucasHosseini,SebastianRiedel,PiotrBojanowski,ArmandJoulin,andEdouardGrave.2022a.Unsu-perviseddenseinformationretrievalwithcon-trastivelearning.TransactionsonMachineLearningResearch.GautierIzacardandEdouardGrave.2021.Lever-agingpassageretrievalwithgenerativemodelsforopendomainquestionanswering.InPro-ceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputationalLinguistics:MainVolume,pages874–880,On-line.AssociationforComputationalLinguistics.GautierIzacard,PatrickLewis,MariaLomeli,Lu-casHosseini,FabioPetroni,TimoSchick,JaneDwivedi-Yu,ArmandJoulin,SebastianRiedel,andEdouardGrave.2022b.Atlas:Few-shotlearningwithretrievalaugmentedlanguagemod-els.JeffJohnson,MatthijsDouze,andHervéJégou.2021.Billion-scalesimilaritysearchwithGPUs.IEEETransactionsonBigData,7(3):535–547.MandarJoshi,EunsolChoi,DanielWeld,andLukeZettlemoyer.2017.TriviaQA:Alargescaledistantlysupervisedchallengedatasetforread-ingcomprehension.InProceedingsofthe55thAnnualMeetingoftheAssociationforCompu-tationalLinguistics(Volume1:LongPapers),pages1601–1611,Vancouver,Canada.Associa-tionforComputationalLinguistics.VladimirKarpukhin,BarlasOguz,SewonMin,PatrickLewis,LedellWu,SergeyEdunov,DanqiChen,andWen-tauYih.2020.Densepassagere-trievalforopen-domainquestionanswering.InProceedingsofthe2020ConferenceonEmpir-icalMethodsinNaturalLanguageProcessing(EMNLP),pages6769–6781,Online.Associa-tionforComputationalLinguistics.UrvashiKhandelwal,OmerLevy,DanJuraf-sky,LukeZettlemoyer,andMikeLewis.2020.Generalizationthroughmemorization:Nearestneighborlanguagemodels.InInternationalConferenceonLearningRepresentations.TomKwiatkowski,JennimariaPalomaki,OliviaRed\\ue000eld,MichaelCollins,AnkurParikh,ChrisAlberti,DanielleEpstein,IlliaPolosukhin,JacobDevlin,KentonLee,KristinaToutanova,LlionJones,MatthewKelcey,Ming-WeiChang,An-drewM.Dai,JakobUszkoreit,QuocLe,and\\x0cSlavPetrov.2019.Naturalquestions:Abench-markforquestionansweringresearch.Trans-actionsoftheAssociationforComputationalLinguistics,7:452–466.YoavLevine,ItayDalmedigos,OriRam,YoelZeldes,DanielJannai,DorMuhlgay,YoniOsin,OpherLieber,BarakLenz,ShaiShalev-Shwartz,AmnonShashua,KevinLeyton-Brown,andYoavShoham.2022a.Standingontheshoul-dersofgiantfrozenlanguagemodels.YoavLevine,OriRam,DanielJannai,BarakLenz,ShaiShalev-Shwartz,AmnonShashua,KevinLeyton-Brown,andYoavShoham.2022b.Hugefrozenlanguagemodelsasreadersforopen-domainquestionanswering.InICML2022WorkshoponKnowledgeRetrievalandLan-guageModels.YoavLevine,NoamWies,DanielJannai,DanNavon,YedidHoshen,andAmnonShashua.2022c.Theinductivebiasofin-contextlearn-ing:Rethinkingpretrainingexampledesign.InInternationalConferenceonLearningRepresen-tations.PatrickLewis,EthanPerez,AleksandraPiktus,FabioPetroni,VladimirKarpukhin,NamanGoyal,HeinrichKüttler,MikeLewis,Wen-tauYih,TimRocktäschel,SebastianRiedel,andDouweKiela.2020.Retrieval-augmentedgen-erationforknowledge-intensivenlptasks.InAdvancesinNeuralInformationProcessingSys-tems,pages9459–9474.ZonglinLi,RuiqiGuo,andSanjivKumar.2022.Decoupledcontextprocessingforcontextaug-mentedlanguagemodeling.InAdvancesinNeu-ralInformationProcessingSystems.OpherLieber,OrSharir,BarakLenz,andYoavShoham.2021.Jurassic-1:Technicaldetailsandevaluation.JimmyLin,XueguangMa,Sheng-ChiehLin,Jheng-HongYang,RonakPradeep,andRodrigoNogueira.2021.Pyserini:Apythontoolkitforreproducibleinformationretrievalresearchwithsparseanddenserepresentations.InProceed-ingsofthe44thInternationalACMSIGIRCon-ferenceonResearchandDevelopmentinInfor-mationRetrieval,SIGIR’21,page2356–2362,NewYork,NY,USA.AssociationforComput-ingMachinery.StephanieLin,JacobHilton,andOwainEvans.2022.TruthfulQA:Measuringhowmodelsmimichumanfalsehoods.InProceedingsofthe60thAnnualMeetingoftheAssociationforCom-putationalLinguistics(Volume1:LongPapers),pages3214–3252,Dublin,Ireland.AssociationforComputationalLinguistics.YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,MandarJoshi,DanqiChen,OmerLevy,MikeLewis,LukeZettlemoyer,andVeselinStoyanov.2019.RoBERTa:Arobustlyoptimizedbertpretrainingapproach.JoshuaMaynez,ShashiNarayan,BerndBohnet,andRyanMcDonald.2020.Onfaithfulnessandfactualityinabstractivesummarization.InPro-ceedingsofthe58thAnnualMeetingoftheAs-sociationforComputationalLinguistics,pages1906–1919,Online.AssociationforComputa-tionalLinguistics.StephenMerity,CaimingXiong,JamesBradbury,andRichardSocher.2016.Pointersentinelmix-turemodels.DorMuhlgay,OriRam,InbalMagar,YoavLevine,NirRatner,YonatanBelinkov,OmriAbend,KevinLeyton-Brown,AmnonShashua,andYoavShoham.2023.Generatingbenchmarksforfactualityevaluationoflanguagemodels.FabioPetroni,AleksandraPiktus,AngelaFan,PatrickLewis,MajidYazdani,NicolaDeCao,JamesThorne,YacineJernite,VladimirKarpukhin,JeanMaillard,VassilisPlachouras,TimRocktäschel,andSebastianRiedel.2021.KILT:abenchmarkforknowledgeintensivelan-guagetasks.InProceedingsofthe2021Con-ferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu-manLanguageTechnologies,pages2523–2544,Online.AssociationforComputationalLinguis-tics.AlecRadford,KarthikNarasimhan,TimSalimans,andIlyaSutskever.2018.Improvinglanguageunderstandingbygenerativepre-training.AlecRadford,JeffWu,RewonChild,DavidLuan,DarioAmodei,andIlyaSutskever.2019.Lan-guagemodelsareunsupervisedmultitasklearn-ers.\\x0cOriRam,GalShachaf,OmerLevy,JonathanBe-rant,andAmirGloberson.2022.Learningtore-trievepassageswithoutsupervision.InProceed-ingsofthe2022ConferenceoftheNorthAmer-icanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnolo-gies,pages2687–2700,Seattle,UnitedStates.AssociationforComputationalLinguistics.NirRatner,YoavLevine,YonatanBelinkov,OriRam,OmriAbend,EhudKarpas,Am-nonShashua,KevinLeyton-Brown,andYoavShoham.2022.Parallelcontextwindowsim-provein-contextlearningoflargelanguagemod-els.StephenRobertsonandHugoZaragoza.2009.Theprobabilisticrelevanceframework:BM25andbeyond.Found.TrendsInf.Retr.,3(4):333–389.DevendraSachan,MikeLewis,MandarJoshi,Ar-menAghajanyan,Wen-tauYih,JoellePineau,andLukeZettlemoyer.2022.Improvingpassageretrievalwithzero-shotquestiongeneration.InProceedingsofthe2022ConferenceonEmpir-icalMethodsinNaturalLanguageProcessing,pages3781–3797,AbuDhabi,UnitedArabEmi-rates.AssociationforComputationalLinguis-tics.WeijiaShi,SewonMin,MichihiroYasunaga,Min-joonSeo,RichJames,MikeLewis,LukeZettle-moyer,andWentauYih.2023.REPLUG:Retrieval-augmentedblack-boxlanguagemod-els.NandanThakur,NilsReimers,AndreasRücklé,AbhishekSrivastava,andIrynaGurevych.2021.BEIR:Aheterogeneousbenchmarkforzero-shotevaluationofinformationretrievalmodels.InProceedingsoftheNeuralInformationProcess-ingSystemsTrackonDatasetsandBenchmarks,volume1.HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timo-théeLacroix,BaptisteRozière,NamanGoyal,EricHambro,FaisalAzhar,AurelienRodriguez,ArmandJoulin,EdouardGrave,andGuillaumeLample.2023.LLaMA:Openandef\\ue000cientfoun-dationlanguagemodels.AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanGomez,ŁukaszKaiser,andIlliaPolosukhin.2017.At-tentionisallyouneed.InAdvancesinNeuralInformationProcessingSystems30,pages5998–6008.BenWangandAranKomatsuzaki.2021.GPT-J-6B:A6BillionParameterAutoregressiveLan-guageModel.ThomasWolf,LysandreDebut,VictorSanh,JulienChaumond,ClementDelangue,AnthonyMoi,PierricCistac,TimRault,RemiLouf,MorganFuntowicz,JoeDavison,SamShleifer,PatrickvonPlaten,ClaraMa,YacineJernite,JulienPlu,CanwenXu,TevenLeScao,SylvainGugger,MariamaDrame,QuentinLhoest,andAlexan-derRush.2020.Transformers:State-of-the-artnaturallanguageprocessing.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing:SystemDemon-strations,pages38–45,Online.AssociationforComputationalLinguistics.RowanZellers,AriHoltzman,HannahRashkin,YonatanBisk,AliFarhadi,FranziskaRoesner,andYejinChoi.2019.Defendingagainstneuralfakenews.InAdvancesinNeuralInformationProcessingSystems,volume32.CurranAsso-ciates,Inc.SusanZhang,StephenRoller,NamanGoyal,MikelArtetxe,MoyaChen,ShuohuiChen,ChristopherDewan,MonaDiab,XianLi,XiVictoriaLin,TodorMihaylov,MyleOtt,SamShleifer,KurtShuster,DanielSimig,PunitSinghKoura,An-jaliSridhar,TianluWang,andLukeZettlemoyer.2022.OPT:Openpre-trainedtransformerlan-guagemodels.ZexuanZhong,TaoLei,andDanqiChen.2022.Traininglanguagemodelswithmemoryaugmen-tation.InProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguagePro-cessing,pages5657–5673,AbuDhabi,UnitedArabEmirates.AssociationforComputationalLinguistics.AQueryLengthAblationsFigure9andFigure10showablationsontheopti-malquerylengthℓforoff-the-shelfdenseretrievers(BERTandContrieverrespectively).WeomittheresultsofSpiderastheyarealmostidenticaltothoseofContriever.Consistently,usingℓ=64\\x0c(tokens)isoptimal.ThisisincontrasttosimilarexperimentsweconductedforBM25(cf.Figure6),whereℓ=32isoptimal.BGPT-NeoResultsTable5givestheresultsofapplyingIn-ContextRALMtothemodelsfromtheGPT-NeomodelfamilyonWikiText-103andRealNews.COpen-DomainQuestionAnsweringExperiments:FurtherDetailsClosed-BookSettingFortheclosed-bookset-ting,weadoptthepromptofTouvronetal.(2023):Answerthesequestions:Q:Whogotthefirstnobelprizeinphysics?A:Open-BookSettingFortheopen-booksetting,weextendtheabovepromptasfollows:NobelPrizeAgroupincluding42Swedishwriters,artists,andliterarycriticsprotestedagainstthisdecision,havingexpectedLeoTolstoytobeawarded.Some,includingBurtonFeldman,havecriticisedthisprizebecausethey...NobelPrizeinPhysiologyorMedicineInthelasthalfcenturytherehasbeenanincreasingtendencyforscientiststoworkasteams,resultingincontroversialexclusions.AlfredNobelwasbornon21October1833inStockholm,Sweden,intoafamilyofengineers...Basedonthesetexts,answerthesequestions:Q:Whogotthefirstnobelprizeinphysics?A:ModelRetrievalWiki-103RealNewswordppltokenpplGPT-Neo1.3B-17.512.3BM25,§514.69.9GPT-Neo2.7B-15.111.0BM25,§512.89.0GPT-J6B-11.69.2BM25,§510.07.7Table5:TheperformanceofmodelsfromtheGPT-Neofamily,measuredbyword-levelperplexityonthetestsetofWikiText-103andtoken-levelper-plexityonthedevelopmentsetofRealNews.Figure9:Ananalysisofperplexityasafunctionofthenumberoftokensinthequeryforanoff-the-shelfBERTretrieveronthedevelopmentsetofWikiText-103.Figure10:AnanalysisofperplexityasafunctionofthenumberoftokensinthequeryforContrieveronthedevelopmentsetofWikiText-103.\\x0c', metadata={'source': '/content/drive/MyDrive/PdfRag/clusterofstars/InContextRALM.pdf'})]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "reader = PdfReader(os.path.expanduser(PDFS[0]))\n",
        "pages = reader.pages\n",
        "documents = []\n",
        "for page in pages:\n",
        "  documents.append(page.extract_text())\n",
        "print(documents[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MFUNfTF86nL",
        "outputId": "280fcbf6-0b59-4c6d-f303-b97ea25e65ff"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tokens) is optimal. This is in contrast to similar\n",
            "experiments we conducted for BM25 (cf. Figure 6),\n",
            "whereℓ= 32is optimal.\n",
            "B GPT-Neo Results\n",
            "Table 5gives the results of applying In-Context\n",
            "RALM to the models from the GPT-Neo model\n",
            "family on WikiText-103 and RealNews.\n",
            "C Open-Domain Question Answering\n",
            "Experiments: Further Details\n",
            "Closed-Book SettingFor the closed-book set-\n",
            "ting, we adopt the prompt of Touvron et al. (2023 ):\n",
            "Answer these questions:\n",
            "Q: Who got the first nobel\n",
            "prize in physics?\n",
            "A:\n",
            "Open-Book SettingFor the open-book setting,\n",
            "we extend the above prompt as follows:\n",
            "Nobel Prize\n",
            "A group including 42\n",
            "Swedish writers, artists,\n",
            "and literary critics\n",
            "protested against this\n",
            "decision, having expected\n",
            "Leo Tolstoy to be awarded.\n",
            "Some, including Burton\n",
            "Feldman, have criticised\n",
            "this prize because they...\n",
            "Nobel Prize in Physiology\n",
            "or Medicine\n",
            "In the last half century\n",
            "there has been an\n",
            "increasing tendency\n",
            "for scientists to work\n",
            "as teams, resulting in\n",
            "controversial exclusions.\n",
            "Alfred Nobel was born\n",
            "on 21 October 1833 in\n",
            "Stockholm, Sweden, into\n",
            "a family of engineers...\n",
            "Based on these texts,\n",
            "answer these questions:\n",
            "Q: Who got the first nobel\n",
            "prize in physics?\n",
            "A:Model RetrievalWiki-103 RealNews\n",
            "word ppl token ppl\n",
            "GPT-Neo 1.3B- 17.5 12.3\n",
            "BM25, § 5 14.6 9.9\n",
            "GPT-Neo 2.7B- 15.1 11.0\n",
            "BM25, § 5 12.8 9.0\n",
            "GPT-J 6B- 11.6 9.2\n",
            "BM25, § 5 10.0 7.7\n",
            "Table 5: The performance of models from the GPT-\n",
            "Neo family, measured by word-level perplexity on\n",
            "the test set of WikiText-103 and token-level per-\n",
            "plexity on the development set of RealNews.\n",
            "Figure 9: An analysis of perplexity as a function\n",
            "ofthe number of tokens in the queryfor an off-\n",
            "the-shelf BERT retriever on the development set of\n",
            "WikiText-103.\n",
            "Figure 10: An analysis of perplexity as a function\n",
            "ofthe number of tokens in the queryfor Contriever\n",
            "on the development set of WikiText-103.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First drop everything from References onwards. References were 'confusing' RAG into retrieving primarily titles of papers mentioned there, which is likely not very useful"
      ],
      "metadata": {
        "id": "JJpsJPXfXEPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "def load_pdf_to_string(pdf_path):\n",
        "    # Open the PDF file in binary mode\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        # Create a PDF file reader object\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "        # Initialize an empty string to hold the text\n",
        "        text = ''\n",
        "\n",
        "        # Loop through each page and extract the text\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            page_text = page.extract_text()\n",
        "            references_index= page_text.upper().find('\\nREFERENCES\\n')\n",
        "            if references_index != -1:\n",
        "              page_text = page_text[:references_index]\n",
        "              text += page_text\n",
        "              return text\n",
        "            text += page_text\n",
        "    return text\n",
        "\n",
        "# Use the function to load a PDF into a string\n",
        "text = load_pdf_to_string(os.path.expanduser(PDFS[1]))"
      ],
      "metadata": {
        "id": "rwNg_tThTApj"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text.find('References\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e4t1iYQTtai",
        "outputId": "e7294a55-595b-4f1a-ea2c-d8090aebf79e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PDFS[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyWYtK01WpHH",
        "outputId": "7273107e-fd7d-401a-b9e2-551ebf5a15fe"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/PdfRag/clusterofstars/InContextRALM.pdf')"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_docs = [load_pdf_to_string(os.path.expanduser(pdf_path)) for pdf_path in PDFS]"
      ],
      "metadata": {
        "id": "kF_jaR4HXzNM"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUf419rEWNJv",
        "outputId": "63bd588f-cfa3-416a-a658-8287437f98bf"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_docs[-1].find('References\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnLF5p2Gc_1j",
        "outputId": "4b7e5639-8f12-4b0a-c5c3-6b7d273607e7"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# loader = PyPDFLoader(os.path.expanduser(PDFS[0]))\n",
        "# #pages = loader.load_and_split()\n",
        "# pages = loader.load()\n",
        "# all_pages = [load_pdf_without_references(i) for i in range(len(PDFS))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "4C2OK_0TQWQg",
        "outputId": "0ff98afb-34d3-41f5-b3eb-0e00489cc806"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-35ab664e66a4>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#pages = loader.load_and_split()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mall_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mload_pdf_without_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDFS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-35ab664e66a4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#pages = loader.load_and_split()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mall_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mload_pdf_without_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDFS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-3fe6dd315b58>\u001b[0m in \u001b[0;36mload_pdf_without_references\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Extract the text from each Document and join into a single string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Find the \"References\" section\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mreferences_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'References'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-3fe6dd315b58>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Extract the text from each Document and join into a single string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Find the \"References\" section\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mreferences_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'References'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7_gFVTm1SR6d",
        "outputId": "2252fd74-d28e-40d2-c6a0-36947e31e520"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In-Context Retrieval-Augmented Language Models\\nOri Ram∗Yoav Levine∗Itay Dalmedigos Dor Muhlgay\\nAmnon Shashua Kevin Leyton-Brown Yoav Shoham\\nAI21 Labs\\n{orir,yoavl,itayd,dorm,amnons,kevinlb,yoavs}@ai21.com\\nAbstract\\nRetrieval-Augmented Language Modeling\\n(RALM) methods, which condition a lan-\\nguage model (LM) on relevant documents\\nfrom a grounding corpus during generation,\\nwere shown to signi\\ue000cantly improve lan-\\nguage modeling performance. In addition,\\nthey can mitigate the problem of factually\\ninaccurate text generation and provide natu-\\nral source attribution mechanism. Existing\\nRALM approaches focus on modifying the\\nLM architecture in order to facilitate the in-\\ncorporation of external information, signi\\ue000-\\ncantly complicating deployment. This paper\\nconsiders a simple alternative, which we dub\\nIn-Context RALM: leaving the LM architec-\\nture unchanged and prepending grounding\\ndocuments to the input,without any further\\ntraining of the LM. We show that In-Context\\nRALM that builds on off-the-shelf general\\npurpose retrievers provides surprisingly large\\nLM gains across model sizes and diverse cor-\\npora. We also demonstrate that the document\\nretrieval and ranking mechanism can be spe-\\ncialized to the RALM setting to further boost\\nperformance. We conclude that In-Context\\nRALM has considerable potential to increase\\nthe prevalence of LM grounding, particularly\\nin settings where a pretrained LM must be\\nused without modi\\ue000cation or even via API\\naccess.1\\n1 Introduction\\nRecent advances in language modeling (LM) have\\ndramatically increased the usefulness of machine-\\ngenerated text across a wide range of use-cases\\nand domains ( Brown et al. ,2020 ). However, the\\nmainstream paradigm of generating text with LMs\\nbears inherent limitations in access to external\\nknowledge. First, LMs are not coupled with any\\n∗Equal contribution.\\n1Our code is available at https://github.com/\\nAI21Labs/in-context-ralm\\nFigure 1: Our framework, dubbedIn-Context\\nRALM, provides large language modeling gains on\\nthe test set of WikiText-103,without modifying the\\nLM. Adapting the use of a BM25 retriever ( Robert-\\nson and Zaragoza ,2009) to the LM task (§ 5) yields\\nsigni\\ue000cant gains, and choosing the grounding doc-\\numents via our new class of Predictive Rerankers\\n(§6) provides a further boost. See Table 1for the\\nfull results on\\ue000ve diverse corpora.\\nsource attribution, and must be trained in order\\nto incorporate up-to-date information that was not\\nseen during training. More importantly, they tend\\nto produce factual inaccuracies and errors ( Lin\\net al. ,2022 ;Maynez et al. ,2020 ;Huang et al. ,\\n2020 ). This problem is present in any LM gen-\\neration scenario, and is exacerbated when gener-\\nation is made in uncommon domains or private\\ndata. A promising approach for addressing the\\nabove is Retrieval-Augmented Language Modeling\\n(RALM), grounding the LM during generation by\\nconditioning on relevant documents retrieved from\\nan external knowledge source. RALM systems in-\\nclude two high level components: (i)document se-\\nlection, selecting the set of documents upon which\\nto condition; and (ii)document reading, determin-\\ning how to incorporate the selected documents into\\nthe LM generation process.\\nLeading RALM systems introduced recently\\narXiv:2302.00083v3  [cs.CL]  1 Aug 2023Figure 2: An example ofIn-Context RALM: we simply prepend the retrieved document before the input pre\\ue000x.\\ntend to be focused on altering the language model\\narchitecture ( Khandelwal et al. ,2020 ;Borgeaud\\net al.,2022;Zhong et al. ,2022;Levine et al. ,2022c ;\\nLi et al. ,2022). Notably, Borgeaud et al. (2022) in-\\ntroduced RETRO, featuring document reading via\\nnontrivial modi\\ue000cations that require further train-\\ning to the LM architecture, while using an off-the-\\nshelf frozen BERT retriever for document selec-\\ntion. Although the paper’s experimental\\ue000ndings\\nshowed impressive performance gains, the need for\\nchanges in architecture and dedicated retraining\\nhas hindered the wide adoption of such models.\\nIn this paper, we show that a very simple doc-\\nument reading mechanism can have a large im-\\npact, and that substantial gains can also be made\\nby adapting the document selection mechanism to\\nthe task of language modeling. Thus, we show that\\nmany of the bene\\ue000ts of RALM can be achieved\\nwhile working with off-the-shelf LMs, even via\\nAPI access. Speci\\ue000cally, we consider a simple but\\npowerful RALM framework, dubbedIn-Context\\nRALM(presented in Section 3), which employs a\\nzero-effort document reading mechanism: we sim-\\nply prepend the selected documents to the LM’s\\ninput text (Figure 2).\\nSection 4describes our experimental setup. To\\nshow the wide applicability of our framework, we\\nperformed LM experiments on a suite of\\ue000ve di-\\nverse corpora: WikiText-103 ( Merity et al. ,2016 ),\\nRealNews ( Zellers et al. ,2019 ), and three datasets\\nfrom The Pile ( Gao et al. ,2021 ): ArXiv, Stack\\nExchange and FreeLaw. We use open-source LMs\\nranging from 110M to 66B parameters (from the\\nGPT-2, GPT-Neo, OPT and LLaMA model fami-\\nlies).\\nIn Section 5we evaluate the application of off-\\nthe-shelf retrievers to our framework. In this\\nminimal-effort setting, we found that In-Context\\nRALM led to LM performance gains equivalent to\\nincreasing the LM’s number of parameters by 2–\\n3×across all of the text corpora we examined. In\\nSection 6we investigate methods for adapting doc-ument ranking to the LM task, a relatively under-\\nexplored RALM degree of freedom. Our adapta-\\ntion methods range from using a small LM to per-\\nform zero-shot ranking of the retrieved documents,\\nup to training a dedicated bidirectional reranker\\nby employingself-supervision from the LM signal.\\nThese methods lead to further gains in the LM task\\ncorresponding to an additional size increase of 2×\\nin the LM architecture. As a concrete example of\\nthe gains, a 345M parameter GPT-2 enhanced by\\nIn-Context RALM outperforms a 762M parame-\\nter GPT-2 when employing an off-the-shelf BM25\\nretriever ( Robertson and Zaragoza ,2009 ), and out-\\nperforms a 1.5B parameter GPT-2 when employing\\nour trained LM-oriented reranker (see Figure 1).\\nFor large model sizes, our method is even more\\neffective: In-Context RALM with an off-the-shelf\\nretriever improved the performance of a 6.7B pa-\\nrameter OPT model to match that of a 66B param-\\neter parameter OPT model (see Figure 4).\\nIn Section 7we demonstrate the applicability\\nof In-Context RALM to downstream open-domain\\nquestions answering (ODQA) tasks.\\nIn a concurrent work, Shi et al. (2023 ) also sug-\\ngest to augment off-the-shelf LMs with retrieved\\ntexts by prepending them to the input. Their re-\\nsults are based on training a dedicated retriever for\\nlanguage modeling. In contrast, we focus on the\\ngains achievable in using off-the-shelf retrievers\\nfor this task. We show strong gains of this simpler\\nsetting by investigating: (1) which off-the-shelf\\nretriever is best suited for language modeling, (2)\\nthe frequency of retrieval operations, and (3) the\\noptimal query length. In addition, we boost the off-\\nthe-shelf retrieval performance by introducing two\\nreranking methods that demonstrate further gains\\nin perplexity.\\nWe believe that In-Context RALM can play two\\nimportant roles in making RALM systems more\\npowerful and more prevalent. First, given its simple\\nreading mechanism, In-Context RALM can serve\\nas a clean probe for developing document retrievalmethods that are specialized for the LM task. These\\nin turn can be used to improve both In-Context\\nRALM and other more elaborate RALM methods\\nthat currently leverage general purpose retrievers.\\nSecond, due to its compatibility with off-the-shelf\\nLMs, In-Context RALM can help drive wider de-\\nployment of RALM systems.\\n2 Related Work\\nRALM approaches can be roughly divided into two\\nfamilies of models: (i)nearest-neighbor language\\nmodels(also called kNN-LM), and (ii)retrieve\\nand read models. Our work belongs to the second\\nfamily, but is distinct in that it involves no further\\ntraining of the LM.\\nNearest Neighbor Language ModelsThe kNN-\\nLM approach was\\ue000rst introduced in Khandel-\\nwal et al. (2020 ). The authors suggest a simple\\ninference-time model that interpolates between two\\nnext-token distributions: one induced by the LM\\nitself, and one induced by the kneighbors from the\\nretrieval corpus that are closest to the query token in\\nthe LM embedding space. Zhong et al. (2022 ) sug-\\ngest a framework for training these models. While\\nthey showed signi\\ue000cant gains from kNN-LM, the\\napproach requires storing the representationsfor\\neach token in the corpus, an expensive requirement\\neven for a small corpus like Wikipedia. Although\\nnumerous approaches have been suggested for al-\\nleviating this issue ( He et al. ,2021 ;Alon et al. ,\\n2022), scaling any of them to large corpora remains\\nan open challenge.\\nRetrieve and Read ModelsThis family of\\nRALMs creates a clear division betweendocument\\nselectionanddocument readingcomponents. All\\nprior work involves training the LM. We begin by\\ndescribing works that use this approach for tack-\\nling downstream tasks, and then mention works ori-\\nented towards RALM. Lewis et al. (2020) and Izac-\\nard and Grave (2021 )\\ue000ne tuned encoder–decoder\\narchitectures for downstream knowledge-intensive\\ntasks. Izacard et al. (2022b ) explored different\\nways of pretraining such models, while Levine\\net al. (2022c ) pretrained an autoregressive LM on\\nclusters of nearest neighbors in sentence embed-\\nding space. Levine et al. (2022a ) showed competi-\\ntive open domain question-answering performance\\nby prompt-tuning a frozen LM as a reader. Guu\\net al. (2020 ) pretrained REALM, a retrieval aug-\\nmentedbidirectional, maskedLM, later\\ue000ne-tunedfor open-domain question answering. The work\\nclosest to this paper—with a focus on the language\\nmodeling task—is RETRO ( Borgeaud et al. ,2022),\\nwhich modi\\ue000es an autoregressive LM to attend to\\nrelevant documents via chunked cross-attention,\\nthus introducing new parameters to the model. Our\\nIn-Context RALM differs from prior work in this\\nfamily of models in two key aspects:\\n•We useoff-the-shelfLMs for document read-\\ningwithout any further training of the LM.\\n•We focus onhow to choose documents for\\nimproved LM performance.\\n3 Our Framework\\n3.1 In-Context RALM\\nLanguage models de\\ue000ne probability distributions\\nover sequences of tokens. Given such a sequence\\nx1, ..., x n, the standard way to model its probabil-\\nity is via next-token prediction: p(x 1, ..., x n) =\\ue007n\\ni=1p(x i|x<i), where x<i:=x 1, ..., x i−1is the\\nsequence of tokens preceding xi, also referred to\\nas itspre\\ue000x. This autoregressive model is usu-\\nally implemented via a learned transformer net-\\nwork ( Vaswani et al. ,2017 ) parameterized by the\\nset of parametersθ:\\np(x 1, ..., x n) =n\\ue009\\ni=1pθ(xi|x<i),(1)\\nwhere the conditional probabilities are modeled\\nby employing a causal self-attention mask ( Rad-\\nford et al. ,2018 ). Notably, leading LMs such\\nas GPT-2 ( Radford et al. ,2019 ), GPT-3 ( Brown\\net al.,2020 ), OPT ( Zhang et al. ,2022 ) or Jurassic-\\n1 (Lieber et al. ,2021 ) follow this simple parame-\\nterization.\\nRetrieval augmented language models (RALMs)\\nadd an operation that retrieves one or more docu-\\nments from an external corpus C, and condition the\\nabove LM predictions on these documents. Speci\\ue000-\\ncally, for predicting xi, the retrieval operation from\\nCdepends on its pre\\ue000x: RC(x<i), so the most\\ngeneral RALM decomposition is: p(x 1, ..., x n) =\\ue007n\\ni=1p(x i|x<i,RC(x<i)). In order to condition\\nthe LM generation on the retrieved document, pre-\\nvious RALM approaches used specialized architec-\\ntures or algorithms (see § 2). Inspired by the suc-\\ncess of In-Context Learning ( Brown et al. ,2020 ;\\nDong et al. ,2023 ),In-Context RALMrefers to the\\nfollowing speci\\ue000c, simple method of concatenatingthe retrieved documents2within the Transformer’s\\ninput prior to the pre\\ue000x (see Figure 2),which does\\nnot involve altering the LM weightsθ:\\np(x 1, ..., x n) =\\nn\\ue009\\ni=1pθ(xi|[R C(x<i);x <i]),(2)\\nwhere [a;b] denotes the concatenation of strings a\\nandb.\\nSince common Transformer-based LM imple-\\nmentations support limited length input sequences,\\nwhen the concatenation of the document and the\\ninput sequence exceed this limit we remove to-\\nkens from the beginning of xuntil the overall input\\nlength equals that allowed by the model. Because\\nour retrieved documents are passages of limited\\nlength, we always have enough context left from x\\n(see § 4.3).\\n3.2 RALM Design Choices\\nWe detail below two practical design choices often\\nmade in RALM systems. In § 5, we investigate the\\neffect of these in the setting of In-Context RALM.\\nRetrieval StrideWhile in the above formulation\\na retrieval operation can occur at each generation\\nstep, we might want to perform retrieval only once\\nevery s >1 tokens due to the cost of calling the\\nretriever, and the need to replace the documents in\\nthe LM pre\\ue000x during generation. We refer to sas\\ntheretrieval stride. This gives rise to the follow-\\ning In-Context RALM formulation (which reduces\\nback to Eq. ( 2) fors= 1):\\np(x 1, ..., x n) =\\nns−1\\ue009\\nj=0s\\ue009\\ni=1pθ\\ue000\\nxs·j+i|\\ue002\\nRC(x≤s·j);x <(s·j+i)\\ue003\\ue001\\n,\\n(3)\\nwheren s=n/sis the number of retrieval strides.\\nNotably, in this framework the runtime costs of\\neach retrieval operation is composed of (a) apply-\\ning the retriever itself, and (b) recomputing the\\nembeddings of the pre\\ue000x. In § 5.2we show that us-\\ning smaller retrieval strides,i.e., retrieving as often\\nas possible, is superior to using larger ones (though\\nIn-Context RALM with larger strides already pro-\\nvides large gains over vanilla LM). Thus, choosing\\nthe retrieval stride is ultimately a tradeoff between\\nruntime and performance.\\n2We always use asingle document, but it is conceptually\\nsimple to support multiple documents as well.Retrieval Query LengthWhile the retrieval\\nquery above in principle depends on all pre\\ue000x to-\\nkens x≤s·j, the information at the very end of the\\npre\\ue000x is typically the most relevant to the generated\\ntokens. If the retrieval query is too long then this in-\\nformation can be diluted. To avoid this, we restrict\\nthe retrieval query at stride jto the last ℓtokens\\nof the pre\\ue000x,i.e., we use qs,ℓ\\nj:=x s·j−ℓ+1 , ..., x s·j.\\nWe refer to ℓas theretrieval query length. Note that\\nprior RALM work couples the retrieval stride sand\\nthe retrieval query length ℓ(Borgeaud et al. ,2022).\\nIn §5, we show that enforcing s=ℓdegrades LM\\nperformance. Integrating these hyper-parameters\\ninto the In-Context RALM formulation gives\\np(x 1, ..., x n) =\\nns−1\\ue009\\nj=0s\\ue009\\ni=1pθ\\ue004\\nxs·j+i|\\ue00a\\nRC(qs,ℓ\\nj);x <(s·j+i)\\ue00b\\ue005\\n.\\n(4)\\n4 Experimental Details\\nWe now describe our experimental setup, including\\nall models we use and their implementation details.\\n4.1 Datasets\\nWe evaluated the effectiveness of In-Context\\nRALM across\\ue000ve diverse language modeling\\ndatasets and two common open-domain question\\nanswering datasets.\\nLanguage ModelingThe\\ue000rst LM dataset is\\nWikiText-103( Merity et al. ,2016 ), which has been\\nextensively used to evaluate RALMs ( Khandelwal\\net al.,2020 ;He et al. ,2021 ;Borgeaud et al. ,2022 ;\\nAlon et al. ,2022 ;Zhong et al. ,2022 ). Second, we\\nchose three datasets spanning diverse subjects from\\nThe Pile ( Gao et al. ,2021):ArXiv,Stack Exchange\\nandFreeLaw. Finally, we also investigatedReal-\\nNews( Zellers et al. ,2019 ), since The Pile lacks a\\ncorpus focused only on news (which is by nature a\\nknowledge-intensive domain).\\nOpen-Domain Question AnsweringIn order\\nto evaluate In-Context RALM on downstream\\ntasks as well, we use theNatural Questions(NQ;\\nKwiatkowski et al. 2019 ) andTriviaQA( Joshi et al. ,\\n2017 ) open-domain question answering datasets.\\n4.2 Models\\nLanguage ModelsWe performed our experi-\\nments using the four models of GPT-2 (110M–\\n1.5B; Radford et al. 2019 ), three models of GPT-\\nNeo and GPT-J (1.3B–6B; Black et al. 2021 ;Wangand Komatsuzaki 2021 ), eight models of OPT\\n(125M–66B; Zhang et al. 2022 ) and three mod-\\nels of LLaMA (7B–33B; Touvron et al. 2023 ). All\\nmodels are open source and publicly available.3\\nWe elected to study these particular models for\\nthe following reasons. The\\ue000rst four (GPT-2) mod-\\nels were trained on WebText ( Radford et al. ,2019),\\nwith Wikipedia documents excluded from their\\ntraining datasets. We were thus able to evaluate our\\nmethod’s “zero-shot” performance when retrieving\\nfrom a novel corpus (for WikiText-103). The rest of\\nthe models brought two further bene\\ue000ts. First, they\\nallowed us to investigate how our methods scale\\nto models larger than GPT-2. Second, the fact that\\nWikipedia was part of their training data allowed us\\nto investigate the usefulness of In-Context RALM\\nfor corpora seen during training. The helpfulness\\nof such retrieval has been demonstrated for previ-\\nous RALM methods ( Khandelwal et al. ,2020) and\\nhas also been justi\\ue000ed theoretically by Levine et al.\\n(2022c ).\\nWe ran all models with a maximum sequence\\nlength of 1,024, even though GPT-Neo, OPT and\\nLLaMA models support a sequence length of\\n2,048.4\\nRetrieversWe experimented with both sparse\\n(word-based) and dense (neural) retrievers. We\\nused BM25 ( Robertson and Zaragoza ,2009) as our\\nsparse model. For dense models, we experimented\\nwith (i) a frozen BERT-base ( Devlin et al. ,2019 )\\nfollowed by mean pooling, similar to Borgeaud\\net al. (2022 ); and (ii) the Contriever ( Izacard et al. ,\\n2022a ) and Spider ( Ram et al. ,2022 ) models,\\nwhich are dense retrievers that were trained in un-\\nsupervised manners.\\nRerankingWhen training rerankers (Sec-\\ntion6.2), we initialized from RoBERTa-base ( Liu\\net al.,2019 ).\\n4.3 Implementation Details\\nWe implemented our code base using the Trans-\\nformers library ( Wolf et al. ,2020 ). We based\\nour dense retrieval code on the DPR repository\\n(Karpukhin et al. ,2020 ).\\n3All models are available for use use via https://\\nhuggingface.co/\\n4In preliminary experiments, we observed similar improve-\\nments from In-Context RALM when using a sequence length\\nof 2,048. We used a sequence length of 1,024 in order to\\nfacilitate a direct comparison between all models.\\nFigure 3: The performance of four off-the-shelf\\nretrievers used for In-Context RALM on the de-\\nvelopment set of WikiText-103. All RALMs are\\nrun with s= 4 (i.e., retrieval is applied every four\\ntokens). For each RALM, we report the result of\\nthe best query lengthℓ(see Figures 6,9,10).\\nRetrieval CorporaFor WikiText-103 and\\nODQA datasets, we used the Wikipedia corpus\\nfrom Dec. 20, 2018, standardized by Karpukhin\\net al. (2020 ) using the preprocessing from Chen\\net al. (2017 ). To avoid contamination, we found\\nand removed all 120 articles of the development\\nand test set of WikiText-103 from the corpus. For\\nthe remaining datasets, we used their training\\ndata as the retrieval corpus. Similar to Karpukhin\\net al. (2020 ), our retrieval corpora consist of\\nnon-overlapping passages of 100 words (which\\ntranslate to less than 150 tokens for the vast\\nmajority of passages). Thus, we truncate our\\nretrieved passages at 256 tokens when input to the\\nmodels, but they are usually much smaller.\\nRetrievalFor sparse retrieval, we used the Py-\\nserini library ( Lin et al. ,2021 ). For dense retrieval,\\nwe applied exact search using FAISS ( Johnson\\net al.,2021 ).\\n5 The Effectiveness of In-Context RALM\\nwith Off-the-Shelf Retrievers\\nWe now empirically show that despite its simple\\ndocument reading mechanism, In-Context RALM\\nleads to substantial LM gains across our diverse\\nevaluation suite. We begin in this section by inves-\\ntigating the effectiveness of off-the-shelf retrievers\\nfor In-Context RALM; we go on in § 6to show\\nthat further LM gains can be made by tailoring\\ndocument ranking functions to the LM task.\\nThe experiments in this section provided us\\nwith a recommended con\\ue000guration for applying In-Model Retrieval RerankingWikiText-103 RealNews ArXiv Stack Exch. FreeLaw\\nword ppl token ppl token ppl token ppl token ppl\\nGPT-2 S– – 37.5 21.3 12.0 12.8 13.0\\nBM25 § 5– 29.6 16.1 10.9 11.3 9.6\\nBM25 Zero-shot § 6.1 28.6 15.5 10.1 10.6 8.8\\nBM25 Predictive § 6.2 26.8 – – – –\\nGPT-2 M– – 26.3 15.7 9.3 8.8 9.6\\nBM25 § 5– 21.5 12.4 8.6 8.1 7.4\\nBM25 Zero-shot § 6.1 20.8 12.0 8.0 7.7 6.9\\nBM25 Predictive § 6.2 19.7 – – – –\\nGPT-2 L– – 22.0 13.6 8.4 8.5 8.7\\nBM25 § 5– 18.1 10.9 7.8 7.8 6.8\\nBM25 Zero-shot § 6.1 17.6 10.6 7.3 7.4 6.4\\nBM25 Predictive § 6.2 16.6 – – – –\\nGPT-2 XL– – 20.0 12.4 7.8 8.0 8.0\\nBM25 § 5– 16.6 10.1 7.2 7.4 6.4\\nBM25 Zero-shot § 6.1 16.1 9.8 6.8 7.1 6.0\\nBM25 Predictive § 6.2 15.4 – – – –\\nTable 1: Perplexity on the test set of WikiText-103, RealNews and three datasets from the Pile. For\\neach LM, we report: (a) its performance without retrieval, (b) its performance when fed the top-scored\\npassage by BM25 (§ 5), and (c) its performance when applied on the top-scored passage of each of our two\\nsuggested rerankers (§ 6). All models share the same vocabulary, thus token-level perplexity (token ppl)\\nnumbers are comparable. For WikiText we follow prior work and report word-level perplexity (word ppl).\\nModel RetrievalWikiText-103\\nword ppl\\nLLaMA-7B- 9.9\\nBM25, § 5 8.8\\nLLaMA-13B- 8.5\\nBM25, § 5 7.6\\nLLaMA-33B- 6.3\\nBM25, § 5 6.1\\nTable 2: The performance of models from the\\nLLaMA family, measured by word-level perplexity\\non the test set of WikiText-103.\\nContext RALM: applying a sparse BM25 retriever\\nthat receives ℓ= 32 query tokens and is applied\\nas frequently as possible. Practically, we retrieve\\nevery s= 4 tokens ( ℓandsare de\\ue000ned in § 3).\\nTable 1shows for the GPT-2 models that across\\nall the examined corpora, employing In-Context\\nRALM with an off-the-shelf retriever improved\\nLM perplexity to a suf\\ue000cient extent that it matched\\nthat of a 2–3×larger model. Figure 4and Tables 2\\nand5show that this trend holds across model sizes\\nup to 66B parameters, for both WikiText-103 andRealNews.\\n5.1 BM25 Outperforms Off-the-Shelf Neural\\nRetrievers in Language Modeling\\nWe experimented with different off-the-shelf gen-\\neral purpose retrievers, and found that the sparse\\n(lexical) BM25 retriever ( Robertson and Zaragoza ,\\n2009 ) outperformed three popular dense (neu-\\nral) retrievers: the self-supervised retrievers Con-\\ntriever ( Izacard et al. ,2022a ) and Spider ( Ram et al. ,\\n2022 ), as well as a retriever based on the average\\npooling of BERT embeddings that was used in\\nthe RETRO system ( Borgeaud et al. ,2022 ). We\\nconducted a minimal hyper-parameter search on\\nthe query length ℓfor each of the retrievers, and\\nfound that ℓ= 32 was optimal for BM25 (Fig-\\nure6), and ℓ= 64 worked best for dense retrievers\\n(Figures 9,10).\\nFigure 3compares the performance gains of In-\\nContext RALM with these four general-purpose re-\\ntrievers. The BM25 retriever clearly outperformed\\nall dense retrievers. This outcome is consistent\\nwith prior work showing that BM25 outperforms\\nneural retrievers across a wide array of tasks, when\\napplied in zero-shot settings ( Thakur et al. ,2021 ).\\nThis result renders In-Context RALM even moreFigure 4: Results of OPT models ( Zhang et al. ,2022 ) on the test set of WikiText-103 (word-level\\nperplexity) and the development set of RealNews (token-level perplexity). In-Context RALM models use\\na BM25 retriever with s= 4 (i.e., the retriever is called every four tokens) and ℓ= 32 (i.e., the retriever\\nquery is comprised of the last 32 tokens of the pre\\ue000x).In-Context RALM with an off-the-shelf retriever\\nimproved the performance of a 6.7B parameter OPT model to match that of a 66B parameter OPT model.\\nappealing since applying a BM25 retriever is sig-\\nni\\ue000cantly cheaper than the neural alternatives.\\n5.2 Frequent Retrieval Improves Language\\nModeling\\nWe investigated the effect of varying the retrieval\\nstride s(i.e., the number of tokens between consec-\\nutive retrieval operations). Figure 5shows that LM\\nperformance improved as the retrieval operation\\nbecame more frequent. This supports the intuition\\nthat retrieved documents become more relevant the\\ncloser the retrieval query becomes to the gener-\\nated tokens. Of course, each retrieval operation\\nimposes a runtime cost. To balance performance\\nand runtime, we used s= 4 in our experiments.\\nFor comparison, RETRO employed a retrieval fre-\\nquency of s= 64 (Borgeaud et al. ,2022 ), which\\nleads to large degradation in perplexity. Intuitively,\\nretrieving with high frequency (low retrieval stride)\\nallows to ground the LM in higher resolution.5.3 A Contextualization vs. Recency Tradeoff\\nin Query Length\\nWe also investigated the effect of varying ℓ, the\\nlength of the retrieval query for BM25. Figure 6\\nreveals an interesting tradeoff and a sweet spot\\naround a query length of 32tokens. Similar ex-\\nperiments for dense retrievers are given in App. A.\\nWe conjecture that when the retriever query is too\\nshort, it does not include enough of the input con-\\ntext, decreasing the retrieved document’s relevance.\\nConversely, excessively growing the retriever query\\ndeemphasizes the tokens at the very end of the pre-\\n\\ue000x, diluting the query’s relevance to the LM task.\\n6 Improving In-Context RALM with\\nLM-Oriented Reranking\\nSince In-Context RALM uses a\\ue000xed document\\nreading component by de\\ue000nition, it is natural to\\nask whether performance can be improved by spe-\\ncializing its document retrieval mechanism to the\\nLM task. Indeed, there is considerable scope for\\nimprovement: the previous section considered con-\\nditioning the model only on the\\ue000rst document re-Figure 5: An analysis of perplexity as a function\\nofs, theretrieval stride,i.e., the number of tokens\\nbetween consecutive retrieval operations, on the\\ndevelopment set of WikiText-103. Throughout the\\npaper, we use s= 4 to balance perplexity and\\nruntime.\\nFigure 6: An analysis of perplexity as a function\\nofthe number of tokens in the query ℓfor BM25\\non the development set of WikiText-103. In the\\nappendix, we show similar trade-offs for dense\\nretrievers within WikiText-103. Throughout the\\npaper, we use a query length ofℓ= 32tokens.\\ntrieved by the BM25 retriever. This permits very\\nlimited semantic understanding of the query, since\\nBM25 is based only on the bag of words signal.\\nMoreover, it offers no way to accord different de-\\ngrees of importance to different retrieval query to-\\nkens, such as recognizing that later query tokens\\nare more relevant to the generated text.\\nIn this section, we focus on choosing which doc-\\nument to present to the model, by reranking the\\ntop-kdocuments returned by the BM25 retriever.5\\nWe use Figure 7as motivation: it shows the large\\npotential for improvement among the top- 16docu-\\nments returned by the BM25 retriever. We act upon\\n5In both § 6.1and § 6.2we usek= 16.\\nFigure 7:Potential for gainsfrom reranking: per-\\nplexity improvement (on the development set of\\nWikiText-103) from an oracle that takes the best\\nof the top-16 documents retrieved by BM25 rather\\nthan the\\ue000rst.\\nthis motivation by using two rerankers. Speci\\ue000-\\ncally, in § 6.1we show performance gains across\\nour evaluation suite obtained by using an LM to\\nperform zero-shot reranking of the top- kBM25\\nretrieved documents (results in third row for each\\nof the models in Table 1). Then, in § 6.2we show\\nthat training a specialized bidirectional reranker\\nof the top- kBM25 retrieved documents in a self-\\nsupervised manner via the LM signal can provide\\nfurther LM gains (results in forth row for each of\\nthe models in Table 1).\\n6.1 LMs as Zero-Shot Rerankers\\nFirst, we used off-the-shelf language models as\\ndocument rerankers for the In-Context RALM set-\\nting. Formally, for a query qconsisting of the\\nlastℓtokens in the pre\\ue000x of the LM input x, let\\n{d1, ..., d k}be the top- kdocuments returned by\\nBM25. For retrieval iteration j, let the text for\\ngeneration be y:=x s·j+1 , ..., x s·j+s. Ideally, we\\nwould like to\\ue000nd the document di∗that maximizes\\nthe probability of the text for generation,i.e.,\\ni∗= arg max\\ni∈[k]pθ(y|[d i;x≤s·j]).(5)\\nHowever, at test time we do not have access to\\nthe tokens of y. Instead, we used the lastpre-\\n\\ue000xtokens (whichareavailable at test time), de-\\nnoted by y′, for reranking. Formally, let s′be\\na hyper-parameter that determines the number of\\nthe pre\\ue000x tokens by which to rerank. We de\\ue000ne\\ny′:=x s·j−s′+1, ..., x s·j(i.e., the stride of length s′\\nthat precedes y) and choose the document dˆisuchModelReranking\\nModelWikiText-103 RealNews\\nword ppl token ppl\\nGPT-2 345M (M)GPT-2 110M (S) 20.8 12.1\\nGPT-2 345M (M) 20.8 12.0\\nGPT-2 762M (L)GPT-2 110M (S) 17.7 10.7\\nGPT-2 762M (L) 17.6 10.6\\nGPT-2 1.5B (XL)GPT-2 110M (S) 16.2 9.9\\nGPT-2 1.5B (XL) 16.1 9.8\\nTable 3: Perplexity for zero-shot reranking (§ 6.1) where the reranking models is smaller than the LM, or\\nthe LM itself. Reranking is performed on the top 16 documents retrieved by BM25. Using a GPT-2 110M\\n(S) instead of a larger language model as a reranker leads to only a minor degradation.\\nthat\\nˆi= arg max\\ni∈[k]pϕ(y′|\\ue002\\ndi;x≤(s·j−s′)\\ue003\\n). (6)\\nThe main motivation is that since BM25 is a lexical\\nretriever, we want to incorporate a semantic signal\\ninduced by the LM. Also, this reranking shares con-\\nceptual similarities with the reranking framework\\nofSachan et al. (2022 ) for open-domain question\\nanswering, where y′(i.e., the last pre\\ue000x tokens) can\\nbe thought of as their “question”.\\nNote that our zero-shot reranking does not re-\\nquire that the LM used for reranking is the same\\nmodel as the LM used for generation (i.e., the LM\\nin Eq. (6), parameterized by ϕ, does not need to be\\nthe LM in Eq. (2), parameterized by θ). This ob-\\nservation unlocks the possibility of reranking with\\nsmaller (and thus faster) models, which is impor-\\ntant for two main reasons: (i) Reranking kdocu-\\nments requires kforward passes; and (ii) it allows\\nour methods to be used in cases where the actual\\nLM’s log probabilities are not available (for exam-\\nple, when the LM is accessed through an API).6\\nResultsA minimal hyper-parameter search on\\nthe development set of WikiText-103 revealed that\\nthe optimal query length is s′= 16 ,7so we proceed\\nwith this value going forward. Table 1shows the\\nresults of letting the LM perform zero-shot rerank-\\ning on the top-16 documents retrieved by BM25\\n(third row for each of the models). It is evident\\nthat reranking yielded consistently better results\\nthan simply taking the\\ue000rst result returned by the\\nretriever.\\n6Note we do not require that the two models share the\\nsame vocabulary.\\n7We experimented withs′∈{4,8,16,32}.Table 3shows that a small LM (GPT-2 117M)\\ncan be used to rerank the documents for all larger\\nGPT-2 models, with roughly the same performance\\nas having each LM perform reranking for itself,\\nsupporting the applicability of this method for LMs\\nthat are only accessible via an API.\\n6.2 Training LM-dedicated Rerankers\\nNext, wetraineda reranker to choose one of the\\ntop-kdocuments retrieved by BM25. We refer to\\nthis approach asPredictive Reranking, since the\\nreranker learns to choose which document will help\\nin “predicting” the upcoming text. For this process,\\nwe assume availability of training data from the\\ntarget corpus. Our reranker is a classi\\ue000er that gets\\na pre\\ue000x x≤s·jand a document di(fori∈[k] ), and\\nproduces a scalar f(x ≤s·j, di)that should resemble\\nthe relevance ofd iforthe continuationofx ≤s·j.\\nWe then normalize these relevance scores:\\nprank(di|x≤s·j) =exp(f(x ≤s·j, di))\\ue006k\\ni′=1exp(f(x ≤s·j, di′)),(7)\\nand choose the documentd ˆisuch that\\nˆi= arg max\\ni∈[k]prank(di|x≤s·j).(8)\\nCollecting Training ExamplesTo train our pre-\\ndictive reranker, we collected training examples\\nas follows. Let x≤s·jbe a pre\\ue000x we sample from\\nthe training data, and y:=x s·j+1 , ..., x s·j+s be the\\ntext for generation upcoming in its next stride. We\\nrun BM25 on the query qs,ℓ\\njderived from x≤s·j\\n(see § 3.2) and get kdocuments {d1, ..., d k}. For\\neach document di, we then run the LM to compute\\npθ(y|[d i;x≤s·j])similar to Eq. ( 4).Figure 8: Zero-shot performance of In-Context\\nRALM on the development set of Natural Ques-\\ntions and TriviaQA, when varying the number of\\ndocuments (retrieved by DPR) shown in-context.\\nTrainingOur reranker was a\\ue000ne-tuned\\nRoBERTa-base ( Liu et al. ,2019 ) that trained for\\n10,000 steps with a peak learning rate of 10−5and\\na batch size of 32. Overall, we created 300,000\\nexamples from the training set of WikiText-103 as\\nexplained above. The loss function we use to train\\nthe reranker follows previous work ( Guu et al. ,\\n2020 ;Lewis et al. ,2020 ):\\n−logk\\ue008\\ni=1prank(di|x≤s·j)·p θ(y|[d i;x≤s·j]).(9)\\nNote that unlike those works, we train only the\\nreranker (p rank), keeping the LM weightsθfrozen.\\nResultsTable 1shows the result of our predictive\\nreranker, trained on WikiText-103. Speci\\ue000cally, we\\ntrained it with data produced by GPT-2 110M (S),\\nand tested its effectiveness for all GPT-2 models.\\nWe observed signi\\ue000cant gains obtained from Predic-\\ntive Reranking. For example, the perplexity of GPT-\\n2 110M (S) improved from 29.6 to 26.8, and that of\\nGPT-2 1.5B (XL) improved from 16.6 to 15.4. This\\ntrend held for the other two models as well. Overall,\\nthese results demonstrate that training a reranker\\nwith domain-speci\\ue000c data was more effective than\\nzero-shot reranking (Section 6.1). Note that these\\nresults—while impressive—still leave room for fur-\\nther improvements, compared to the top-16 BM25\\noracle results (see Figure 7). Moreover, the oracle\\nresults themselves can be improved by retrieving\\nk >16 documents via a BM25 retriever, or by\\ntraining stronger retrievers dedicated to the RALM\\ntask. We leave this direction for future work.Model Retrieval NQ TriviaQA\\nLLaMA-7B- 10.3 47.5\\nDPR 28.0 56.0\\nLLaMA-13B- 12.0 54.8\\nDPR 31.0 60.1\\nLLaMA-33B- 13.7 58.3\\nDPR 32.3 62.7\\nTable 4: Zero-shot results of In-Context RALM on\\nthe test set of Natural Questions and TriviaQA mea-\\nsured by exact match. In the open-book setting, we\\ninclude the top two documents returned by DPR.\\n7 In-Context RALM for Open-Domain\\nQuestion Answering\\nSo far, we evaluated our framework on language\\nmodeling benchmarks. To test its ef\\ue000cacy in addi-\\ntional scenarios, and speci\\ue000cally downstream tasks,\\nwe now turn to evaluate In-Context RALM on open-\\ndomain question answering (ODQA; Chen et al.\\n2017 ). This experiment is intended to verify, in\\na controlled environment, that LMs can leverage\\nretrieved documentswithout further trainingand\\nwithout any training examples. Speci\\ue000cally, we\\nuse the LLaMA family ( Touvron et al. ,2023 )with\\nandwithoutIn-Context RALM (often referred to\\nin ODQA literature as open-book and closed-book\\nsettings, respectively). In contrast to most prior\\nwork on ODQA (e.g., Izacard and Grave 2021 ;Fa-\\njcik et al. 2021 ;Izacard et al. 2022b ;Levine et al.\\n2022b ), our “reader” (i.e., the model that gets the\\nquestion along with its corresponding retrieved doc-\\numents, and returns the answer) is simply a frozen\\nlarge LM:notpretrained,\\ue000ne-tuned or prompted\\nto be retrieval-augmented. For the closed-book set-\\nting, we utilize the prompt of Touvron et al. (2023).\\nFor the open-book setting, we extend this prompt\\nto include retrieved documents (see App. C). We\\nuse DPR ( Karpukhin et al. ,2020 ) as our retriever.\\nVarying the Number of DocumentsTo inves-\\ntigate the the effect of the number of documents\\nshown to the model, we performed a minimal anal-\\nysis on the development set of NQ and TriviaQA.\\nFigure 8demonstrates that showing documents in-\\ncontext signi\\ue000cantly improves the model’s perfor-\\nmance. In addition, most of the gain can be ob-\\ntained by using only two documents (or even a\\nsingle one in some cases).ResultsTable 4gives the results of In-Context\\nRALM on the test set of Natural Questions and\\nTriviaQA. Motivated by our previous\\ue000ndings,\\nwe used two retrieved documents. It is evident\\nthat showing the model relevant documents sig-\\nni\\ue000cantly boosted its performance. For example,\\nadding retrieved documents improved LLaMA-\\n13B in the zero-shot setting by more than 18 points\\non NQ (from 12.0% to 31.0%) and more than 5\\npoints on TriviaQA (from 54.8% to 60.1%).\\n8 Discussion\\nRetrieval from external sources has become a com-\\nmon practice in knowledge-intensive tasks (such\\nas factual question answering, fact checking, and\\nmore; Petroni et al. 2021 ). In parallel, recent break-\\nthroughs in LM generation capabilities has led to\\nLMs that can generate useful long texts. How-\\never, factual inaccuracies remain a common way in\\nwhich machine-generated text can fall short, and\\nlack of direct provenance makes it hard to trust\\nmachine generated text. This makes language mod-\\neling both a promising and an urgent new applica-\\ntion area for knowledge grounding, and motivates\\npromoting RALM approaches. Prior research has\\nalready investigated RALM, of course, but it is\\nnot yet widely deployed. One likely reason is that\\nexisting approaches rely upon\\ue000ne-tuning the LM,\\nwhich is typically dif\\ue000cult and costly, and is even\\nimpossible for LMs accessible only via an API.\\nThis paper presented the framework ofIn-\\nContext RALM, enabling frozen, off-the-shelf LMs\\nto bene\\ue000t from retrieval. We demonstrated that\\nsubstantial performance gains can be achieved by\\nusing general purpose retrievers, and showed that\\nadditional gains can be achieved by tailoring the\\ndocument selection to the LM setting. A recent\\nwork by Muhlgay et al. (2023 ) demonstrates that\\nIn-Context RALM is indeed able to improve the\\nfactuality of large LMs.\\nSeveral directions for further improvement re-\\nmain for future work. First, this paper considers\\nonly the case of prepending a single external docu-\\nment to the context; adding more documents could\\ndrive further gains (for example, using the frame-\\nwork of Ratner et al. 2022 ). Second, we retrieved\\ndocuments every\\ue000xed interval of stokens, but see\\npotential for large latency and cost gains by retriev-\\ning more sparsely, such as only when a specialized\\nmodel predicts that retrieval is needed.\\nWe release the code used in this work, for thecommunity to use and improve over. We hope it\\nwill drive further research of RALM, which will\\nenable its wider adoption.\\nAcknowledgements\\nWe would like to thank the reviewers and the Ac-\\ntion Editor for their valuable feedback.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# loader = PyPDFLoader(os.path.expanduser(PDFS[0]))\n",
        "# #pages = loader.load_and_split()\n",
        "# pages = loader.load()\n",
        "# all_pages = [PyPDFLoader(os.path.expanduser(PDFS[i])).load() for i in range(len(PDFS))]"
      ],
      "metadata": {
        "id": "wQ_qBHL_87WG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Instead of load_and_split, going for a more custom split to have more control over context length sicnce working with limited compute"
      ],
      "metadata": {
        "id": "R5K-172CQWJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pages[0], len(pages)"
      ],
      "metadata": {
        "id": "K0V5lV8Y87Y4"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Either PyPDFLoader or PyPDF2 approach could work"
      ],
      "metadata": {
        "id": "qtNRwXOGO-Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.document_loaders.onedrive_file import CHUNK_SIZE\n",
        "# from langchain.document_loaders import TextLoader\n",
        "# from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter\n",
        "# CHUNK_SIZE = 1000\n",
        "# CHUNK_OVERLAP = 30\n",
        "\n",
        "# text_splitter = CharacterTextSplitter(\n",
        "#     chunk_size=CHUNK_SIZE,\n",
        "#     chunk_overlap = CHUNK_OVERLAP,\n",
        "#     length_function=len,\n",
        "# )\n",
        "# docs  = text_splitter.split_documents(pages)\n",
        "# docs"
      ],
      "metadata": {
        "id": "hHKQcqKM85K6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "vQa6rjDLqPCI"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders.onedrive_file import CHUNK_SIZE\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import Document\n",
        "\n",
        "# CHUNK_SIZE = 1000\n",
        "# CHUNK_OVERLAP = 30\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 30\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap = CHUNK_OVERLAP,\n",
        "    length_function=len,\n",
        ")\n",
        "#text_splitter.split_text(all_pages[0])\n",
        "# docs = [Document(page_content=pages) for pages in all_pages]\n",
        "docs  = [text_splitter.split_text(doc) for doc in all_docs]\n",
        "# # docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51XLp620bkX-",
        "outputId": "4ce577a6-6c93-467e-abf6-4860f60ae36c"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGF-vPI9bmjK",
        "outputId": "3d556c49-1930-4dc4-aed0-7a953c07b05e"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In-Context Retrieval-Augmented Language Models\\nOri Ram∗Yoav Levine∗Itay Dalmedigos Dor Muhlgay\\nAmnon Shashua Kevin Leyton-Brown Yoav Shoham\\nAI21 Labs\\n{orir,yoavl,itayd,dorm,amnons,kevinlb,yoavs}@ai21.com\\nAbstract\\nRetrieval-Augmented Language Modeling\\n(RALM) methods, which condition a lan-\\nguage model (LM) on relevant documents\\nfrom a grounding corpus during generation,\\nwere shown to signi\\ue000cantly improve lan-\\nguage modeling performance. In addition,\\nthey can mitigate the problem of factually\\ninaccurate text generation and provide natu-\\nral source attribution mechanism. Existing\\nRALM approaches focus on modifying the\\nLM architecture in order to facilitate the in-\\ncorporation of external information, signi\\ue000-\\ncantly complicating deployment. This paper\\nconsiders a simple alternative, which we dub\\nIn-Context RALM: leaving the LM architec-\\nture unchanged and prepending grounding\\ndocuments to the input,without any further\\ntraining of the LM. We show that In-Context',\n",
              " 'RALM that builds on off-the-shelf general\\npurpose retrievers provides surprisingly large\\nLM gains across model sizes and diverse cor-\\npora. We also demonstrate that the document\\nretrieval and ranking mechanism can be spe-\\ncialized to the RALM setting to further boost\\nperformance. We conclude that In-Context\\nRALM has considerable potential to increase\\nthe prevalence of LM grounding, particularly\\nin settings where a pretrained LM must be\\nused without modi\\ue000cation or even via API\\naccess.1\\n1 Introduction\\nRecent advances in language modeling (LM) have\\ndramatically increased the usefulness of machine-\\ngenerated text across a wide range of use-cases\\nand domains ( Brown et al. ,2020 ). However, the\\nmainstream paradigm of generating text with LMs\\nbears inherent limitations in access to external\\nknowledge. First, LMs are not coupled with any\\n∗Equal contribution.\\n1Our code is available at https://github.com/\\nAI21Labs/in-context-ralm\\nFigure 1: Our framework, dubbedIn-Context',\n",
              " 'RALM, provides large language modeling gains on\\nthe test set of WikiText-103,without modifying the\\nLM. Adapting the use of a BM25 retriever ( Robert-\\nson and Zaragoza ,2009) to the LM task (§ 5) yields\\nsigni\\ue000cant gains, and choosing the grounding doc-\\numents via our new class of Predictive Rerankers\\n(§6) provides a further boost. See Table 1for the\\nfull results on\\ue000ve diverse corpora.\\nsource attribution, and must be trained in order\\nto incorporate up-to-date information that was not\\nseen during training. More importantly, they tend\\nto produce factual inaccuracies and errors ( Lin\\net al. ,2022 ;Maynez et al. ,2020 ;Huang et al. ,\\n2020 ). This problem is present in any LM gen-\\neration scenario, and is exacerbated when gener-\\nation is made in uncommon domains or private\\ndata. A promising approach for addressing the\\nabove is Retrieval-Augmented Language Modeling\\n(RALM), grounding the LM during generation by\\nconditioning on relevant documents retrieved from',\n",
              " 'an external knowledge source. RALM systems in-\\nclude two high level components: (i)document se-\\nlection, selecting the set of documents upon which\\nto condition; and (ii)document reading, determin-\\ning how to incorporate the selected documents into\\nthe LM generation process.\\nLeading RALM systems introduced recently\\narXiv:2302.00083v3  [cs.CL]  1 Aug 2023Figure 2: An example ofIn-Context RALM: we simply prepend the retrieved document before the input pre\\ue000x.\\ntend to be focused on altering the language model\\narchitecture ( Khandelwal et al. ,2020 ;Borgeaud\\net al.,2022;Zhong et al. ,2022;Levine et al. ,2022c ;\\nLi et al. ,2022). Notably, Borgeaud et al. (2022) in-\\ntroduced RETRO, featuring document reading via\\nnontrivial modi\\ue000cations that require further train-\\ning to the LM architecture, while using an off-the-\\nshelf frozen BERT retriever for document selec-\\ntion. Although the paper’s experimental\\ue000ndings\\nshowed impressive performance gains, the need for',\n",
              " 'changes in architecture and dedicated retraining\\nhas hindered the wide adoption of such models.\\nIn this paper, we show that a very simple doc-\\nument reading mechanism can have a large im-\\npact, and that substantial gains can also be made\\nby adapting the document selection mechanism to\\nthe task of language modeling. Thus, we show that\\nmany of the bene\\ue000ts of RALM can be achieved\\nwhile working with off-the-shelf LMs, even via\\nAPI access. Speci\\ue000cally, we consider a simple but\\npowerful RALM framework, dubbedIn-Context\\nRALM(presented in Section 3), which employs a\\nzero-effort document reading mechanism: we sim-\\nply prepend the selected documents to the LM’s\\ninput text (Figure 2).\\nSection 4describes our experimental setup. To\\nshow the wide applicability of our framework, we\\nperformed LM experiments on a suite of\\ue000ve di-\\nverse corpora: WikiText-103 ( Merity et al. ,2016 ),\\nRealNews ( Zellers et al. ,2019 ), and three datasets\\nfrom The Pile ( Gao et al. ,2021 ): ArXiv, Stack',\n",
              " 'Exchange and FreeLaw. We use open-source LMs\\nranging from 110M to 66B parameters (from the\\nGPT-2, GPT-Neo, OPT and LLaMA model fami-\\nlies).\\nIn Section 5we evaluate the application of off-\\nthe-shelf retrievers to our framework. In this\\nminimal-effort setting, we found that In-Context\\nRALM led to LM performance gains equivalent to\\nincreasing the LM’s number of parameters by 2–\\n3×across all of the text corpora we examined. In\\nSection 6we investigate methods for adapting doc-ument ranking to the LM task, a relatively under-\\nexplored RALM degree of freedom. Our adapta-\\ntion methods range from using a small LM to per-\\nform zero-shot ranking of the retrieved documents,\\nup to training a dedicated bidirectional reranker\\nby employingself-supervision from the LM signal.\\nThese methods lead to further gains in the LM task\\ncorresponding to an additional size increase of 2×\\nin the LM architecture. As a concrete example of\\nthe gains, a 345M parameter GPT-2 enhanced by',\n",
              " 'In-Context RALM outperforms a 762M parame-\\nter GPT-2 when employing an off-the-shelf BM25\\nretriever ( Robertson and Zaragoza ,2009 ), and out-\\nperforms a 1.5B parameter GPT-2 when employing\\nour trained LM-oriented reranker (see Figure 1).\\nFor large model sizes, our method is even more\\neffective: In-Context RALM with an off-the-shelf\\nretriever improved the performance of a 6.7B pa-\\nrameter OPT model to match that of a 66B param-\\neter parameter OPT model (see Figure 4).\\nIn Section 7we demonstrate the applicability\\nof In-Context RALM to downstream open-domain\\nquestions answering (ODQA) tasks.\\nIn a concurrent work, Shi et al. (2023 ) also sug-\\ngest to augment off-the-shelf LMs with retrieved\\ntexts by prepending them to the input. Their re-\\nsults are based on training a dedicated retriever for\\nlanguage modeling. In contrast, we focus on the\\ngains achievable in using off-the-shelf retrievers\\nfor this task. We show strong gains of this simpler',\n",
              " 'setting by investigating: (1) which off-the-shelf\\nretriever is best suited for language modeling, (2)\\nthe frequency of retrieval operations, and (3) the\\noptimal query length. In addition, we boost the off-\\nthe-shelf retrieval performance by introducing two\\nreranking methods that demonstrate further gains\\nin perplexity.\\nWe believe that In-Context RALM can play two\\nimportant roles in making RALM systems more\\npowerful and more prevalent. First, given its simple\\nreading mechanism, In-Context RALM can serve\\nas a clean probe for developing document retrievalmethods that are specialized for the LM task. These\\nin turn can be used to improve both In-Context\\nRALM and other more elaborate RALM methods\\nthat currently leverage general purpose retrievers.\\nSecond, due to its compatibility with off-the-shelf\\nLMs, In-Context RALM can help drive wider de-\\nployment of RALM systems.\\n2 Related Work\\nRALM approaches can be roughly divided into two\\nfamilies of models: (i)nearest-neighbor language',\n",
              " 'models(also called kNN-LM), and (ii)retrieve\\nand read models. Our work belongs to the second\\nfamily, but is distinct in that it involves no further\\ntraining of the LM.\\nNearest Neighbor Language ModelsThe kNN-\\nLM approach was\\ue000rst introduced in Khandel-\\nwal et al. (2020 ). The authors suggest a simple\\ninference-time model that interpolates between two\\nnext-token distributions: one induced by the LM\\nitself, and one induced by the kneighbors from the\\nretrieval corpus that are closest to the query token in\\nthe LM embedding space. Zhong et al. (2022 ) sug-\\ngest a framework for training these models. While\\nthey showed signi\\ue000cant gains from kNN-LM, the\\napproach requires storing the representationsfor\\neach token in the corpus, an expensive requirement\\neven for a small corpus like Wikipedia. Although\\nnumerous approaches have been suggested for al-\\nleviating this issue ( He et al. ,2021 ;Alon et al. ,\\n2022), scaling any of them to large corpora remains\\nan open challenge.',\n",
              " 'an open challenge.\\nRetrieve and Read ModelsThis family of\\nRALMs creates a clear division betweendocument\\nselectionanddocument readingcomponents. All\\nprior work involves training the LM. We begin by\\ndescribing works that use this approach for tack-\\nling downstream tasks, and then mention works ori-\\nented towards RALM. Lewis et al. (2020) and Izac-\\nard and Grave (2021 )\\ue000ne tuned encoder–decoder\\narchitectures for downstream knowledge-intensive\\ntasks. Izacard et al. (2022b ) explored different\\nways of pretraining such models, while Levine\\net al. (2022c ) pretrained an autoregressive LM on\\nclusters of nearest neighbors in sentence embed-\\nding space. Levine et al. (2022a ) showed competi-\\ntive open domain question-answering performance\\nby prompt-tuning a frozen LM as a reader. Guu\\net al. (2020 ) pretrained REALM, a retrieval aug-\\nmentedbidirectional, maskedLM, later\\ue000ne-tunedfor open-domain question answering. The work\\nclosest to this paper—with a focus on the language',\n",
              " 'modeling task—is RETRO ( Borgeaud et al. ,2022),\\nwhich modi\\ue000es an autoregressive LM to attend to\\nrelevant documents via chunked cross-attention,\\nthus introducing new parameters to the model. Our\\nIn-Context RALM differs from prior work in this\\nfamily of models in two key aspects:\\n•We useoff-the-shelfLMs for document read-\\ningwithout any further training of the LM.\\n•We focus onhow to choose documents for\\nimproved LM performance.\\n3 Our Framework\\n3.1 In-Context RALM\\nLanguage models de\\ue000ne probability distributions\\nover sequences of tokens. Given such a sequence\\nx1, ..., x n, the standard way to model its probabil-\\nity is via next-token prediction: p(x 1, ..., x n) =\\ue007n\\ni=1p(x i|x<i), where x<i:=x 1, ..., x i−1is the\\nsequence of tokens preceding xi, also referred to\\nas itspre\\ue000x. This autoregressive model is usu-\\nally implemented via a learned transformer net-\\nwork ( Vaswani et al. ,2017 ) parameterized by the\\nset of parametersθ:\\np(x 1, ..., x n) =n\\ue009\\ni=1pθ(xi|x<i),(1)',\n",
              " 'i=1pθ(xi|x<i),(1)\\nwhere the conditional probabilities are modeled\\nby employing a causal self-attention mask ( Rad-\\nford et al. ,2018 ). Notably, leading LMs such\\nas GPT-2 ( Radford et al. ,2019 ), GPT-3 ( Brown\\net al.,2020 ), OPT ( Zhang et al. ,2022 ) or Jurassic-\\n1 (Lieber et al. ,2021 ) follow this simple parame-\\nterization.\\nRetrieval augmented language models (RALMs)\\nadd an operation that retrieves one or more docu-\\nments from an external corpus C, and condition the\\nabove LM predictions on these documents. Speci\\ue000-\\ncally, for predicting xi, the retrieval operation from\\nCdepends on its pre\\ue000x: RC(x<i), so the most\\ngeneral RALM decomposition is: p(x 1, ..., x n) =\\ue007n\\ni=1p(x i|x<i,RC(x<i)). In order to condition\\nthe LM generation on the retrieved document, pre-\\nvious RALM approaches used specialized architec-\\ntures or algorithms (see § 2). Inspired by the suc-\\ncess of In-Context Learning ( Brown et al. ,2020 ;\\nDong et al. ,2023 ),In-Context RALMrefers to the',\n",
              " 'following speci\\ue000c, simple method of concatenatingthe retrieved documents2within the Transformer’s\\ninput prior to the pre\\ue000x (see Figure 2),which does\\nnot involve altering the LM weightsθ:\\np(x 1, ..., x n) =\\nn\\ue009\\ni=1pθ(xi|[R C(x<i);x <i]),(2)\\nwhere [a;b] denotes the concatenation of strings a\\nandb.\\nSince common Transformer-based LM imple-\\nmentations support limited length input sequences,\\nwhen the concatenation of the document and the\\ninput sequence exceed this limit we remove to-\\nkens from the beginning of xuntil the overall input\\nlength equals that allowed by the model. Because\\nour retrieved documents are passages of limited\\nlength, we always have enough context left from x\\n(see § 4.3).\\n3.2 RALM Design Choices\\nWe detail below two practical design choices often\\nmade in RALM systems. In § 5, we investigate the\\neffect of these in the setting of In-Context RALM.\\nRetrieval StrideWhile in the above formulation\\na retrieval operation can occur at each generation',\n",
              " 'step, we might want to perform retrieval only once\\nevery s >1 tokens due to the cost of calling the\\nretriever, and the need to replace the documents in\\nthe LM pre\\ue000x during generation. We refer to sas\\ntheretrieval stride. This gives rise to the follow-\\ning In-Context RALM formulation (which reduces\\nback to Eq. ( 2) fors= 1):\\np(x 1, ..., x n) =\\nns−1\\ue009\\nj=0s\\ue009\\ni=1pθ\\ue000\\nxs·j+i|\\ue002\\nRC(x≤s·j);x <(s·j+i)\\ue003\\ue001\\n,\\n(3)\\nwheren s=n/sis the number of retrieval strides.\\nNotably, in this framework the runtime costs of\\neach retrieval operation is composed of (a) apply-\\ning the retriever itself, and (b) recomputing the\\nembeddings of the pre\\ue000x. In § 5.2we show that us-\\ning smaller retrieval strides,i.e., retrieving as often\\nas possible, is superior to using larger ones (though\\nIn-Context RALM with larger strides already pro-\\nvides large gains over vanilla LM). Thus, choosing\\nthe retrieval stride is ultimately a tradeoff between\\nruntime and performance.\\n2We always use asingle document, but it is conceptually',\n",
              " 'simple to support multiple documents as well.Retrieval Query LengthWhile the retrieval\\nquery above in principle depends on all pre\\ue000x to-\\nkens x≤s·j, the information at the very end of the\\npre\\ue000x is typically the most relevant to the generated\\ntokens. If the retrieval query is too long then this in-\\nformation can be diluted. To avoid this, we restrict\\nthe retrieval query at stride jto the last ℓtokens\\nof the pre\\ue000x,i.e., we use qs,ℓ\\nj:=x s·j−ℓ+1 , ..., x s·j.\\nWe refer to ℓas theretrieval query length. Note that\\nprior RALM work couples the retrieval stride sand\\nthe retrieval query length ℓ(Borgeaud et al. ,2022).\\nIn §5, we show that enforcing s=ℓdegrades LM\\nperformance. Integrating these hyper-parameters\\ninto the In-Context RALM formulation gives\\np(x 1, ..., x n) =\\nns−1\\ue009\\nj=0s\\ue009\\ni=1pθ\\ue004\\nxs·j+i|\\ue00a\\nRC(qs,ℓ\\nj);x <(s·j+i)\\ue00b\\ue005\\n.\\n(4)\\n4 Experimental Details\\nWe now describe our experimental setup, including\\nall models we use and their implementation details.\\n4.1 Datasets',\n",
              " '4.1 Datasets\\nWe evaluated the effectiveness of In-Context\\nRALM across\\ue000ve diverse language modeling\\ndatasets and two common open-domain question\\nanswering datasets.\\nLanguage ModelingThe\\ue000rst LM dataset is\\nWikiText-103( Merity et al. ,2016 ), which has been\\nextensively used to evaluate RALMs ( Khandelwal\\net al.,2020 ;He et al. ,2021 ;Borgeaud et al. ,2022 ;\\nAlon et al. ,2022 ;Zhong et al. ,2022 ). Second, we\\nchose three datasets spanning diverse subjects from\\nThe Pile ( Gao et al. ,2021):ArXiv,Stack Exchange\\nandFreeLaw. Finally, we also investigatedReal-\\nNews( Zellers et al. ,2019 ), since The Pile lacks a\\ncorpus focused only on news (which is by nature a\\nknowledge-intensive domain).\\nOpen-Domain Question AnsweringIn order\\nto evaluate In-Context RALM on downstream\\ntasks as well, we use theNatural Questions(NQ;\\nKwiatkowski et al. 2019 ) andTriviaQA( Joshi et al. ,\\n2017 ) open-domain question answering datasets.\\n4.2 Models\\nLanguage ModelsWe performed our experi-',\n",
              " 'ments using the four models of GPT-2 (110M–\\n1.5B; Radford et al. 2019 ), three models of GPT-\\nNeo and GPT-J (1.3B–6B; Black et al. 2021 ;Wangand Komatsuzaki 2021 ), eight models of OPT\\n(125M–66B; Zhang et al. 2022 ) and three mod-\\nels of LLaMA (7B–33B; Touvron et al. 2023 ). All\\nmodels are open source and publicly available.3\\nWe elected to study these particular models for\\nthe following reasons. The\\ue000rst four (GPT-2) mod-\\nels were trained on WebText ( Radford et al. ,2019),\\nwith Wikipedia documents excluded from their\\ntraining datasets. We were thus able to evaluate our\\nmethod’s “zero-shot” performance when retrieving\\nfrom a novel corpus (for WikiText-103). The rest of\\nthe models brought two further bene\\ue000ts. First, they\\nallowed us to investigate how our methods scale\\nto models larger than GPT-2. Second, the fact that\\nWikipedia was part of their training data allowed us\\nto investigate the usefulness of In-Context RALM\\nfor corpora seen during training. The helpfulness',\n",
              " 'of such retrieval has been demonstrated for previ-\\nous RALM methods ( Khandelwal et al. ,2020) and\\nhas also been justi\\ue000ed theoretically by Levine et al.\\n(2022c ).\\nWe ran all models with a maximum sequence\\nlength of 1,024, even though GPT-Neo, OPT and\\nLLaMA models support a sequence length of\\n2,048.4\\nRetrieversWe experimented with both sparse\\n(word-based) and dense (neural) retrievers. We\\nused BM25 ( Robertson and Zaragoza ,2009) as our\\nsparse model. For dense models, we experimented\\nwith (i) a frozen BERT-base ( Devlin et al. ,2019 )\\nfollowed by mean pooling, similar to Borgeaud\\net al. (2022 ); and (ii) the Contriever ( Izacard et al. ,\\n2022a ) and Spider ( Ram et al. ,2022 ) models,\\nwhich are dense retrievers that were trained in un-\\nsupervised manners.\\nRerankingWhen training rerankers (Sec-\\ntion6.2), we initialized from RoBERTa-base ( Liu\\net al.,2019 ).\\n4.3 Implementation Details\\nWe implemented our code base using the Trans-\\nformers library ( Wolf et al. ,2020 ). We based',\n",
              " 'our dense retrieval code on the DPR repository\\n(Karpukhin et al. ,2020 ).\\n3All models are available for use use via https://\\nhuggingface.co/\\n4In preliminary experiments, we observed similar improve-\\nments from In-Context RALM when using a sequence length\\nof 2,048. We used a sequence length of 1,024 in order to\\nfacilitate a direct comparison between all models.\\nFigure 3: The performance of four off-the-shelf\\nretrievers used for In-Context RALM on the de-\\nvelopment set of WikiText-103. All RALMs are\\nrun with s= 4 (i.e., retrieval is applied every four\\ntokens). For each RALM, we report the result of\\nthe best query lengthℓ(see Figures 6,9,10).\\nRetrieval CorporaFor WikiText-103 and\\nODQA datasets, we used the Wikipedia corpus\\nfrom Dec. 20, 2018, standardized by Karpukhin\\net al. (2020 ) using the preprocessing from Chen\\net al. (2017 ). To avoid contamination, we found\\nand removed all 120 articles of the development\\nand test set of WikiText-103 from the corpus. For',\n",
              " 'the remaining datasets, we used their training\\ndata as the retrieval corpus. Similar to Karpukhin\\net al. (2020 ), our retrieval corpora consist of\\nnon-overlapping passages of 100 words (which\\ntranslate to less than 150 tokens for the vast\\nmajority of passages). Thus, we truncate our\\nretrieved passages at 256 tokens when input to the\\nmodels, but they are usually much smaller.\\nRetrievalFor sparse retrieval, we used the Py-\\nserini library ( Lin et al. ,2021 ). For dense retrieval,\\nwe applied exact search using FAISS ( Johnson\\net al.,2021 ).\\n5 The Effectiveness of In-Context RALM\\nwith Off-the-Shelf Retrievers\\nWe now empirically show that despite its simple\\ndocument reading mechanism, In-Context RALM\\nleads to substantial LM gains across our diverse\\nevaluation suite. We begin in this section by inves-\\ntigating the effectiveness of off-the-shelf retrievers\\nfor In-Context RALM; we go on in § 6to show\\nthat further LM gains can be made by tailoring\\ndocument ranking functions to the LM task.',\n",
              " 'The experiments in this section provided us\\nwith a recommended con\\ue000guration for applying In-Model Retrieval RerankingWikiText-103 RealNews ArXiv Stack Exch. FreeLaw\\nword ppl token ppl token ppl token ppl token ppl\\nGPT-2 S– – 37.5 21.3 12.0 12.8 13.0\\nBM25 § 5– 29.6 16.1 10.9 11.3 9.6\\nBM25 Zero-shot § 6.1 28.6 15.5 10.1 10.6 8.8\\nBM25 Predictive § 6.2 26.8 – – – –\\nGPT-2 M– – 26.3 15.7 9.3 8.8 9.6\\nBM25 § 5– 21.5 12.4 8.6 8.1 7.4\\nBM25 Zero-shot § 6.1 20.8 12.0 8.0 7.7 6.9\\nBM25 Predictive § 6.2 19.7 – – – –\\nGPT-2 L– – 22.0 13.6 8.4 8.5 8.7\\nBM25 § 5– 18.1 10.9 7.8 7.8 6.8\\nBM25 Zero-shot § 6.1 17.6 10.6 7.3 7.4 6.4\\nBM25 Predictive § 6.2 16.6 – – – –\\nGPT-2 XL– – 20.0 12.4 7.8 8.0 8.0\\nBM25 § 5– 16.6 10.1 7.2 7.4 6.4\\nBM25 Zero-shot § 6.1 16.1 9.8 6.8 7.1 6.0\\nBM25 Predictive § 6.2 15.4 – – – –\\nTable 1: Perplexity on the test set of WikiText-103, RealNews and three datasets from the Pile. For\\neach LM, we report: (a) its performance without retrieval, (b) its performance when fed the top-scored',\n",
              " 'passage by BM25 (§ 5), and (c) its performance when applied on the top-scored passage of each of our two\\nsuggested rerankers (§ 6). All models share the same vocabulary, thus token-level perplexity (token ppl)\\nnumbers are comparable. For WikiText we follow prior work and report word-level perplexity (word ppl).\\nModel RetrievalWikiText-103\\nword ppl\\nLLaMA-7B- 9.9\\nBM25, § 5 8.8\\nLLaMA-13B- 8.5\\nBM25, § 5 7.6\\nLLaMA-33B- 6.3\\nBM25, § 5 6.1\\nTable 2: The performance of models from the\\nLLaMA family, measured by word-level perplexity\\non the test set of WikiText-103.\\nContext RALM: applying a sparse BM25 retriever\\nthat receives ℓ= 32 query tokens and is applied\\nas frequently as possible. Practically, we retrieve\\nevery s= 4 tokens ( ℓandsare de\\ue000ned in § 3).\\nTable 1shows for the GPT-2 models that across\\nall the examined corpora, employing In-Context\\nRALM with an off-the-shelf retriever improved\\nLM perplexity to a suf\\ue000cient extent that it matched\\nthat of a 2–3×larger model. Figure 4and Tables 2',\n",
              " 'and5show that this trend holds across model sizes\\nup to 66B parameters, for both WikiText-103 andRealNews.\\n5.1 BM25 Outperforms Off-the-Shelf Neural\\nRetrievers in Language Modeling\\nWe experimented with different off-the-shelf gen-\\neral purpose retrievers, and found that the sparse\\n(lexical) BM25 retriever ( Robertson and Zaragoza ,\\n2009 ) outperformed three popular dense (neu-\\nral) retrievers: the self-supervised retrievers Con-\\ntriever ( Izacard et al. ,2022a ) and Spider ( Ram et al. ,\\n2022 ), as well as a retriever based on the average\\npooling of BERT embeddings that was used in\\nthe RETRO system ( Borgeaud et al. ,2022 ). We\\nconducted a minimal hyper-parameter search on\\nthe query length ℓfor each of the retrievers, and\\nfound that ℓ= 32 was optimal for BM25 (Fig-\\nure6), and ℓ= 64 worked best for dense retrievers\\n(Figures 9,10).\\nFigure 3compares the performance gains of In-\\nContext RALM with these four general-purpose re-\\ntrievers. The BM25 retriever clearly outperformed',\n",
              " 'all dense retrievers. This outcome is consistent\\nwith prior work showing that BM25 outperforms\\nneural retrievers across a wide array of tasks, when\\napplied in zero-shot settings ( Thakur et al. ,2021 ).\\nThis result renders In-Context RALM even moreFigure 4: Results of OPT models ( Zhang et al. ,2022 ) on the test set of WikiText-103 (word-level\\nperplexity) and the development set of RealNews (token-level perplexity). In-Context RALM models use\\na BM25 retriever with s= 4 (i.e., the retriever is called every four tokens) and ℓ= 32 (i.e., the retriever\\nquery is comprised of the last 32 tokens of the pre\\ue000x).In-Context RALM with an off-the-shelf retriever\\nimproved the performance of a 6.7B parameter OPT model to match that of a 66B parameter OPT model.\\nappealing since applying a BM25 retriever is sig-\\nni\\ue000cantly cheaper than the neural alternatives.\\n5.2 Frequent Retrieval Improves Language\\nModeling\\nWe investigated the effect of varying the retrieval',\n",
              " 'stride s(i.e., the number of tokens between consec-\\nutive retrieval operations). Figure 5shows that LM\\nperformance improved as the retrieval operation\\nbecame more frequent. This supports the intuition\\nthat retrieved documents become more relevant the\\ncloser the retrieval query becomes to the gener-\\nated tokens. Of course, each retrieval operation\\nimposes a runtime cost. To balance performance\\nand runtime, we used s= 4 in our experiments.\\nFor comparison, RETRO employed a retrieval fre-\\nquency of s= 64 (Borgeaud et al. ,2022 ), which\\nleads to large degradation in perplexity. Intuitively,\\nretrieving with high frequency (low retrieval stride)\\nallows to ground the LM in higher resolution.5.3 A Contextualization vs. Recency Tradeoff\\nin Query Length\\nWe also investigated the effect of varying ℓ, the\\nlength of the retrieval query for BM25. Figure 6\\nreveals an interesting tradeoff and a sweet spot\\naround a query length of 32tokens. Similar ex-\\nperiments for dense retrievers are given in App. A.',\n",
              " 'We conjecture that when the retriever query is too\\nshort, it does not include enough of the input con-\\ntext, decreasing the retrieved document’s relevance.\\nConversely, excessively growing the retriever query\\ndeemphasizes the tokens at the very end of the pre-\\n\\ue000x, diluting the query’s relevance to the LM task.\\n6 Improving In-Context RALM with\\nLM-Oriented Reranking\\nSince In-Context RALM uses a\\ue000xed document\\nreading component by de\\ue000nition, it is natural to\\nask whether performance can be improved by spe-\\ncializing its document retrieval mechanism to the\\nLM task. Indeed, there is considerable scope for\\nimprovement: the previous section considered con-\\nditioning the model only on the\\ue000rst document re-Figure 5: An analysis of perplexity as a function\\nofs, theretrieval stride,i.e., the number of tokens\\nbetween consecutive retrieval operations, on the\\ndevelopment set of WikiText-103. Throughout the\\npaper, we use s= 4 to balance perplexity and\\nruntime.',\n",
              " 'runtime.\\nFigure 6: An analysis of perplexity as a function\\nofthe number of tokens in the query ℓfor BM25\\non the development set of WikiText-103. In the\\nappendix, we show similar trade-offs for dense\\nretrievers within WikiText-103. Throughout the\\npaper, we use a query length ofℓ= 32tokens.\\ntrieved by the BM25 retriever. This permits very\\nlimited semantic understanding of the query, since\\nBM25 is based only on the bag of words signal.\\nMoreover, it offers no way to accord different de-\\ngrees of importance to different retrieval query to-\\nkens, such as recognizing that later query tokens\\nare more relevant to the generated text.\\nIn this section, we focus on choosing which doc-\\nument to present to the model, by reranking the\\ntop-kdocuments returned by the BM25 retriever.5\\nWe use Figure 7as motivation: it shows the large\\npotential for improvement among the top- 16docu-\\nments returned by the BM25 retriever. We act upon\\n5In both § 6.1and § 6.2we usek= 16.',\n",
              " 'Figure 7:Potential for gainsfrom reranking: per-\\nplexity improvement (on the development set of\\nWikiText-103) from an oracle that takes the best\\nof the top-16 documents retrieved by BM25 rather\\nthan the\\ue000rst.\\nthis motivation by using two rerankers. Speci\\ue000-\\ncally, in § 6.1we show performance gains across\\nour evaluation suite obtained by using an LM to\\nperform zero-shot reranking of the top- kBM25\\nretrieved documents (results in third row for each\\nof the models in Table 1). Then, in § 6.2we show\\nthat training a specialized bidirectional reranker\\nof the top- kBM25 retrieved documents in a self-\\nsupervised manner via the LM signal can provide\\nfurther LM gains (results in forth row for each of\\nthe models in Table 1).\\n6.1 LMs as Zero-Shot Rerankers\\nFirst, we used off-the-shelf language models as\\ndocument rerankers for the In-Context RALM set-\\nting. Formally, for a query qconsisting of the\\nlastℓtokens in the pre\\ue000x of the LM input x, let\\n{d1, ..., d k}be the top- kdocuments returned by',\n",
              " 'BM25. For retrieval iteration j, let the text for\\ngeneration be y:=x s·j+1 , ..., x s·j+s. Ideally, we\\nwould like to\\ue000nd the document di∗that maximizes\\nthe probability of the text for generation,i.e.,\\ni∗= arg max\\ni∈[k]pθ(y|[d i;x≤s·j]).(5)\\nHowever, at test time we do not have access to\\nthe tokens of y. Instead, we used the lastpre-\\n\\ue000xtokens (whichareavailable at test time), de-\\nnoted by y′, for reranking. Formally, let s′be\\na hyper-parameter that determines the number of\\nthe pre\\ue000x tokens by which to rerank. We de\\ue000ne\\ny′:=x s·j−s′+1, ..., x s·j(i.e., the stride of length s′\\nthat precedes y) and choose the document dˆisuchModelReranking\\nModelWikiText-103 RealNews\\nword ppl token ppl\\nGPT-2 345M (M)GPT-2 110M (S) 20.8 12.1\\nGPT-2 345M (M) 20.8 12.0\\nGPT-2 762M (L)GPT-2 110M (S) 17.7 10.7\\nGPT-2 762M (L) 17.6 10.6\\nGPT-2 1.5B (XL)GPT-2 110M (S) 16.2 9.9\\nGPT-2 1.5B (XL) 16.1 9.8\\nTable 3: Perplexity for zero-shot reranking (§ 6.1) where the reranking models is smaller than the LM, or',\n",
              " 'the LM itself. Reranking is performed on the top 16 documents retrieved by BM25. Using a GPT-2 110M\\n(S) instead of a larger language model as a reranker leads to only a minor degradation.\\nthat\\nˆi= arg max\\ni∈[k]pϕ(y′|\\ue002\\ndi;x≤(s·j−s′)\\ue003\\n). (6)\\nThe main motivation is that since BM25 is a lexical\\nretriever, we want to incorporate a semantic signal\\ninduced by the LM. Also, this reranking shares con-\\nceptual similarities with the reranking framework\\nofSachan et al. (2022 ) for open-domain question\\nanswering, where y′(i.e., the last pre\\ue000x tokens) can\\nbe thought of as their “question”.\\nNote that our zero-shot reranking does not re-\\nquire that the LM used for reranking is the same\\nmodel as the LM used for generation (i.e., the LM\\nin Eq. (6), parameterized by ϕ, does not need to be\\nthe LM in Eq. (2), parameterized by θ). This ob-\\nservation unlocks the possibility of reranking with\\nsmaller (and thus faster) models, which is impor-\\ntant for two main reasons: (i) Reranking kdocu-',\n",
              " 'ments requires kforward passes; and (ii) it allows\\nour methods to be used in cases where the actual\\nLM’s log probabilities are not available (for exam-\\nple, when the LM is accessed through an API).6\\nResultsA minimal hyper-parameter search on\\nthe development set of WikiText-103 revealed that\\nthe optimal query length is s′= 16 ,7so we proceed\\nwith this value going forward. Table 1shows the\\nresults of letting the LM perform zero-shot rerank-\\ning on the top-16 documents retrieved by BM25\\n(third row for each of the models). It is evident\\nthat reranking yielded consistently better results\\nthan simply taking the\\ue000rst result returned by the\\nretriever.\\n6Note we do not require that the two models share the\\nsame vocabulary.\\n7We experimented withs′∈{4,8,16,32}.Table 3shows that a small LM (GPT-2 117M)\\ncan be used to rerank the documents for all larger\\nGPT-2 models, with roughly the same performance\\nas having each LM perform reranking for itself,\\nsupporting the applicability of this method for LMs',\n",
              " 'that are only accessible via an API.\\n6.2 Training LM-dedicated Rerankers\\nNext, wetraineda reranker to choose one of the\\ntop-kdocuments retrieved by BM25. We refer to\\nthis approach asPredictive Reranking, since the\\nreranker learns to choose which document will help\\nin “predicting” the upcoming text. For this process,\\nwe assume availability of training data from the\\ntarget corpus. Our reranker is a classi\\ue000er that gets\\na pre\\ue000x x≤s·jand a document di(fori∈[k] ), and\\nproduces a scalar f(x ≤s·j, di)that should resemble\\nthe relevance ofd iforthe continuationofx ≤s·j.\\nWe then normalize these relevance scores:\\nprank(di|x≤s·j) =exp(f(x ≤s·j, di))\\ue006k\\ni′=1exp(f(x ≤s·j, di′)),(7)\\nand choose the documentd ˆisuch that\\nˆi= arg max\\ni∈[k]prank(di|x≤s·j).(8)\\nCollecting Training ExamplesTo train our pre-\\ndictive reranker, we collected training examples\\nas follows. Let x≤s·jbe a pre\\ue000x we sample from\\nthe training data, and y:=x s·j+1 , ..., x s·j+s be the\\ntext for generation upcoming in its next stride. We',\n",
              " 'run BM25 on the query qs,ℓ\\njderived from x≤s·j\\n(see § 3.2) and get kdocuments {d1, ..., d k}. For\\neach document di, we then run the LM to compute\\npθ(y|[d i;x≤s·j])similar to Eq. ( 4).Figure 8: Zero-shot performance of In-Context\\nRALM on the development set of Natural Ques-\\ntions and TriviaQA, when varying the number of\\ndocuments (retrieved by DPR) shown in-context.\\nTrainingOur reranker was a\\ue000ne-tuned\\nRoBERTa-base ( Liu et al. ,2019 ) that trained for\\n10,000 steps with a peak learning rate of 10−5and\\na batch size of 32. Overall, we created 300,000\\nexamples from the training set of WikiText-103 as\\nexplained above. The loss function we use to train\\nthe reranker follows previous work ( Guu et al. ,\\n2020 ;Lewis et al. ,2020 ):\\n−logk\\ue008\\ni=1prank(di|x≤s·j)·p θ(y|[d i;x≤s·j]).(9)\\nNote that unlike those works, we train only the\\nreranker (p rank), keeping the LM weightsθfrozen.\\nResultsTable 1shows the result of our predictive\\nreranker, trained on WikiText-103. Speci\\ue000cally, we',\n",
              " 'trained it with data produced by GPT-2 110M (S),\\nand tested its effectiveness for all GPT-2 models.\\nWe observed signi\\ue000cant gains obtained from Predic-\\ntive Reranking. For example, the perplexity of GPT-\\n2 110M (S) improved from 29.6 to 26.8, and that of\\nGPT-2 1.5B (XL) improved from 16.6 to 15.4. This\\ntrend held for the other two models as well. Overall,\\nthese results demonstrate that training a reranker\\nwith domain-speci\\ue000c data was more effective than\\nzero-shot reranking (Section 6.1). Note that these\\nresults—while impressive—still leave room for fur-\\nther improvements, compared to the top-16 BM25\\noracle results (see Figure 7). Moreover, the oracle\\nresults themselves can be improved by retrieving\\nk >16 documents via a BM25 retriever, or by\\ntraining stronger retrievers dedicated to the RALM\\ntask. We leave this direction for future work.Model Retrieval NQ TriviaQA\\nLLaMA-7B- 10.3 47.5\\nDPR 28.0 56.0\\nLLaMA-13B- 12.0 54.8\\nDPR 31.0 60.1\\nLLaMA-33B- 13.7 58.3\\nDPR 32.3 62.7',\n",
              " 'DPR 32.3 62.7\\nTable 4: Zero-shot results of In-Context RALM on\\nthe test set of Natural Questions and TriviaQA mea-\\nsured by exact match. In the open-book setting, we\\ninclude the top two documents returned by DPR.\\n7 In-Context RALM for Open-Domain\\nQuestion Answering\\nSo far, we evaluated our framework on language\\nmodeling benchmarks. To test its ef\\ue000cacy in addi-\\ntional scenarios, and speci\\ue000cally downstream tasks,\\nwe now turn to evaluate In-Context RALM on open-\\ndomain question answering (ODQA; Chen et al.\\n2017 ). This experiment is intended to verify, in\\na controlled environment, that LMs can leverage\\nretrieved documentswithout further trainingand\\nwithout any training examples. Speci\\ue000cally, we\\nuse the LLaMA family ( Touvron et al. ,2023 )with\\nandwithoutIn-Context RALM (often referred to\\nin ODQA literature as open-book and closed-book\\nsettings, respectively). In contrast to most prior\\nwork on ODQA (e.g., Izacard and Grave 2021 ;Fa-\\njcik et al. 2021 ;Izacard et al. 2022b ;Levine et al.',\n",
              " '2022b ), our “reader” (i.e., the model that gets the\\nquestion along with its corresponding retrieved doc-\\numents, and returns the answer) is simply a frozen\\nlarge LM:notpretrained,\\ue000ne-tuned or prompted\\nto be retrieval-augmented. For the closed-book set-\\nting, we utilize the prompt of Touvron et al. (2023).\\nFor the open-book setting, we extend this prompt\\nto include retrieved documents (see App. C). We\\nuse DPR ( Karpukhin et al. ,2020 ) as our retriever.\\nVarying the Number of DocumentsTo inves-\\ntigate the the effect of the number of documents\\nshown to the model, we performed a minimal anal-\\nysis on the development set of NQ and TriviaQA.\\nFigure 8demonstrates that showing documents in-\\ncontext signi\\ue000cantly improves the model’s perfor-\\nmance. In addition, most of the gain can be ob-\\ntained by using only two documents (or even a\\nsingle one in some cases).ResultsTable 4gives the results of In-Context\\nRALM on the test set of Natural Questions and\\nTriviaQA. Motivated by our previous\\ue000ndings,',\n",
              " 'we used two retrieved documents. It is evident\\nthat showing the model relevant documents sig-\\nni\\ue000cantly boosted its performance. For example,\\nadding retrieved documents improved LLaMA-\\n13B in the zero-shot setting by more than 18 points\\non NQ (from 12.0% to 31.0%) and more than 5\\npoints on TriviaQA (from 54.8% to 60.1%).\\n8 Discussion\\nRetrieval from external sources has become a com-\\nmon practice in knowledge-intensive tasks (such\\nas factual question answering, fact checking, and\\nmore; Petroni et al. 2021 ). In parallel, recent break-\\nthroughs in LM generation capabilities has led to\\nLMs that can generate useful long texts. How-\\never, factual inaccuracies remain a common way in\\nwhich machine-generated text can fall short, and\\nlack of direct provenance makes it hard to trust\\nmachine generated text. This makes language mod-\\neling both a promising and an urgent new applica-\\ntion area for knowledge grounding, and motivates\\npromoting RALM approaches. Prior research has',\n",
              " 'already investigated RALM, of course, but it is\\nnot yet widely deployed. One likely reason is that\\nexisting approaches rely upon\\ue000ne-tuning the LM,\\nwhich is typically dif\\ue000cult and costly, and is even\\nimpossible for LMs accessible only via an API.\\nThis paper presented the framework ofIn-\\nContext RALM, enabling frozen, off-the-shelf LMs\\nto bene\\ue000t from retrieval. We demonstrated that\\nsubstantial performance gains can be achieved by\\nusing general purpose retrievers, and showed that\\nadditional gains can be achieved by tailoring the\\ndocument selection to the LM setting. A recent\\nwork by Muhlgay et al. (2023 ) demonstrates that\\nIn-Context RALM is indeed able to improve the\\nfactuality of large LMs.\\nSeveral directions for further improvement re-\\nmain for future work. First, this paper considers\\nonly the case of prepending a single external docu-\\nment to the context; adding more documents could\\ndrive further gains (for example, using the frame-\\nwork of Ratner et al. 2022 ). Second, we retrieved',\n",
              " 'documents every\\ue000xed interval of stokens, but see\\npotential for large latency and cost gains by retriev-\\ning more sparsely, such as only when a specialized\\nmodel predicts that retrieval is needed.\\nWe release the code used in this work, for thecommunity to use and improve over. We hope it\\nwill drive further research of RALM, which will\\nenable its wider adoption.\\nAcknowledgements\\nWe would like to thank the reviewers and the Ac-\\ntion Editor for their valuable feedback.']"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PDFS[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IPF5-pRbyW7",
        "outputId": "a9615db1-d31b-4a9a-efaa-01ad62210e10"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/PdfRag/clusterofstars/Self-Rag.pdf')"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.document_loaders.onedrive_file import CHUNK_SIZE\n",
        "# from langchain.document_loaders import TextLoader\n",
        "# from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter, RecursiveCharacterTextSplitter\n",
        "# CHUNK_SIZE = 1000\n",
        "# CHUNK_OVERLAP = 30\n",
        "\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=CHUNK_SIZE,\n",
        "#     chunk_overlap = CHUNK_OVERLAP,\n",
        "#     length_function=len,\n",
        "# )\n",
        "# #docs  = text_splitter.split_documents([doc.page_content for doc in all_pages])\n",
        "# docs = text_splitter.split_documents(all_pages)\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13SCU5ggV58M",
        "outputId": "515c145b-ef5d-40e5-e4bf-111f4d826a39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytufVlPBQnCL",
        "outputId": "e1ccc2f3-212a-45aa-c1b9-d54a836b1128"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Not yet sure if should use Qdrant or FAISS\n"
      ],
      "metadata": {
        "id": "YYbANb_jJpwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Qdrant, FAISS"
      ],
      "metadata": {
        "id": "Q2q-7KnPTNbV"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import CacheBackedEmbeddings, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.storage import LocalFileStore\n",
        "\n",
        "store = LocalFileStore(\"./cache/\")\n",
        "\n",
        "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "\n",
        "core_embeddings_model = HuggingFaceEmbeddings(\n",
        "    model_name=embed_model_id\n",
        ")\n",
        "\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    core_embeddings_model, store, namespace=embed_model_id\n",
        ")\n",
        "\n",
        "#vector_store = FAISS.from_documents(docs, embedder)\n",
        "#vector_store = FAISS.from_documents((docs[i][j] for i in range(len(docs)) for j in range(len(docs[i]))), embedder)"
      ],
      "metadata": {
        "id": "C5sJKllBTMyn"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#docs = [Document(page_content=doc[0]) for doc in docs]"
      ],
      "metadata": {
        "id": "nC9LtKwjjKjJ"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP8sJPR1k6Ea",
        "outputId": "01e57c9d-7926-4068-9d62-48ebaee874e1"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='In-Context Retrieval-Augmented Language Models\\nOri Ram∗Yoav Levine∗Itay Dalmedigos Dor Muhlgay\\nAmnon Shashua Kevin Leyton-Brown Yoav Shoham\\nAI21 Labs\\n{orir,yoavl,itayd,dorm,amnons,kevinlb,yoavs}@ai21.com\\nAbstract\\nRetrieval-Augmented Language Modeling\\n(RALM) methods, which condition a lan-\\nguage model (LM) on relevant documents\\nfrom a grounding corpus during generation,\\nwere shown to signi\\ue000cantly improve lan-\\nguage modeling performance. In addition,\\nthey can mitigate the problem of factually\\ninaccurate text generation and provide natu-\\nral source attribution mechanism. Existing\\nRALM approaches focus on modifying the\\nLM architecture in order to facilitate the in-\\ncorporation of external information, signi\\ue000-\\ncantly complicating deployment. This paper\\nconsiders a simple alternative, which we dub\\nIn-Context RALM: leaving the LM architec-\\nture unchanged and prepending grounding\\ndocuments to the input,without any further\\ntraining of the LM. We show that In-Context')"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vector_store = FAISS.from_documents(docs, embedder)\n",
        "#vector_store = FAISS.from_documents(docs[0], embedder)\n",
        "from langchain.schema.document import Document\n",
        "\n",
        "docs = [Document(page_content=doc[i]) for doc in docs for i in range(len(doc))]\n",
        "for index, pdf in enumerate(docs):\n",
        "   content = docs[index]\n",
        "   if index == 0:\n",
        "       vector_store = FAISS.from_documents([content], embedder)\n",
        "   else:\n",
        "      vector_store_i = FAISS.from_documents([content], embedder)\n",
        "      vector_store.merge_from(vector_store_i)\n",
        "\n",
        "\n",
        "vector_store.save_local(index_dir)"
      ],
      "metadata": {
        "id": "-0NEutY7FDGK"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Retrieval-augmented generation?\"\n",
        "embedding_vector = core_embeddings_model.embed_query(query)\n",
        "docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)\n",
        "\n",
        "for page in docs:\n",
        "  print(page.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LVQR6XgHPTA",
        "outputId": "0baaefe9-16ef-408e-abdf-653b5d70e901"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 I NTRODUCTION\n",
            "State-of-the-art LLMs continue to struggle with factual errors (Mallen et al., 2023; Min et al., 2023)\n",
            "despite their increased model and data scale (Ouyang et al., 2022). Retrieval-Augmented Generation\n",
            "(RAG) methods (Figure 1 left; Lewis et al. 2020; Guu et al. 2020) augment the input of LLMs\n",
            "with relevant retrieved passages, reducing factual errors in knowledge-intensive tasks (Ram et al.,\n",
            "2023; Asai et al., 2023a). However, these methods may hinder the versatility of LLMs or introduce\n",
            "unnecessary or off-topic passages that lead to low-quality generations (Shi et al., 2023) since they\n",
            "retrieve passages indiscriminately regardless of whether the factual grounding is helpful. Moreover,\n",
            "the output is not guaranteed to be consistent with retrieved relevant passages (Gao et al., 2023) since\n",
            "the models are not explicitly trained to leverage and follow facts from provided passages. This\n",
            "work introduces Self-Reflective Retrieval-augmented Generation ( SELF-RAG)to improve an\n",
            "LLM’s generation quality, including its factual accuracy without hurting its versatility, via on-demand\n",
            "retrieval and self-reflection. We train an arbitrary LM in an end-to-end manner to learn to reflect on\n",
            "its own generation process given a task input by generating both task output and intermittent special\n",
            "tokens (i.e., reflection tokens ). Reflection tokens are categorized into retrieval andcritique tokens to\n",
            "indicate the need for retrieval and its generation quality respectively (Figure 1 right). In particular,\n",
            "given an input prompt and preceding generations, SELF-RAGfirst determines if augmenting the\n",
            "continued generation with retrieved passages would be helpful. If so, it outputs a retrieval token that\n",
            "calls a retriever model on demand (Step 1). Subsequently, SELF-RAGconcurrently processes multiple\n",
            "retrieved passages, evaluating their relevance and then generating corresponding task outputs (Step\n",
            "engineering to improve the factuality of LLM generations.\n",
            "Baselines with retrievals. We evaluate models augmented with retrieval at test time or during training.\n",
            "The first category includes standard RAG baselines, where an LM (Llama2, Alpaca) generates output\n",
            "given the query prepended with the top retrieved documents using the same retriever as in our system.\n",
            "It also includes Llama2-FT, where Llama2 is fine-tuned on all training data we use without the\n",
            "reflection tokens or retrieved passages. We also report the result of retrieval-augmented baselines\n",
            "with LMs trained with private data: Ret-ChatGPT and Ret-Llama2-chat, which deploy the same\n",
            "augmentation technique above, as well as perplexity.ai, an InstructGPT-based production search\n",
            "system. The second category includes concurrent methods that are trained with retrieved text\n",
            "passages, i.e., SAIL (Luo et al., 2023) to instruction-tune an LM on the Alpaca instruction-tuning\n",
            "Preprint.\n",
            "SELF-RAG: LEARNING TO RETRIEVE , GENERATE ,AND\n",
            "CRITIQUE THROUGH SELF-REFLECTION\n",
            "Akari Asai†, Zeqiu Wu†, Yizhong Wang†§, Avirup Sil‡, Hannaneh Hajishirzi†§\n",
            "†University of Washington§Allen Institute for AI‡IBM Research AI\n",
            "{akari,zeqiuwu,yizhongw,hannaneh }@cs.washington.edu ,avi@us.ibm.com\n",
            "ABSTRACT\n",
            "Despite their remarkable capabilities, large language models (LLMs) often produce\n",
            "responses containing factual inaccuracies due to their sole reliance on the paramet-\n",
            "ric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad\n",
            "hoc approach that augments LMs with retrieval of relevant knowledge, decreases\n",
            "such issues. However, indiscriminately retrieving and incorporating a fixed number\n",
            "of retrieved passages, regardless of whether retrieval is necessary, or passages are\n",
            "relevant, diminishes LM versatility or can lead to unhelpful response generation.\n",
            "We introduce a new framework called Self-Reflective Retrieval-Augmented Gen-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Self-Rag?\"\n",
        "embedding_vector = core_embeddings_model.embed_query(query)\n",
        "docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)\n",
        "\n",
        "for page in docs:\n",
        "  print(page.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0vvt3ikTO_g",
        "outputId": "2a016520-7771-47da-c7eb-ab818fd6b4a1"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions are mostly aligned with their assessments. Appendix Table 6 shows several annotated\n",
            "examples and explanations on assessments.\n",
            "6 C ONCLUSION\n",
            "This work introduces SELF-RAG, a new framework to enhance the quality and factuality of LLMs\n",
            "through retrieval on demand and self-reflection. SELF-RAGtrains an LM to learn to retrieve, generate,\n",
            "and critique text passages and its own generation by predicting the next tokens from its original\n",
            "vocabulary as well as newly added special tokens, called reflection tokens. SELF-RAGfurther enables\n",
            "the tailoring of LM behaviors at test time by leveraging reflection tokens. Our holistic evaluations on\n",
            "six tasks using multiple metrics demonstrate that SELF-RAGsignificantly outperforms LLMs with\n",
            "more parameters or with conventional retrieval-augmented generation approaches.\n",
            "10Preprint.\n",
            "ETHICAL CONCERNS\n",
            "This work aims to improve the factuality of LLM outputs, the lack of which continues to cause nu-\n",
            "3 S ELF-RAG: LEARNING TO RETRIEVE , GENERATE AND CRITIQUE\n",
            "We introduce Self-Reflective Retrieval-Augmented Generation ( SELF-RAG), shown in Figure 1.\n",
            "SELF-RAGis a framework that enhances the quality and factuality of an LLM through retrieval and\n",
            "self-reflection, without sacrificing LLM’s original creativity and versatility. Our end-to-end training\n",
            "lets an LM Mgenerate text informed by retrieved passages, if needed, and criticize the output by\n",
            "learning to generate special tokens. These reflection tokens (Table 1) signal the need for retrieval\n",
            "or confirm the output’s relevance, support, or completeness. In contrast, common RAG approaches\n",
            "retrieve passages indiscriminately, without ensuring complete support from cited sources.\n",
            "3.1 P ROBLEM FORMALIZATION AND OVERVIEW\n",
            "Formally, given input x, we train Mto sequentially generate textual outputs yconsisting of multiple\n",
            "segments y= [y1, . . . , y T], where ytindicates a sequence of tokens for the t-th segment.3Generated\n",
            "performance. In particular, we randomly sample 5k, 10k, 20k, and 50k instances from our original\n",
            "150k training instances, and fine-tune four SELF-RAG 7Bvariants on those subsets. Then, we compare\n",
            "the model performance on PopQA, PubHealth, and ASQA (citation precision) with our final SELF-\n",
            "RAGtrained on the full 150k instances. We also evaluate Figures 4a, 4b and 4c shows the models’\n",
            "performance trained on different amount of data. Across all datasets, increasing data size often shows\n",
            "upward trajectories and the improvements are significantly larger in PopQA and ASQA, while we do\n",
            "not observed such significant improvements on Llama2-FT 7Bwhen increasing the training data from\n",
            "50k to 150k. These results also indicate that further expanding the training data of SELF-RAGmay\n",
            "lead to further improvements, although in this work we limit our training data size to 150k.\n",
            "Human evaluations. We conduct small human evaluations on SELF-RAGoutputs, as well as the\n",
            "eration ( SELF-RAG)that enhances an LM’s quality and factuality through retrieval\n",
            "and self-reflection. Our framework trains a single arbitrary LM that adaptively\n",
            "retrieves passages on-demand, and generates and reflects on retrieved passages\n",
            "and its own generations using special tokens, called reflection tokens. Generating\n",
            "reflection tokens makes the LM controllable during the inference phase, enabling it\n",
            "to tailor its behavior to diverse task requirements. Experiments show that SELF-\n",
            "RAG(7B and 13B parameters) significantly outperforms state-of-the-art LLMs\n",
            "and retrieval-augmented models on a diverse set of tasks. Specifically, SELF-RAG\n",
            "outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA,\n",
            "reasoning and fact verification tasks, and it shows significant gains in improving\n",
            "factuality and citation accuracy for long-form generations relative to these models.1\n",
            "1 I NTRODUCTION\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8BWF1sumEa4"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looks like retrieving from References section may be a problem!  Could experiment with different retriever or a smart-enough model (Self-Rag?)"
      ],
      "metadata": {
        "id": "Hmt8hMk2MfDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOOKS LIKE REMOVING REFERENCES ONWARDS INCREASED THE RETRIEVAL QUALITY NOTICEABLY"
      ],
      "metadata": {
        "id": "AY08J_IBmMQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGukhbm3TPDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Data Preparation\n",
        "\n",
        "In this task we'll be collecting, and then parsing, our data."
      ],
      "metadata": {
        "id": "FLrL342RtWxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/oppenheimer.csv"
      ],
      "metadata": {
        "id": "ruax_eiPgDBo",
        "outputId": "0519b5e3-b3ec-4d02-f852-1d9330e82cf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-04 20:56:55--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/oppenheimer.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80957 (79K) [text/plain]\n",
            "Saving to: ‘oppenheimer.csv’\n",
            "\n",
            "oppenheimer.csv     100%[===================>]  79.06K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-11-04 20:56:55 (33.7 MB/s) - ‘oppenheimer.csv’ saved [80957/80957]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/barbie.csv"
      ],
      "metadata": {
        "id": "K2gk_9V-gHKY",
        "outputId": "25f1e54a-d054-4758-a948-e6b21cdcc086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-04 20:56:57--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/barbie.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72289 (71K) [text/plain]\n",
            "Saving to: ‘barbie.csv’\n",
            "\n",
            "barbie.csv          100%[===================>]  70.59K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-11-04 20:56:57 (33.3 MB/s) - ‘barbie.csv’ saved [72289/72289]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Parsing\n",
        "\n",
        "Now that we have our data - let's go ahead and start parsing it into a more usable format for LangChain!\n",
        "\n",
        "We'll be using the `CSVLoader` for this application.\n",
        "\n",
        "Check out the docs here:\n",
        "- [CSVLoader](https://python.langchain.com/docs/integrations/document_loaders/csv)"
      ],
      "metadata": {
        "id": "JtBD1H8ezNLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders.csv_loader import CSVLoader"
      ],
      "metadata": {
        "id": "AdXub4CszAAt"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barbie_loader = CSVLoader(file_path=\"barbie.csv\", source_column=\"Review_Url\")\n",
        "\n",
        "barbie_data = barbie_loader.load()"
      ],
      "metadata": {
        "id": "piE3_eSi0KGC"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(barbie_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26SZD9zb3luR",
        "outputId": "de3fa678-3e22-4a93-d13c-23b1e902d38d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oppenheimer_loader = CSVLoader(file_path=\"oppenheimer.csv\", source_column=\"Review_Url\")\n",
        "\n",
        "oppenheimer_data = oppenheimer_loader.load()"
      ],
      "metadata": {
        "id": "u9T5hEouh0G6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(oppenheimer_data)"
      ],
      "metadata": {
        "id": "dUrUpodmh-S-",
        "outputId": "81170871-434a-4544-900b-183e8e23f65a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have collected our review information into a loader - we can go ahead and chunk the reviews into more manageable pieces.\n",
        "\n",
        "We'll be leveraging the `RecursiveCharacterTextSplitter` for this task today.\n",
        "\n",
        "While splitting our text seems like a simple enough task - getting this correct/incorrect can have massive downstream impacts on your application's performance.\n",
        "\n",
        "You can read the docs here:\n",
        "- [RecursiveCharacterTextSplitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter)\n",
        "\n",
        "> ### HINT:\n",
        ">It's always worth it to check out the LangChain source code if you're ever in a bind - for instance, if you want to know how to transform a set of documents, check it out [here](https://github.com/langchain-ai/langchain/blob/5e9687a196410e9f41ebcd11eb3f2ca13925545b/libs/langchain/langchain/text_splitter.py#L268C18-L268C18)"
      ],
      "metadata": {
        "id": "_CTameZZ0r76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000, # the character length of the chunk\n",
        "    chunk_overlap = 100, # the character length of the overlap between chunks\n",
        "    length_function = len, # the length function - in this case, character length (aka the python len() fn.)\n",
        ")"
      ],
      "metadata": {
        "id": "uEgcUVtl00Xm"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barbie_documents = text_splitter.transform_documents(barbie_data)"
      ],
      "metadata": {
        "id": "y9RJUiUD2gS5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(barbie_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N4OXAhc3oIB",
        "outputId": "3b9da50d-706f-435c-97ba-c91c70f2e93b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "181"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oppenheimer_documents = text_splitter.transform_documents(oppenheimer_data)"
      ],
      "metadata": {
        "id": "SXwnuaIdiOda"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(oppenheimer_documents)"
      ],
      "metadata": {
        "id": "besfEZURiXn3",
        "outputId": "165e439f-7290-4a75-85f3-b691d05407f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_documents = barbie_documents + oppenheimer_documents"
      ],
      "metadata": {
        "id": "mQ0nakUTjAlW"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our documents transformed into more manageable sizes, and with the correct metadata set-up, we're now ready to move on to creating our VectorStore!"
      ],
      "metadata": {
        "id": "ylT4jwmx3zCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Creating an \"Index\"\n",
        "\n",
        "The term \"index\" is used largely to mean: Structured documents parsed into a useful format for querying, retrieving, and use in the LLM application stack."
      ],
      "metadata": {
        "id": "9cB0L_CN38W5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Selecting Our VectorStore\n",
        "\n",
        "There are a number of different VectorStores, and a number of different strengths and weaknesses to each.\n",
        "\n",
        "In this notebook, we will be keeping it very simple by leveraging [Facebook AI Similarity Search](https://ai.meta.com/tools/faiss/#:~:text=FAISS%20(Facebook%20AI%20Similarity%20Search,more%20scalable%20similarity%20search%20functions.), or `FAISS`."
      ],
      "metadata": {
        "id": "GycdG53N4f9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U faiss-cpu tiktoken sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5o4vwSn4hfe",
        "outputId": "57d16b8d-dd60-4353-fbdf-94c48294ca74"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3177, in __init__\n",
            "    self.specs = [(spec.operator, spec.version) for spec in self.specifier]\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1622, in _log\n",
            "    record = self.makeRecord(self.name, level, fn, lno, msg, args,\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1591, in makeRecord\n",
            "    rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 328, in __init__\n",
            "    self.msecs = int((ct - int(ct)) * 1000) + 0.0  # see gh-89047\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to be setting up our VectorStore with the OpenAI embeddings model. While this embeddings model does not need to be consistent with the LLM selection, it does need to be consistent between embedding our index and embedding our queries over that index.\n",
        "\n",
        "While we don't have to worry too much about that in this example - it's something to keep in mind for more complex applications.\n",
        "\n",
        "We're going to leverage a [`CacheBackedEmbeddings`](https://python.langchain.com/docs/modules/data_connection/caching_embeddings )flow to prevent us from re-embedding similar queries over and over again.\n",
        "\n",
        "Not only will this save time, it will also save us precious embedding tokens, which will reduce the overall cost for our application.\n",
        "\n",
        ">#### Note:\n",
        ">The overall cost savings needs to be compared against the additional cost of storing the cached embeddings for a true cost/benefit analysis. If your users are submitting the same queries often, though, this pattern can be a massive reduction in cost."
      ],
      "metadata": {
        "id": "CGU96p5R54Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import CacheBackedEmbeddings, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.storage import LocalFileStore\n",
        "\n",
        "store = LocalFileStore(\"./cache/\")\n",
        "\n",
        "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "\n",
        "core_embeddings_model = HuggingFaceEmbeddings(\n",
        "    model_name=embed_model_id\n",
        ")\n",
        "\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    core_embeddings_model, store, namespace=embed_model_id\n",
        ")\n",
        "\n",
        "vector_store = FAISS.from_documents(combined_documents, embedder)"
      ],
      "metadata": {
        "id": "AOzZWPU05WLr"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've created the VectorStore, we can check that it's working by embedding a query and retrieving passages from our reviews that are close to it."
      ],
      "metadata": {
        "id": "IGHzcE5i6fOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How is Will Ferrell in this movie?\"\n",
        "embedding_vector = core_embeddings_model.embed_query(query)\n",
        "docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)\n",
        "\n",
        "for page in docs:\n",
        "  print(page.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLOvFNxA6ZSH",
        "outputId": "9aad030c-760a-4f17-dba2-cd1fc4b52883"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Published as a conference paper at ICLR 2023\n",
            "Fever Prompts – Continued from previous page\n",
            "Claim Beautiful reached number two on the Billboard Hot 100 in 2003.\n",
            "Thought The song peaked at number two on the Billboard Hot 100 in the United States,\n",
            "but not sure if it was in 2003.\n",
            "Answer NOT ENOUGH INFO\n",
            "ReAct Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\n",
            "there is NOT ENOUGH INFORMATION.\n",
            "Claim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
            "Thought 1 I need to search Nikolaj Coster-Waldau and find if he has worked with the\n",
            "Fox Broadcasting Company.\n",
            "Action 1 Search[Nikolaj Coster-Waldau]\n",
            "Observation 1 Nikolaj William Coster-Waldau (born 27 July 1970) is a Danish actor and\n",
            "producer. He graduated from the Danish National School of Performing Arts\n",
            "in Copenhagen in 1993,[1] and had his breakthrough role in Denmark with\n",
            "the film Nightwatch (1994). He played Jaime Lannister in the HBO fantasy\n",
            "Published as a conference paper at ICLR 2023\n",
            "C.2 F EVER\n",
            "FEVER Prompts\n",
            "Orig inal Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\n",
            "there is NOT ENOUGH INFORMATION.\n",
            "Claim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
            "Answer SUPPORTS\n",
            "Claim Stranger Things is set in Bloomington, Indiana.\n",
            "Answer REFUTES\n",
            "Claim Beautiful reached number two on the Billboard Hot 100 in 2003.\n",
            "Answer NOT ENOUGH INFO\n",
            "Act Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\n",
            "there is NOT ENOUGH INFORMATION.\n",
            "Claim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
            "Action2 Search[Nikolaj Coster-Waldau]\n",
            "Observation 1 Nikolaj William Coster-Waldau (born 27 July 1970) is a Danish actor and\n",
            "producer. He graduated from the Danish National School of Performing Arts\n",
            "in Copenhagen in 1993,[1] and had his breakthrough role in Denmark with\n",
            "the film Nightwatch (1994). He played Jaime Lannister in the HBO fantasy\n",
            "Q: [final question]\n",
            "A: [completion]\n",
            "Dataset features\n",
            "• 11,873 examples drawn from the validation dataset\n",
            "• In the few-shot setting, there are 4 additional background paragraphs and associated questions.\n",
            "• Evaluation metric is the f1 score from the sample to the target completion.\n",
            "Figure 20: Squadv2: prompting, examples, and dataset features.\n",
            "47\n",
            "act like the assigned role using the tone, manner, and vocabulary the role would use. The more\n",
            "assistant-like tones, the worse. The more in-character, the better.” The way that SoT breaks the\n",
            "41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how much time the `CacheBackedEmbeddings` pattern saves us:"
      ],
      "metadata": {
        "id": "ix4fyOUS-fU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1 -r 1\n",
        "query = \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow.\"\n",
        "embedding_vector = embedder.embed_query(query)\n",
        "docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLXFKzu--m81",
        "outputId": "35ecaba4-d8be-44ce-82a3-f7fe96c5f671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.4 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "query = \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow.\"\n",
        "embedding_vector = embedder.embed_query(query)\n",
        "docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCwtsJbc_KPd",
        "outputId": "c9316757-4f64-466a-dd3a-0f2752de9730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.89 ms ± 275 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, even over a significant number of runs - the cached query is significantly faster than the first instance of the query!\n",
        "\n",
        "With that, we're ready to move onto Task 3!"
      ],
      "metadata": {
        "id": "b4utL1EfARTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Building a Retrieval Chain\n",
        "\n",
        "In this task, we'll be making a Retrieval Chain which will allow us to ask semantic questions over our data.\n",
        "\n",
        "This part is rather abstracted away from us in LangChain and so it seems very powerful.\n",
        "\n",
        "Be sure to check the documentation, the source code, and other provided resources to build a deeper understanding of what's happening \"under the hood\"!"
      ],
      "metadata": {
        "id": "Po3kHNHGBp0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A Basic RetrievalQA Chain\n",
        "\n",
        "We're going to leverage `return_source_documents=True` to ensure we have proper sources for our reviews - should the end user want to verify the reviews themselves.\n",
        "\n",
        "Hallucinations [are](https://arxiv.org/abs/2202.03629) [a](https://arxiv.org/abs/2305.15852) [massive](https://arxiv.org/abs/2303.16104) [problem](https://arxiv.org/abs/2305.18248) in LLM applications.\n",
        "\n",
        "Though it has been tenuously shown that using Retrieval Augmentation [reduces hallucination in conversations](https://arxiv.org/pdf/2104.07567.pdf), one sure fire way to ensure your model is not hallucinating in a non-transparent way is to provide sources with your responses. This way the end-user can verify the output."
      ],
      "metadata": {
        "id": "i5Ux9XdzCDi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Our LLM\n",
        "\n",
        "In this notebook, we're going to leverage Meta's LLaMA 2!\n",
        "\n",
        "Specifically, we'll be using: `meta-llama/Llama-2-13b-chat-hf`\n",
        "\n",
        "That's right, a 13B parameter model that we're going to run on *less than* 15GB of GPU RAM.\n",
        "\n",
        "More information on this model can be found [here](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf)"
      ],
      "metadata": {
        "id": "O_waVo3AEk71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-hub -q"
      ],
      "metadata": {
        "id": "BZaXz33mlv4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "wNuj7UZNl2A-",
        "outputId": "4e8a21ac-3952-4cea-b27d-9be7cbf41b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "9727a21383dc4097a45bd1faa5de4813",
            "dc679de6da604022b281a6db617856c9",
            "8924d53ecb7747fca0751a73aebc48f3",
            "255bd55cd800495cbf533bfc93f7fb56",
            "46fb51aa623c469abaadd13c6668fb1c",
            "a299a62e4fc14afb8f8a8fbddfe7230f",
            "fe92789cc57c421998f19e53b4dcc32f",
            "0e4ff6e58fef4010be71f95ff8d4f5c1",
            "03af4c5d5c3043d58b2acda51496ee33",
            "1adb0fd701584681aa7aa395434141e5",
            "ff9fb615eb8542d4993f0c0ecf405dbb",
            "bd017f370d634fdc86b5ea0c86289237",
            "7d43a61035b041e5b1f2b4f0a3a28dd2",
            "275f205008c14c5e9fb24a85a5997d75",
            "c10a3b5cdc3e4c63a462f7d2b44578a9",
            "872c6c5e3adb4310ae3f37d07e6bf6f5",
            "73650804a1884db0aa1b5109340bb5ac",
            "6b32f66273054e7196ee69f5af4f32ff",
            "dea54a2e7cbc4534a2ce19c7428119d2",
            "be992587447b42a8bf183e9bdeb3b82a",
            "db78f9df295d4a12879ca35fd4152318",
            "93fe741a05544776a274a7e19d8d480c",
            "3b94acd8d9d642a9bdaf98cfd5da6635",
            "b1477056b47c495e8914e0b9d965e836",
            "bf2d7666aea2468383b460ece894edb5",
            "6a0832467c464105b7439993218b2bce",
            "75a8916f74894a1784fbe2d3e668d157",
            "695d5b8df9054ce18401bf100fe12f45",
            "283e8139f9db43fb934cb691ef419653",
            "d01f950743ab4555998858827c5d9bd8",
            "fd9c74a3b5ae44a4b947413a23a0caf2",
            "862f74e2ed764cab8eb24ce0b1d0ae12"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9727a21383dc4097a45bd1faa5de4813"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be leveraging Tim Dettmer's `bitsandbytes` as well as `accelerate` and `transformers` from Hugging Face to make our model as small as possible. The overall quality of the model is fairly well retained!"
      ],
      "metadata": {
        "id": "AjP0VURvpsLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "model_id = \"meta-llama/Llama-2-13b-chat-hf\"\n",
        "\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id\n",
        ")\n",
        "\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto'\n",
        ")\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "QfglvbBtExPR",
        "outputId": "8fcefc7c-db14-4050-9da7-e4f8df239e9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725,
          "referenced_widgets": [
            "1efb2374a1644e52a81a636a13d58249",
            "e0d12a53ae8741529c8bf2b5091ff77e",
            "668fc4ca3f3649fba0aa8a8b247190f9",
            "9752189bc9b24d03944bef5a5e54be4c",
            "39813189570f4788999192850a4e49d9",
            "6daf309730fa4663b580b82b809b0a8a",
            "946599f8b6b549ce97259b76c214e2d4",
            "1c92c69be70147a68d69b09298beb0e5",
            "7753614eac8449c28790b03307e041fb",
            "920092d6cc814f7bac5871f15399354f",
            "2fa280ad9b1d412d8069991ea1a71dd1",
            "5c262b8db4074d16abc7b6bf8ea498f8",
            "62613533653246e58b2098ebce07dde9",
            "2d2f447babe349e6b0855ebd88891f35",
            "077844fb62a94cb0a3110dab3c3dece0",
            "de01eaac2f7e4d1f9602dfe91d909a16",
            "77ea299e685d40e7b0b6489238971672",
            "da701fa4748444d481dffa06a9f27615",
            "93f94d3a90644b9ca78017adf744676f",
            "ea8cdf1ee35641f2acccca64ab3cbbd7",
            "6885ce7fb88844eea68afcea5eba5815",
            "3976ed21cc40432f84feaed5b73f0853",
            "e5bbd14bce5748189abbbb7590286084",
            "552ab0fd9a2548eaa83b734afa624700",
            "35f8a9ddeb87498ca8d2255b762b43df",
            "ddc5cf8a1d3b428ab46427324bacb1e2",
            "b2d3a46945814958a0d1f7cc5eab69f0",
            "c4b876d53cfc49bc84196c197ceaa678",
            "206e23463df34730ab727c17d6947957",
            "ac28784d1585470fa1a2694e4241331f",
            "f3b2428376d5422298e3347882b4e4cf",
            "39990ef1d383482d929837fa1342cf68",
            "e29497df3e634110b7de7be93737e02c",
            "f48d9623fa894b97b5bfb18191bc1654",
            "67f293a4c0bb4c71939f7914a503f6b0",
            "92dfe87e5dc4430da51d75237b04c0c1",
            "dfc951fbaa5d4ab38d048debd8438dac",
            "d87dd27f884d44d299516825abc045ee",
            "ff8f259492df4a92b221cb3d2c18112b",
            "f6b76b715d134f118dd5d3fa04d955fa",
            "3e8ffcc4ec024a5a975978aee2583ec5",
            "20f5eab6b39e4d939fb2387dee26e3eb",
            "228ea255624740ffb1dafcb3edd85cb5",
            "bc15521b83864637bf2cfbff055de64b",
            "ab56e160fa2f4449ada8f12a244b8dcc",
            "4b552dfdfe2a4d72afcc80e472980897",
            "f7c8a6b04fb748cf9c54a14af528eaf9",
            "a6e5ee9e3a3a46479d4b6fa61225a26f",
            "e9a4a8dccf3a41058ba67a093277d9d0",
            "4920b6584893485bb084cb7cbc48339a",
            "ba55aa3001a441199c7b7b89decf6f73",
            "c80b2427c22e41f8b3fcc1ecc128c009",
            "f0ebda48fa1b4670baf38a160bb2605b",
            "a1cecf38c3bc4cb0926fa66d82363328",
            "5b582053acbb4cd0857455a272b1b6c9",
            "1466d45547f64f0db50685fd5375fbe8",
            "d93c96940af7482baece6ce369138b40",
            "0a9e946e9a4f4bbea1293d80a9df6ddf",
            "52a78d04f9214f5cb309cd0609f46e64",
            "e79536b981be40d0995f6f064fa28a43",
            "21a3ce442905456bbff81a0539367c31",
            "f311d97105cb46b2899d0ed69954a015",
            "92fbde51dbd64f52aa48cb58bac6a85e",
            "ed0aab945c674eef9db84dbeb681139f",
            "b0ea578250a74c6d84fdec66e4c97ef4",
            "e6fc4c4fd5f3418f8c7ee4b7d471cac3",
            "4c3072086afa42f2a7d819f95ae5a970",
            "e103408322324d749325d7146d941ad5",
            "8ccec662868c4895abcdc0f51d8669ea",
            "f8fb1bbda77e4f0b8079e517f450c53f",
            "9038750942a14c418f84ce889fc06227",
            "efeb488cf2244131a2cf2727b8adb575",
            "fca1f59286754b8f8cc2850a7c1709be",
            "e483714a12794cb6b86da27493f4acdc",
            "1c71bc16b6cf4790aa7a4f75d1ed07b9",
            "4b60f469dc364c998c6896120948eb00",
            "16c6385016e345d9879a7a4dcd1b3344",
            "b1ae393b1a83404894287e8f8d3e6da3",
            "c8909831f56843f6a2bd2fab7540e5e8",
            "55f2d974fd3f411897a4c98a2f461e90",
            "d04d44aba64f42c1a1d32e238253b099",
            "d558550f31984373929ee69b1d049ef3",
            "c306eb541d024e6bb5584457030a5b1f",
            "dfa44ca6659447848d74bdcf2aba91c5",
            "972ab6bfa69f4f4e9b3cd6ee75cf33a4",
            "872fe4cfdfb349178c77fa7653235e2a",
            "b71d2f4a385741b0b04e71ecd743560e",
            "002fc7e34d6542fca4c1c7244f392392"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)a-2-13b-chat-hf/resolve/main/config.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1efb2374a1644e52a81a636a13d58249"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)esolve/main/model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c262b8db4074d16abc7b6bf8ea498f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5bbd14bce5748189abbbb7590286084"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f48d9623fa894b97b5bfb18191bc1654"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab56e160fa2f4449ada8f12a244b8dcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1466d45547f64f0db50685fd5375fbe8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c3072086afa42f2a7d819f95ae5a970"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)t-hf/resolve/main/generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1ae393b1a83404894287e8f8d3e6da3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(32000, 5120, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-39): 40 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=13824, out_features=5120, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm()\n",
              "        (post_attention_layernorm): LlamaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=5120, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_id\n",
        ")"
      ],
      "metadata": {
        "id": "hzl5a1kemBmp",
        "outputId": "7aeacdeb-414b-44c3-a37d-14353f9343e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "8561f0b7d510479fa0e24c4dc0f2c501",
            "ac454e01a978411f9bf8d2450076d1dc",
            "49018fb7c125419e8dfa4dd2a044ad23",
            "907b52d19b5e463391194c1e916a1980",
            "02fa431029614c96b6340780333d0fab",
            "5958e14e464742c88a9a472d1e6a520c",
            "b897cd965ee54c45aaf45e703c969b9a",
            "684b49fbeaa34fe19c8968fa788bc372",
            "d4d2569b660441128ad76f61004cf154",
            "9ed0a98f834e41e6a3326c0dc84bfba8",
            "903506efc5d54acf9a6ad2de25fd8693",
            "5afe71e74c1a404bb4caed2713802863",
            "fe0939e7ba2842fa9801e3b72729d7e6",
            "bce8d1e8e47e45c48f0984b8f55a255c",
            "f7bdf42b7a70418ba8adf8e26b87487c",
            "c40b7841f0a349738143e1e6a46fc26e",
            "c9912e713d5945b693d77949bf72053a",
            "7c5e3810c57546eca33e263389a66333",
            "00ddeed00a774e259d59ffff57638378",
            "7766c4247fc54aad97c8027a59fa70d2",
            "9925962aba204892a01999081f8c0489",
            "58013e37ff59432192ed91f4c1ee494d",
            "a32c8ed7d03e4b6d833254ea4dc25841",
            "5132176feaff40ffaf83b2b5528f3606",
            "ca744cb5cfe14ae7b26b1026735ea908",
            "1138daef29964892a7c5e2f5894f66cf",
            "7bff7c6c762f40de928f1d32f492d3fd",
            "c79b7a7b0f2440448d50b7016b67640e",
            "2c1ce27fa6c14eebb364204def1a8134",
            "51e0aee033b343309be4b447def12b1f",
            "50485d7d98434acbb7ece883958a20b7",
            "34e64be41c124c4ba200ecd2ab8a360b",
            "44f7d3a6182b4484bcfe61e21c8da94c",
            "156ad84235b64399a4d978c8450a3d2f",
            "07d47d2514af4f82a7290d5a689aa9f8",
            "60da19e614b647d6b31511a484333a80",
            "ce239a66fd624f349a259d8769e06fb2",
            "ba926ec5181142ed98492da94d0f2db1",
            "cafb0b0a9d834b6fa03da55a1d5a3b91",
            "13dc5eb9583c4c67afa23004f5a2e6df",
            "1601b7b079d64d23a9e22ef186628c1a",
            "3192096d9b064c889a03cfb725b9578f",
            "1084c72683b14087a81e0def011c2ff5",
            "b59fa3efd3a44f819ab16ccfa0db9e2c"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)at-hf/resolve/main/tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8561f0b7d510479fa0e24c4dc0f2c501"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5afe71e74c1a404bb4caed2713802863"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-13b-chat-hf/resolve/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a32c8ed7d03e4b6d833254ea4dc25841"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-hf/resolve/main/special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "156ad84235b64399a4d978c8450a3d2f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to pack it into a `pipeline` for compatability with `langchain`!"
      ],
      "metadata": {
        "id": "VJX2XhUop5lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers"
      ],
      "metadata": {
        "id": "VuTEhRJXaLAz",
        "outputId": "c61f33a3-2ce4-44a3-f5a5-c90e7e041eeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xformers\n",
            "  Downloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.5)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->xformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->xformers) (1.3.0)\n",
            "Installing collected packages: xformers\n",
            "Successfully installed xformers-0.0.22.post7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    return_full_text=True,\n",
        "    temperature=0.0,\n",
        "    max_new_tokens=256\n",
        ")"
      ],
      "metadata": {
        "id": "cYLhG8_imWei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)"
      ],
      "metadata": {
        "id": "c1UhO3OTmoOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can set up our chain."
      ],
      "metadata": {
        "id": "w35ZkVEoE8II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "T8TWJMH8F_w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "\n",
        "handler = StdOutCallbackHandler()\n",
        "\n",
        "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    callbacks=[handler],\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "QeD8R6huFIf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that it's set-up, let's test it out!"
      ],
      "metadata": {
        "id": "aFv0b0goqAgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_with_sources_chain({\"query\" : \"How was Will Ferrell in this movie?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPaII9nF72R",
        "outputId": "ac14cdd5-abc4-4022-bf55-cd9e0c6f4166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'How was Will Ferrell in this movie?',\n",
              " 'result': ' Based on the reviews, Will Ferrell\\'s character was not well received by some of the reviewers. One reviewer described his character as \"ruining every scene he was in.\" Another reviewer mentioned that his board became \"superfluous.\" However, another reviewer found his performance to be enjoyable. Overall, it seems that opinions on Will Ferrell\\'s performance in the movie are mixed.',\n",
              " 'source_documents': [Document(page_content=\": 61\\nReview_Date: 23 July 2023\\nAuthor: agjbull\\nRating: 6\\nReview_Title: Just a little empty\\nReview: I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\\nReview_Url: /review/rw9199947/?ref_=tt_urv\", metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 61}),\n",
              "  Document(page_content=\": 76\\nReview_Date: 23 July 2023\\nAuthor: a-hilton\\nRating: 10\\nReview_Title: Had me smiling all the way through\\nReview: Okay maybe it was a 9.5 because of two flaws: First was the Will Ferrell character and his board that made their point but then became superfluos. Second was that it is definitely not a kids' movie (although maybe they would see things that I didn't - I mean to be fair, the few kids in the theatre were well behaved so perhaps the movie got their full attention as well).\\nReview_Url: /review/rw9199947/?ref_=tt_urv\", metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 76}),\n",
              "  Document(page_content=': 85\\nReview_Date: 23 July 2023\\nAuthor: hyllus-01262\\nRating: 6\\nReview_Title: Overhyped movie, had its moments though\\nReview: The first half was pretty enjoyable, fun, light, but it took itself too seriously by the second half. No longer allowing the talented cast, especially Gosling, to shine and make us laugh. It felt like the talents of Will Ferrell and Michael Cera were also somewhat underutilized. Interesting concept, had potential, but later in the movie, it definitely started to fall flat for me.\\nReview_Url: /review/rw9199947/?ref_=tt_urv', metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 85}),\n",
              "  Document(page_content='tell Cillian Murphy in person how stunning his screen presence has been throughout. Hopefully, this movie wins the awards like it deserves.', metadata={'source': '/review/rw9202236/?ref_=tt_urv', 'row': 10})]}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47Ov7N22MxOS",
        "outputId": "5a0b6430-8cf5-412d-f505-a692704145a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Do reviewers consider this movie Kenough?',\n",
              " 'result': ' Based on the reviews provided, it seems that the reviewers have mixed opinions about the movie. Some reviewers, such as eoinageary and hamsterination, have positive reviews and rate the movie 8 and 6 out of 10, respectively. However, other reviewers, such as brianjohnson-20043 and holarsch, have more negative reviews and rate the movie 4 and 6 out of 10, respectively. Therefore, it cannot be determined whether the reviewers consider the movie Kenough or not.',\n",
              " 'source_documents': [Document(page_content=': 37\\nReview_Date: 23 July 2023\\nAuthor: eoinageary\\nRating: 8\\nReview_Title: I am Kenough\\nReview: So I went into the movie with little to no expectations and I was pleasantly impressed with the movie overall.\\nReview_Url: /review/rw9199947/?ref_=tt_urv', metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 37}),\n",
              "  Document(page_content=\": 9\\nReview_Date: 19 July 2023\\nAuthor: hamsterination\\nRating: 6\\nReview_Title: It could have been so much better...\\nReview: The film's universe and settings are fantastic. The casting is really good too, with Gosling excelling in the role of Ken.\\nReview_Url: /review/rw9199947/?ref_=tt_urv\", metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 9}),\n",
              "  Document(page_content=\": 43\\nReview_Date: 24 July 2023\\nAuthor: brianjohnson-20043\\nRating: 4\\nReview_Title: This movie tries to be too much\\nReview: I wanted to like it. But I just didn't. The story wasn't very compelling to me because it seemed as if the entire point of much of the movie was to provide learning moments for viewers with some slapstick comedy and quick-delivery comedy. The story itself should nearly always be more important.\\nReview_Url: /review/rw9199947/?ref_=tt_urv\", metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 43}),\n",
              "  Document(page_content=\": 129\\nReview_Date: 31 July 2023\\nAuthor: holarsch\\nRating: 6\\nReview_Title: Overhyped\\nReview: The world has been waiting for a first class drama to help bring em back to the movies after a shortage of really fine movies for a really long time. I went in hoping that this was gonna be the cinematic miracle that Hollywood has been holding it's breath for. It wasn't. It was a modestly adequate film that I could have skipped. With a running time of close to three hours, this ponderous film just felt repetitive and quite tedious throughout. There's an all star cast that would have been better served by appearing in a movie that had been written and edited with more selectivity. Had I seen it on TV and it had been a half hour shorter, perhaps I'd have thought more of it.\\nReview_Url: /review/rw9228550/?ref_=tt_urv\", metadata={'source': '/review/rw9228550/?ref_=tt_urv', 'row': 129})]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_with_sources_chain({\"query\" : \"Did these movies explores themes of existentialism?\"})"
      ],
      "metadata": {
        "id": "g7q7_xn-nFT3",
        "outputId": "a4781c13-2e2a-454e-b776-f3c38cf9a7e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Did these movies explores themes of existentialism?',\n",
              " 'result': ' Based on the reviews, it appears that \"Oppenheimer\" explores themes of existentialism. The review by sosrivi states that the film is \"a reminder to the audience of how obsessed humans are with power and fame,\" which is a common theme in existentialist literature and film. Additionally, the review by chris_rowe-881-168820 states that the film is \"pretty much perfect,\" which suggests that it effectively explores its themes and ideas.',\n",
              " 'source_documents': [Document(page_content=\": 117\\nReview_Date: 20 July 2023\\nAuthor: mattlx\\nRating: 8\\nReview_Title: A decent experience, still not perfect\\nReview: The film's abundance of characters, combined with its non-linear narrative approach, might leave you a bit puzzled during your first viewing.\\nReview_Url: /review/rw9201962/?ref_=tt_urv\", metadata={'source': '/review/rw9201962/?ref_=tt_urv', 'row': 117}),\n",
              "  Document(page_content=\": 135\\nReview_Date: 20 July 2023\\nAuthor: sosrivi\\nRating: 9\\nReview_Title: Just got amazed\\nReview: Oppenheimer is not solely based on the Trinity. It's entirely political drama. Just a reminder to the audience of how obsessed humans are with power and fame. Music is the true hero of Oppenheimer's film. Every highest point throughout the film causes enormous tension. Everyone did an excellent job. The visual grandeur of Trinity underwhelmed me, but the music helped to compensate. Nolan has once again demonstrated his ability to present a political drama. Where all of the mental state were handled flawlessly. Overall, a remarkable image and historical significance that should never be forgotten. The film will leave you speechless.\\nReview_Url: /review/rw9202920/?ref_=tt_urv\", metadata={'source': '/review/rw9202920/?ref_=tt_urv', 'row': 135}),\n",
              "  Document(page_content=': 36\\nReview_Date: 22 July 2023\\nAuthor: ferguson-6\\nRating: 9\\nReview_Title: superior filmmaking and historical storytelling', metadata={'source': '/review/rw9207372/?ref_=tt_urv', 'row': 36}),\n",
              "  Document(page_content=\": 106\\nReview_Date: 27 July 2023\\nAuthor: chris_rowe-881-168820\\nRating: 10\\nReview_Title: Pretty much perfect\\nReview: This isn't my type of film, I normally get bored or find the slow pace just loses my interest, my dad wanted to see this so I thought I'd go and give it a chance.\\nReview_Url: /review/rw9218170/?ref_=tt_urv\", metadata={'source': '/review/rw9218170/?ref_=tt_urv', 'row': 106})]}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And with that, we have our Barbie & Oppenheimer Review RAG tool built!"
      ],
      "metadata": {
        "id": "QQVCkoy3H5Rw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Notebook is a companion to the event put on by [AIMS](https://www.linkedin.com/company/ai-maker-space/), and [Deci](https://deci.ai/), and is authored by [Chris Alexiuk](https://www.linkedin.com/in/csalexiuk/)"
      ],
      "metadata": {
        "id": "hyykEFE3oWDW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5xdfJZnH81C0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}